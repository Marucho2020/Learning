<html><head><title>Lesson 2 == Vector ==========//</title><style>body { font-family: Arial, sans-serif; transition: background 0.3s, color 0.3s; }.dark-mode { background-color: #121212; color: #e0e0e0; }.light-mode { background-color: #ffffff; color: #333333; }h1 { text-align: center; color: #73d9f5; }pre { padding: 15px; border-radius: 5px;       white-space: pre-wrap; word-wrap: break-word;       overflow-x: auto; max-width: 100%;       transition: background 0.3s, color 0.3s; }.dark-mode pre { background: #1e1e1e; color: #e0e0e0; }.light-mode pre { background: #f5f5f5; color: #333333; }#backTop, #backBottom {    font-size: 2em; padding: 20px 40px;    background: #bb86fc; color: white; text-decoration: none;    border-radius: 10px; display: inline-block; text-align: center; }#backTop:hover, #backBottom:hover { background: #9b67e2; }button { font-size: 1.5em; padding: 15px 30px;    background: #03dac6; color: #121212; border: none;    cursor: pointer; border-radius: 5px; display: block; margin: 10px auto; }button:hover { background: #02b8a3; }.dark-mode a { color: #03dac6; } .light-mode a { color: #007bff; }</style></head><body onload='applyTheme(); checkPageHeight()'><div class='container'><a id='backTop' href='../AI-math-learning-list.html'>üîô Quay l·∫°i danh s√°ch</a><br><h1>Lesson 2 -- Vector -//</h1><pre>////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////


	# Kh√°i ni·ªám : Vector l√† m·ªôt ƒë·ªëi t∆∞·ª£ng to√°n h·ªçc c√≥ ƒë·ªô l·ªõn v√† h∆∞·ªõng. Trong ƒë·∫°i s·ªë tuy·∫øn t√≠nh, vector ƒë∆∞·ª£c bi·ªÉu di·ªÖn d∆∞·ªõi d·∫°ng danh s√°ch c√°c s·ªë, th∆∞·ªùng trong m·ªôt c·ªôt ho·∫∑c h√†ng  (ƒë∆∞·ª£c g·ªçi l√† th√†nh ph·∫ßn c·ªßa vector )
	
		V√≠ d·ª• trong kh√¥ng gian 2 chi·ªÅu , vector v = (3,4) c√≥ th√†nh ph·∫ßn x = 3 v√† y  = 4

	# ·ª®ng d·ª•ng : 
		M√¥ t·∫£ d·ªØ li·ªáu trong AI(v√≠ d·ª• m·ªôt h√¨nh ·∫£nh c√≥ th·ªÉ l√† m·ªôt vector c√°c gi√° tr·ªã m√†u s·∫Øc ) 
		ƒê·∫°i di·ªán cho ƒëi·ªÉm ho·∫∑c h∆∞·ªõng trong kh√¥ng gian 
				
//--------------------------------------- Kh√¥ng gian vector(Vector Space)
# Kh√°i ni·ªám : T·∫≠p h·ª£p c√°c vector c√≥ th·ªÉ ƒë∆∞·ª£c c·ªông l·∫°i v·ªõi nhau ho·∫∑c nh√¢n v·ªõi m·ªôt s·ªë(scaling) m√† k·∫øt qu·∫£ v·∫´n n·∫±m trong t·∫≠p ƒë√≥ , v·∫´n n·∫±m trong kh√¥ng gian ƒë√≥ 
		V√≠ d·ª• : t·∫≠p t·∫•t c·∫£ c√°c vector [x,y] v·ªõi x,y l√† s·ªë th·ª±c 
		
		## M·ªôt kh√¥ng gian vector c·∫ßn th·ªèa m√£n c√°c ƒëi·ªÅu ki·ªán sau  
			### C·ªông vector : N·∫øu v , w l√† hai vector trong kh√¥ng gian vector, th√¨ v + w c≈©ng ph·∫£i thu·ªôc kh√¥ng gian vector ƒë√≥  
			
			### Nh√¢n vector v·ªõi scalar : N·∫øu v l√† m·ªôt vector v√† c l√† m·ªôt s·ªë(scalar) th√¨ c x v c≈©ng ph·∫£i thu·ªôc kh√¥ng gian vector ƒë√≥ 
			
			### C√°c t√≠nh ch·∫•t kh√°c :  C√°c ph√©p to√°n c·ªông vector v√† nh√¢n v·ªõi scalar ph·∫£i th·ªèa m√£n m·ªôt s·ªë t√≠nh ch·∫•t nh∆∞ k·∫øt h·ª£p, ph√¢n ph·ªëi, c√≥ ph·∫ßn t·ª≠ kh√¥ng thay ƒë·ªïi(vector 0)
		
		
		## Trong m·ªói h∆∞·ªõng c√≥ t·ªìn t·∫°i v√¥ h·∫°n vector v√¨ th·∫ø ch√∫ng ta c√≥ th·ªÉ nh√¢n ch√∫ng v·ªõi b·∫•t k·ª≥ s·ªë n√†o c≈©ng ra h∆∞·ªõng ƒë√≥ 
		
		
		
# ·ª®ng d·ª•ng 
		+ L√† c∆° s·ªü ƒë·ªÉ hi·ªÉu c√°c kh√°i ni·ªám nh∆∞ h·ªá ph∆∞∆°ng tr√¨nh tuy·∫øn t√≠nh ho·∫∑c h·ªçc m√°y 
		
		

# V√≠ d·ª• v·ªÅ kh√¥ng gian vector 2 chi·ªÅu v√† 3 chi·ªÅu : 
	## 1. Kh√¥ng gian vector 2 chi·ªÅu : 
		+> T·∫≠p h·ª£p t·∫•t c·∫£ c√°c vector c√≥ d·∫°ng(x,y) l√† kh√¥ng gian vector 2 chi·ªÅu trong m·∫∑t ph·∫≥ng()
							V√≠ d·ª• : 
								(3,4) , (-1,2) , (0,0)
		
		+> C√°c vector n√†y c√≥ th·ªÉ c·ªông l·∫°i v√† nh√¢n v·ªõi scalar 

	## 2 Kh√¥ng gian vector 3 chi·ªÅu :
		+> T·∫≠p h·ª£p t·∫•t c·∫£ c√°c vector c√≥ d·∫°ng (x,y,z) l√† kh√¥ng gian vector 3 chi·ªÅu(trong kh√¥ng gian 3 chi·ªÅu )
							V√≠ d·ª•: 
								
								(1,2,3) , (4,-5,6)
		
		+> T∆∞∆°ng t·ª± nh∆∞ kh√¥ng gian 2 chi·ªÅu, b·∫°n c√≥ th·ªÉ th·ª±c hi·ªán c·ªông v√† nh√¢n vector v·ªõi scalar
				


# C√°c ph√©p to√°n c∆° b·∫£n v·ªÅ kh√¥ng gian vector 	
	## C·ªông vector 
		Khi c·ªông hai vector, b·∫°n c·ªông t·ª´ng th√†nh ph·∫ßn t∆∞∆°ng ·ª©ng c·ªßa ch√∫ng 
		
				v√≠ d·ª• : 
				v = (2,3) , w = (4 , -1) 
				v + w = ((2+4) , (3+(-1)) ) = (6,2)
				
	## Nh√¢n vector v·ªõi scalar 
		Nh√¢n v·ªõi Scalar t·ª©c l√† ta s·∫Ω nh√¢n t·ª´ng th√†nh ph·∫ßn c·ªßa vector ƒë√≥ v·ªõi scalar 
			V√≠ d·ª•  
				v = (2,3)  Scalar = 3 
				v . 3 = 3 . (2,3) = (6,9)
				
	
	## ƒê·ªô d√†i c·ªßa vector (Norm of a vector )
		ƒê·ªô d√†i(hay c√≤n g·ªçi l√† norm)  c·ªßa m·ªôt vector v = (x , y) l√† cƒÉn b·∫≠c 2 c·ªßa t·ªïng b√¨nh ph∆∞∆°ng c√°c th√†nh ph·∫ßn 
			||v|| = sqrt(x^2 + y^2)		
			
		V√≠ d·ª• : 
			v = (3,4)  =>  ||v|| = 5


//---------------------------- T√≠ch v√¥ h∆∞·ªõng(Dot product)		
	# Kh√°i ni·ªám : l√† m·ªôt ph√©p to√°n gi·ªØa 2 vector, cho k·∫øt qu·∫£ l√† m·ªôt s·ªë (scalar)
		C√¥ng th·ª©c : u.v = u1v1 + u2v2 + ... + unvn
		
	# ·ª®ng d·ª•ng :
		T√≠nh ƒë·ªô t∆∞∆°ng t·ª± gi·ªØa 2 vector(v√≠ d·ª• trong t√¨m ki·∫øm vƒÉn b·∫£n )
		T√≠nh g√≥c gi·ªØa 2 vector 
		
		
	# C√¥ng th·ª©c 
		 vector A.B = |A|.|B|.cos0  
			- |A| l√† ƒë·ªô d√†i c·ªßa vector A 
			- cos0 : gi√° tr·ªã cosine c·ªßa g√≥c 0 gi·ªØa 2 vector 
			
			-> Khi 	cos0 = 1 	: Hai vector c√πng h∆∞·ªõng 
					cos0 = 0 	: Hai vector vu√¥ng g√≥c 
					cos0 = -1 	: Hai vector ng∆∞·ª£c h∆∞·ªõng  
					

		V√≠ d·ª• : 
			v = (1,2) , w = (3,4) 
			v .  w = 1x3 + 2x4 = 3+8 = 11
			
		V√≠ d·ª• g√≥c gi·ªØa 2 vector 	 A (1,0) , B = (0,1)
				
				T√≠ch v√¥ h∆∞·ªõng :
					A . B = 1.0 + 0 . 1 = 0 
					T√≠ch v√¥ h∆∞·ªõng b·∫±ng 0 nghƒ©a l√† g√≥c gi·ªØa 2 vector vu√¥ng g√≥c 
		
	# ·ª®ng d·ª•ng t√≠ch v√¥ h∆∞·ªõng trong h·ªçc m√°y AI 
		Trong machine learning, t√≠ch v√¥ h∆∞·ªõng th∆∞·ªùng ƒë∆∞·ª£c d√πng ƒë·ªÉ : 
			- T√≠nh ƒë·ªô d√†i gi·ªØa 2 vector
			
			## V√≠ d·ª• : 
				N·∫øu hai vector ƒë·∫°i di·ªán cho 2 vƒÉn b·∫£n, t√≠ch v√¥ h∆∞·ªõng s·∫Ω gi√∫p cho bi·∫øt li·ªáu ch√∫ng c√≥ li√™n quan hay kh√¥ng 
				A = (1,2,3) , B = (4,5,6)
				
				A.B  = 1.4 + 2.5 + 3.6 = 32   // N·∫øu t√≠ch v√¥ h∆∞·ªõng l·ªõn, ƒëi·ªÅu ƒë√≥ c√≥ th·ªÉ cho th·∫•y hai vector r·∫•t gi·ªëng nhau .
				

//--------------------  C√°c kh√°i ni·ªám kh√¥ng gian vector ph·ª©c t·∫°p h∆°n  : 

# ƒê·ªãnh nghƒ©a kh√¥ng gian vector ph·ª©c 
	Kh√¥ng gian vector ph·ª©c(C^n) l√† m·ªôt t·∫≠p h·ª£p c√°c vector, trong ƒë√≥: 
		- C√°c ph·∫ßn t·ª≠ (th√†nh ph·∫ßn) c·ªßa vector thu·ªôc tr∆∞·ªùng s·ªë ph·ª©c C
		- C√°c ph√©p c·ªông vector v√† nh√¢n v·ªõi s·ªë v√¥ h∆∞·ªõng (scalar) tu√¢n theo quy t·∫Øc s·ªë ph·ª©c  
		
	V√≠ d·ª• : M·ªôt kh√¥ng gian vector ph·ª©c trong C^2 g·ªìm c√°c vector d·∫°ng  
			v = (z1,z2) , v·ªõi z1, z2 thu·ªôc t·∫≠p C 
			
# Quy t·∫Øc c·ªßa kh√¥ng gian vector ph·ª©c 
	
	Gi·ªëng nh∆∞ kh√¥ng gian vector th·ª±c(R^n), kh√¥ng gian vector ph·ª©c c≈©ng th·ªèa m√£n c√°c ti·ªÅn ƒë·ªÅ c∆° b·∫£n 
		
	## Ph√©p c·ªông vector  
		ƒê√≥ng vai tr√≤ c·ªông t·ª´ng th√†nh ph·∫ßn  
			(1 + i , 2 - i) + (3 - i , 4 + i) =  (  (1+i) + (3 - i) , (2 - i) + (4+i)   ) = (4,6)		// C·ªông g·ªôp v√†o s·∫Ω lo·∫°i ƒë∆∞·ª£c i ra 
			
	## Ph√©p nh√¢n v·ªõi s·ªë v√¥ h∆∞·ªõng : Nh√¢n t·ª´ng th√†nh ph·∫ßn v·ªõi m·ªôt s·ªë ph·ª©c  
		
		V√≠ d·ª• : 
			(1 + i).(2 - i , -1 + i) = ( (1+i)(2-i) , (1+i)(-1+i) )

	## Tu√¢n th·ªß c√°c t√≠nh ch·∫•t giao ho√°n, ph√¢n ph·ªëi , k·∫øt h·ª£p 
	
		

#√ù nghƒ©a h√¨nh h·ªçc kh√¥ng gian vector ph·ª©c 
	- Trong kh√¥ng gian th·ª±c, vector ƒë∆∞·ª£c xem l√† m≈©i t√™n trong kh√¥ng gian n-chi·ªÅu 
	- Trong kh√¥ng gian ph·ª©c, m·ªói ph·∫ßn t·ª≠ l√† m·ªôt s·ªë ph·ª©c, t·ª©c l√† vector s·∫Ω c√≥ ph·∫ßn th·ª±c v√† ·∫£o. ƒêi·ªÅu n√†y gi√∫p bi·ªÉu di·ªÖn c√°c h·ªá th·ªëng ph·ª©c t·∫°p h∆°n, ch·∫≥ng h·∫°n trong ƒëi·ªán t·ª≠, v·∫≠t l√Ω l∆∞·ª£ng t·ª≠ ho·∫∑c h·ªçc m√°y. 
	
	V√≠ d·ª• :  M·ªôt vector trong C^3 c√≥ th·ªÉ ƒë∆∞·ª£c bi·ªÉu di·ªÖn nh∆∞: 
		
			v = (1 + i , 2 - i , -i )
			

# ƒê·ªô d√†i v√† t√≠ch v√¥ h∆∞·ªõng trong kh√¥ng gian vector ph·ª©c 	

	## ƒê·ªô d√†i (Norm)
		ƒê·ªô d√†i (norm) c·ªßa m·ªôt vector v = (z1, z2 , .... zn) ƒë∆∞·ª£c t√≠nh b·∫±ng 
			||v|| = sqrt(|z1|^2 + |z2|^2 + ... + |zn|^2)

	## T√≠ch v√¥ h∆∞·ªõng 
		T√≠ch v√¥ h∆∞·ªõng trong kh√¥ng gian vector ph·ª©c ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a kh√°c m·ªôt ch√∫t so v·ªõi kh√¥ng gian th·ª±c 
			<u,v> = _u1v1 + _u2v2 + ... + _unvn 
			
			_u1 l√† li√™n h·ª£p ph·ª©c c·ªßa u1 
			
		

# C√°c ·ª©ng d·ª•ng th·ª±c t·∫ø :
		1. X·ª≠ l√Ω t√≠n hi·ªáu v√† √¢m thanh: M√¥ h√¨nh h√≥a s√≥ng √¢m v√† t√≠n hi·ªáu b·∫±ng s·ªë ph·ª©c 
		2. V·∫≠t l√Ω l∆∞·ª£ng t·ª≠: Bi·ªÉu di·ªÖn tr·∫°ng th√°i l∆∞·ª£ng t·ª≠ b·∫±ng c√°c vector ph·ª©c 
		3. H·ªçc m√°y : S·ª≠ d·ª•ng kh√¥ng gian ph·ª©c trong m·∫°ng n∆°-ron ho·∫∑c d·ªØ li·ªáu c√≥ li√™n quan ƒë·∫øn t·∫ßn s·ªë 
		4. H·ªá th·ªëng ƒëi·ªán : D√πng ƒë·ªÉ ph·∫ßn t√≠ch ƒëi·ªán √°p v√† d√≤ng ƒëi·ªán d·∫°ng s√≥ng  


//------------------ Vector ƒë·∫∑c tr∆∞ng(Eigenvector) trong to√°n h·ªçc 

# Kh√°i ni·ªám Eigenvector (Vector ƒë·∫∑c tr∆∞ng trong to√°n h·ªçc )
	Vector ƒë·∫∑c tr∆∞ng l√† m·ªôt vector ƒë·∫∑c bi·ªát, khi b·∫°n nh√¢n n√≥ v·ªõi m·ªôt matrix, k·∫øt qu·∫£ s·∫Ω l√† vector ƒë√≥ nh√¢n v·ªõi m·ªôt s·ªë(scalar )
	
	C·ª• th·ªÉ, n·∫øu g·ªçi vector ƒë·∫∑c tr∆∞ng l√† v v√† s·ªë ƒë√≥ l√† ÂÖ•(lambda), th√¨: 
				A.v = ÂÖ•.v
				
			- A : l√† ma tr·∫≠n vu√¥ng(s·ªë h√†ng =  s·ªë c·ªôt )
			- v : l√† vector ƒë·∫∑c tr∆∞ng (eigenvector)
			- ÂÖ• : l√† gi√° tr·ªã ƒë·∫∑c tr∆∞ng(eigenvalue)

# Nghƒ©a l√† g√¨ trong th·ª±c t·∫ø 

	H√¨nh dung m·ªôt ma tr·∫≠n A l√† m·ªôt h·ªá th·ªëng n√†o ƒë√≥, c√≤n v l√† m·ªôt h∆∞·ªõng ƒë·∫∑c bi·ªát 
		- Khi b·∫°n √°p d·ª•ng ma tr·∫≠n A l√™n vector v, th√¨ vector v ch·ªâ b·ªã c√≥ d√£n ho·∫∑c ph√≥ng to theo h∆∞·ªõng c·ªßa n√≥(kh√¥ng thay ƒë·ªïi h∆∞·ªõng )
		- ÂÖ• cho bi·∫øt m·ª©c ƒë·ªô co d√£n ph√≥ng to 
		
	## V√≠ d·ª• d·ªÖ hi·ªÉu 
		B·∫°n v·∫Ω m·ªôt h√¨nh tr√≤n v√† k√©o d√£n n√≥ th√†nh h√¨nh elip b·∫±ng c√°ch √°p d·ª•ng ma tr·∫≠n A. Sau khi k√©o, m·ªôt v√†i vector ban ƒë·∫ßu kh√¥ng ƒë·ªïi h∆∞·ªõng, ch·ªâ thay ƒë·ªïi ƒë·ªô d√†i. Nh·ªØng vector n√†y ch√≠nh l√† vector ƒë·∫∑c tr∆∞ng, v√† m·ª©c ƒë·ªô k√©o d√£n/ ph√≥ng to c·ªßa ch√∫ng ƒë∆∞·ª£c x√°c ƒë·ªãnh b·ªüi ÂÖ• 
		
		
	## S·ªë l∆∞·ª£ng vector c√≥ th·ªÉ x·∫£y ra 
		Ph∆∞∆°ng tr√¨nh ƒë·∫∑c tr∆∞ng 
							det(A - ÂÖ•I) = 0 
			- L√† m·ªôt ph∆∞∆°ng tr√¨nh ƒëa th·ª©c, c·∫•p b·∫≠c c·ªßa n√≥ b·∫±ng v·ªõi k√≠ch th∆∞·ªõc ma tr·∫≠n A 
			- N·∫øu A l√† ma tr·∫≠n n x n, ph∆∞∆°ng tr√¨nh s·∫Ω c√≥ b·∫≠c n 
			- ƒêi·ªÅu n√†y nghƒ©a l√† b·∫°n c√≥ t·ªëi ƒëa n gi√° tr·ªã ÂÖ•(Eigenvalue) t∆∞∆°ng ·ª©ng v·ªõi n Eigenvector ƒë·ªôc l·∫≠p 
			
	

	## I l√† ma tr·∫≠n ƒë∆°n v·ªã(identity matrix) : Ma tr·∫≠n vu√¥ng m√† c√°c ph·∫ßn t·ª≠ l√† ƒë∆∞·ªùng ch√©o ch√≠nh l√† 1, c√°c ph·∫ßn c√≤n l·∫°i l√† 0 
			V√≠ d·ª• 	
					A =  [ [1,0,0] , [0,1,0] , [0,0,1]  ]
					
			M·ª•c ƒë√≠ch c·ªßa I l√† ƒë·∫£m b·∫£o r·∫±ng ÂÖ• c√≥ th·ªÉ ƒë∆∞·ª£c tr·ª´ tr·ª±c ti·∫øp kh·ªèi ma tr·∫≠n A, v√¨ b·∫°n kh√¥ng th·ªÉ tr·ª´ s·ªë ÂÖ• t·ª´ ma tr·∫≠n A m√† kh√¥ng nh√¢n n√≥ v·ªõi ma tr·∫≠n ƒë∆°n v·ªã , T·ª©c l√† n√≥ t·ªìn t·∫°i ƒë·ªÉ gi·ªØ cho ph√©p to√°n h·ª£p l·ªá v√¨ k th·ªÉ tr·ª´ m·ªôt ma tr·∫≠n cho m·ªôt bi·∫øn X ƒë∆∞·ª£c m√† ph·∫£i nh√¢n n√≥ v·ªõi m·ªôt ma tr·∫≠n ƒë∆°n v·ªã 

	
		
		
# ·ª®ng d·ª•ng v√†o th·ª±c t·∫ø : 
	Vector ƒë·∫∑c tr∆∞ng ƒë∆∞·ª£c d√πng r·ªông r√£i v√¨ t√≠nh ch·∫•t "Gi·ªØ h∆∞·ªõng" n√†y, gi√∫p ƒë∆°n gi·∫£n h√≥a nhi·ªÅu v·∫•n ƒë·ªÅ. M·ªôt s·ªë ·ª©ng d·ª•ng quan tr·ªçng: 
		- Ph√¢n t√≠ch d·ªØ li·ªáu (PCA) : Gi·∫£m s·ªë chi·ªÅu d·ªØ li·ªáu m√† v·∫´n gi·ªØ ƒë∆∞·ª£c th√¥ng tin quan tr·ªçng. 
		- Computer Vision : Ph√°t hi·ªán c√°c khu√¥n m·∫´u ch·ªß y·∫øu trong h√¨nh ·∫£nh 
		- Google Search(Page Rank) : X·∫øp h·∫°ng trang web b·∫±ng c√°ch t√≠nh c√°c vector ƒë·∫∑c tr∆∞ng 
		

# L√†m sao ƒë·ªÉ t√≠nh ƒë∆∞·ª£c Vector ƒë·∫∑c tr∆∞ng 
	ƒê·ªÉ t√¨m vector ƒë·∫∑c tr∆∞ng v v√† gi√° tr·ªã ƒë·∫∑c tr∆∞ng ÂÖ•, b·∫°n gi·∫£i ph∆∞∆°ng tr√¨nh 
		
			det(A - ÂÖ•I) = 0 
			
		// Trong ƒë√≥: 
			-  I : Ma tr·∫≠n ƒë∆°n v·ªã 
			-  det : ƒë·ªãnh th·ª©c c·ªßa ma tr·∫≠n  
		
		Gi·∫£i ph∆∞∆°ng tr√¨nh tr√™n, b·∫°n t√¨m ra ÂÖ•(gi√° tr·ªã ƒë·∫∑c tr∆∞ng). Sau ƒë√≥, thay t·ª´ng ÂÖ• v√†o ph∆∞∆°ng tr√¨nh 
							(A - ÂÖ•I)v = 0 
						ƒê·ªÉ t√¨m c√°c vector v t∆∞∆°ng ·ª©ng  
						


# V√≠ d·ª• s·ªë : 
	
	## Cho ma tr·∫≠n   
			A =  [ [2,1] , [1,2] ]
			
		1. T√¨m vector ƒë·∫∑c tr∆∞ng  
			
			det(A - ÂÖ•I) = det(  [2-ÂÖ• , 1] , [1 , 2-ÂÖ•]  )
			-> ÂÖ•^2 -4ÂÖ• + 3 = 0 
			-> ÂÖ•1 = 3 ,  ÂÖ•2 = 1  			// 2 nghi·ªám ph√¢n bi·ªát 
			
			

		2. T√¨m vector ƒë·∫∑c tr∆∞ng : 
			-  V·ªõi ÂÖ• = 3 : 
					(A - 3I)v = 0 => [ [-1 , 1] , [ 1 , -1 ] ] . [x,y] = 0
					=> v1 = [1,1]
					
			
			- V·ªõi ÂÖ• = 1 
					(A - I) = 0 => [[1,1] , [1,1]] . [x,y] = 0 
					=> v2 = [-1 , 1]
					
	
# T√≥m t·∫Øt √Ω nghƒ©a  
	Vector ƒë·∫∑c tr∆∞ng cho bi·∫øt c√°c h∆∞·ªõng ch√≠nh c·ªßa ma tr·∫≠n ·∫£nh h∆∞·ªüng 
	Gi√° tr·ªã ƒë·∫∑c tr∆∞ng cho bi·∫øt m·ª©c ƒë·ªô ·∫£nh h∆∞·ªüng(co d√£n, ph√≥ng to )
	
	
//------------------ Vector ƒë·∫∑c tr∆∞ng(Feature Vector) Trong Machine learning 
# Kh√°i ni·ªám : 
	- Feature Vector(Vector ƒë·∫∑c tr∆∞ng) l√† m·ªôt t·∫≠p h·ª£p c√°c thu·ªôc t√≠nh(feature) c·ªßa m·ªôt ƒë·ªëi t∆∞·ª£ng, ƒë∆∞·ª£c bi·ªÉu di·ªÖn d∆∞·ªõi d·∫°ng m·ªôt vector 
	- M·ª•c ƒë√≠ch :  Feature vector d√πng ƒë·ªÉ m√¥ t·∫£ ƒë·ªëi t∆∞·ª£ng d∆∞·ªõi d·∫°ng s·ªë li·ªáu, ƒë·ªÉ m√°y t√≠nh c√≥ th·ªÉ hi·ªÉu v√† x·ª≠ l√Ω. 
	
	N√≥i c√°ch kh√°c, n√≥ l√† c√°ch ch√∫ng ta chuy·ªÉn ƒë·ªïi th√¥ng tin t·ª´ th·∫ø gi·ªõi th·ª±c nh∆∞ h√¨nh ·∫£nh, vƒÉn b·∫£n, √¢m thanh th√†nh c√°c con s·ªë m√† m√°y t√≠nh c√≥ th·ªÉ ph√¢n t√≠ch. 
	
	## T·∫°i sao c·∫ßn Feature Vector trong Machine Learning ? 
		M√°y t√≠nh kh√¥ng hi·ªÉu c√°c d·ªØ li·ªáu th√¥ nh∆∞ con ng∆∞·ªùi. V√¨ v·∫≠y, ch√∫ng ta c·∫ßn bi·ªÉu di·ªÖn d·ªØ li·ªáu d∆∞·ªõi d·∫°ng vector s·ªë, gi√∫p c√°c thu·∫≠t to√°n h·ªçc m√°y(machine learning) c√≥ th·ªÉ : 
			1. So s√°nh gi·ªØa c√°c ƒë·ªëi t∆∞·ª£ng 
			2. T√¨m ra m·ªëi quan h·ªá gi·ªØa c√°c ƒë·∫∑c tr∆∞ng 
			3. D·ª± ƒëo√°n, ph√¢n lo·∫°i, ho·∫∑c th·ª±c hi·ªán c√°c nhi·ªám v·ª• h·ªçc m√°y kh√°c. 

# V√≠ d·ª• d·ªÖ hi·ªÉu v·ªÅ Feature Vector 
	
	## V√≠ d·ª• 1: Ph√¢n lo·∫°i tr√°i c√¢y 
		Gi·∫£ s·ª≠ b·∫°n mu·ªën hu·∫•n luy·ªán m·ªôt m√¥ h√¨nh ƒë·ªÉ ph√¢n lo·∫°i tr√°i c√¢y(t√°o, cam, chu·ªëi). M·ªói tr√°i c√¢y c√≥ c√°c ƒë·∫∑c tr∆∞ng sau : 
			- Kh·ªëi l∆∞·ª£ng (gram) : 150g, 200g, 120g
			- M√†u s·∫Øc : ƒê·ªè, v√†ng , cam 
			- ƒê∆∞·ªùng k√≠nh(cm): 6cm , 7cm... 
			
		ƒê·ªÉ bi·ªÉu di·ªÖn tr√°i c√¢y d∆∞·ªõi d·∫°ng vector: 
			- Chuy·ªÉn c√°c ƒë·∫∑c tr∆∞ng th√†nh s·ªë 
				+ Kh·ªëi l∆∞·ª£ng : gi·ªØ nguy√™n 150,200 
				+ M√†u s·∫Øc : M√£ h√≥a th√†nh s·ªë(ƒë·ªè = 0 , cam = 1 , v√†ng  = 2)
				+ ƒê∆∞·ªùng k√≠nh : gi·ªØ nguy√™n 6, 7 
				
			Khi ƒë√≥ m·ªói tr√°i c√¢y ƒë∆∞·ª£c bi·ªÉu di·ªÖn nh∆∞ sau (Feature Vector)
			T√°o = [150 , 0 , 6] , Cam [200 , 1 , 7] , Chu·ªëi [120 , 2 , 5]
			
			
	# V√≠ d·ª• 2: Ph√¢n lo·∫°i email th√†nh spam hay kh√¥ng spam
			M·ªôt email c√≥ th·ªÉ ƒë∆∞·ª£c bi·ªÉu di·ªÖn b·∫±ng c√°c ƒë·∫∑c tr∆∞ng sau:
			
			S·ªë l∆∞·ª£ng t·ª´ kh√≥a "mi·ªÖn ph√≠" xu·∫•t hi·ªán: 3, 0, 1...
			S·ªë li√™n k·∫øt trong email: 5, 2, 0...
			C√≥ t·ªáp ƒë√≠nh k√®m kh√¥ng? (C√≥ = 1, Kh√¥ng = 0).
			M·ªói email s·∫Ω c√≥ Feature Vector:
					Email¬†1=[3,5,1],
					Email¬†2=[0,2,0]

  
‚Äã# ƒê·∫∑c ƒëi·ªÉm ch√≠nh c·ªßa Feature Vector: 

	1. K√≠ch th∆∞·ªõc c·ªë ƒë·ªãnh : Feature Vector ph·∫£i c√≥ s·ªë l∆∞·ª£ng ph·∫ßn t·ª≠ c·ªë ƒë·ªãnh. V√≠ d·ª•, n·∫øu c√≥ 3 ƒë·∫∑c tr∆∞ng(kh·ªëi l∆∞·ª£ng, m√†u s·∫Øc, ƒë∆∞·ªùng k√≠nh), th√¨ m·ªçi vector ƒë·ªÅu c√≥ 3 ph·∫ßn t·ª≠ 
	2. S·ªë li·ªáu h√≥a: m·ªçi ƒë·∫∑c tr∆∞ng ƒë·ªÅu ƒë∆∞·ª£c chuy·ªÉn th√†nh s·ªë(numeric) ƒë·ªÉ m√°y t√≠nh x·ª≠ l√Ω d·ªÖ d√†ng 
	3. ƒêa chi·ªÅu : M·ªôt Feature Vector c√≥ th·ªÉ l√† : 
		Vector 1 chi·ªÅu : [x1 , x2 , xn]
		
		ho·∫∑c nhi·ªÅu chi·ªÅu h∆°n (trong h√¨nh ·∫£nh, √¢m thanh )
		
Feature Vector trong c√°c lo·∫°i d·ªØ li·ªáu kh√°c nhau 
	## 1. H√¨nh ·∫£nh : 
		- M·ªói b·ª©c ·∫£nh c√≥ th·ªÉ ƒë∆∞·ª£c bi·ªÉu di·ªÖn d∆∞·ªõi d·∫°ng ma tr·∫≠n s·ªë(c√°c pixcel)
		- Feature Vector l√† c√°ch bi·ªÉu di·ªÖn c√°c th√¥ng tin ch√≠nh(m√†u s·∫Øc, h√¨nh d·∫°ng, c·∫°nh) d∆∞·ªõi d·∫°ng vector 
	
		### V√≠ d·ª• m·ªôt b·ª©c ·∫£nh 28x28 px c√≥ th·ªÉ ƒë∆∞·ª£c chuy·ªÉn th√†nh vector 784 ph·∫ßn t·ª≠ 
					Feature¬†Vector=[ 0,255,128,‚Ä¶,64]
	
	
	
	## 2. √Çm thanh  
		- D·ªØ li·ªáu √¢m thanh ƒë∆∞·ª£c bi·ªÉu di·ªÖn b·∫±ng c√°c ƒë·∫∑c tr∆∞ng nh∆∞ t·∫ßn s·ªë, bi√™n ƒë·ªô... 
		- V√≠ d·ª• : M·ªôt ƒëo·∫°n √¢m thanh ƒë∆∞·ª£c bi·ªÉu di·ªÖn b·∫±ng m·ªôt Vector nh∆∞: 
				Feature Vector = [440,100,80,0.5]
					T·∫ßn s·ªë 440Hz , Bi√™n ƒë·ªô  = 100 .... 
					
	## VƒÉn b·∫£n : 
		- VƒÉn b·∫£n ƒë∆∞·ª£c chuy·ªÉn th√†nh vector b·∫±ng c√°ch ƒë·∫øm s·ªë t·ª´ ho·∫∑c d√πng c√°c k·ªπ thu·∫≠t nh∆∞ World Embedding 
		- V√≠ d·ª• : VƒÉn b·∫£n I love AI c√≥ th·ªÉ tr·ªü th√†nh  
			Feature¬†Vector = [1,2,0,0]
			(S·ªë l∆∞·ª£ng t·ª´ "I", "love", "AI",...)


# L√†m th·∫ø n√†o ƒë·ªÉ ch·ªçn Feature t·ªët ? 

	M·ªôt Feature t·ªët c·∫ßn ph·∫£i 
		1. M√¥ t·∫£ ch√≠nh x√°c ƒë·ªëi t∆∞·ª£ng : Feature ph·∫£i ch·ª©a th√¥ng tin li√™n quan ƒë·∫øn b√†i to√°n . 
			- V√≠ d·ª• : trong b√†i to√°n ph√¢n lo·∫°i tr√°i c√¢y, m√†u s·∫Øc l√† quan tr·ªçng , nh∆∞ng s·ªë l·∫ßn tr√°i c√¢y ƒë∆∞·ª£c mua trong tu·∫ßn c√≥ th·ªÉ kh√¥ng quan tr·ªçng 
			
		2. Kh√¥ng d∆∞ th·ª´a : tr√°nh c√°c ƒë·∫∑c tr∆∞ng kh√¥ng li√™n quan ho·∫∑c g√¢y nhi·ªÅu(noise)
				-> V√≠ d·ª• trong b√†i to√°n spam email : "k√≠ch th∆∞·ªõc ph√¥ng ch·ªØ" th∆∞·ªùng kh√¥ng li√™n quan 

		3. ƒê·ªôc l·∫≠p : C√°c ƒë·∫∑c tr∆∞ng kh√¥ng n√™n ph·ª• thu·ªôc qu√° nhi·ªÅu v√†o nhau. 
		

# T√≥m l·∫°i 
	Feature vector l√† c√°ch ch√∫ng ta bi·ªÉu di·ªÖn d·ªØ li·ªáu d∆∞·ªõi d·∫°ng s·ªë ƒë·ªÉ m√°y t√≠nh c√≥ th·ªÉ hi·ªÉu v√† ph√¢n t√≠ch. N√≥ l√† m·ªôt ph·∫ßn c·ª±c k·ª≥ quan tr·ªçng trong Machine Learning v√¨ ch·∫•t l∆∞·ª£ng c·ªßa Feature vector quy·∫øt ƒë·ªãnh hi·ªáu su·∫•t c·ªßa m√¥ h√¨nh  
	
	


	
# 4. Vector t·ªëi ∆∞u h∆°n JSON/Object ·ªü ƒëi·ªÉm n√†o?
	Ti√™u ch√≠				Vector														JSON/Object
	T·ªëc ƒë·ªô x·ª≠ l√Ω			Nhanh, nh·ªù th∆∞ vi·ªán to√°n h·ªçc v√† ph·∫ßn c·ª©ng t·ªëi ∆∞u.			Ch·∫≠m h∆°n do c·∫ßn gi·∫£i m√£ c·∫•u tr√∫c v√† x·ª≠ l√Ω d·ªØ li·ªáu.
	Dung l∆∞·ª£ng l∆∞u tr·ªØ		√çt t·ªën b·ªô nh·ªõ (ch·ªâ l∆∞u s·ªë).									T·ªën b·ªô nh·ªõ do ph·∫£i l∆∞u c·∫£ c·∫•u tr√∫c (key-value).
	Thao t√°c to√°n h·ªçc		D·ªÖ d√†ng th·ª±c hi·ªán (c·ªông, nh√¢n,...)							Kh√¥ng h·ªó tr·ª£ to√°n h·ªçc tr·ª±c ti·∫øp.
	ƒê·ªìng nh·∫•t d·ªØ li·ªáu		Ph·∫£i c√≥ k√≠ch th∆∞·ªõc c·ªë ƒë·ªãnh, lo·∫°i d·ªØ li·ªáu gi·ªëng nhau.		C√≥ th·ªÉ kh√°c nhau gi·ªØa c√°c ƒë·ªëi t∆∞·ª£ng.
	Linh ho·∫°t c·∫•u tr√∫c		H·∫°n ch·∫ø (ch·ªâ s·ªë).											Linh ho·∫°t, ch·ª©a c·∫£ text, object l·ªìng nhau,...
	
//-------------------- Vector trong kh√¥ng gian chi·ªÅu cao(Hight-Dimensional Space)

# Kh√°i ni·ªám :
	Khi n√≥i ƒë·∫øn vector trong kh√¥ng gian chi·ªÅu cao (nD), h√£y t∆∞·ªüng t∆∞·ª£ng nh∆∞ ta ƒëang m√¥ ta m·ªôt ƒë·ªëi t∆∞·ª£ng b·∫±ng r·∫•t nhi·ªÅu th√¥ng tin  
		
	## V√≠ d·ª• , n·∫øu ta m√¥ ta m·ªôt ng∆∞·ªùi ta c√≥ th·ªÉ d√πng m·ªôt vector nh∆∞ sau : 
		(Tu·ªïi, C√¢n n·∫∑ng, Chi·ªÅu cao, IQ, Thu nh·∫≠p, S·ªë gi·ªù ng·ªß/ng√†y, S·ªë b∆∞·ªõc ƒëi/ng√†y, ...)
		(25, 70, 175, 110, 2000, 7, 10000, ...)	
		-> M·ªói chi·ªÅu c·ªßa vector t∆∞∆°ng ·ª©ng v·ªõi m·ªôt ƒë·∫∑c ƒëi·ªÉm c·ªßa ƒë·ªëi t∆∞·ª£ng  
		
# Vector trong to√°n h·ªçc(Kh√¥ng gian vector, ph√©p to√°n)
	
	## Bi·ªÉu di·ªÖn vector b·∫±ng ma tr·∫≠n  
		M·ªôt vector c√≥ th·ªÉ vi·∫øt d∆∞·ªõi d·∫°ng ma tr·∫≠n c·ªôt ho·∫∑c ma tr·∫≠n h√†ng : 
			Vector c·ªôt : 
				v = [3 , 4 , 5	]			//vi·∫øt theo chi·ªÅu d·ªçc 

			Vector h√†ng : 
				v = [3 , 4 , 5	]			//vi·∫øt theo chi·ªÅu ngang 
				
				
	## C√°c ph√©p to√°n v·ªõi vector 
		## C·ªông vector 
		
		## Nh√¢n vector v·ªõi s·ªë v√¥ h∆∞·ªõng 
					2 x (3,4,5) = (6,8,10)
					
		## T√≠ch v√¥ h∆∞·ªõng (dot product) - ƒëo ƒë·ªô t∆∞∆°ng ƒë·ªìng gi·ªØa 2 vector 
			
				v1.v2 = x1.x2 + y1y2 + z1z2 
							(1,2,3).(4,5,6) = 1x4 + 2x5 + 3x6 = 32 
							
# Vector trong AI 							
			


//----------------------- H·ªá ph∆∞∆°ng tr√¨nh tuy·∫øn t√≠nh 
# Trong to√°n h·ªçc :
	H·ªá ph∆∞∆°ng tr√¨nh tuy·∫øn t√≠nh l√† m·ªôt t·∫≠p h·ª£p c√°c ph∆∞∆°ng tr√¨nh tuy·∫øn t√≠nh c√≥ d·∫°ng: 
		a1x1 + a2x2 + ... + anxn = b 
		
	## Bi·ªÉu di·ªÖn b·∫±ng ma tr·∫≠n  
		Ax = b 
		
		A = [ [2,3] , [4,-1] ] 
		x = [x,y] 
		b = [8,5]
		
		
	## Gi·∫£i h·ªá ph∆∞∆°ng tr√¨nh tuy·∫øn t√≠nh  
		- Ph∆∞∆°ng ph√°p th·∫ø 
		- Ph∆∞∆°ng ph√°p c·ªông ƒë·∫°i s·ªë 
		- Ph∆∞∆°ng ph√°p ma tr·∫≠n  
			+) N·∫øu A l√† ma tr·∫≠n vu√¥ng v√† kh·∫£ ngh·ªãch(det(A) != 0) ta c√≥ th·ªÉ t√¨m nghi·ªám b·∫±ng 
					x = A^1 . b
						
						
			+) N·∫øu h·ªá c√≥ v√¥ s·ªë nghi·ªám ho·∫∑c v√¥ nghi·ªám, ph·∫£i d√πng ph∆∞∆°ng ph√°p kh√°c nh∆∞ kh·ª≠ Gauss 

			

# Trong AI 
	## ·ª®ng d·ª•ng trong Machine Learning 
		H·ªá ph∆∞∆°ng tr√¨nh tuy·∫øn t√≠nh xu·∫•t hi·ªán nhi·ªÅu trong c√°c b√†i to√°n AI, v√≠ d·ª•: 
			- H·ªìi quy tuy·∫øn t√≠nh (Linear Regression)
			- M·∫°ng n∆°-ron nh√¢n t·∫°o(Neural Networks)
			- Ph√¢n r√£ gi√° tr·ªã k·ª≥ d·ªã (SVD) trong x·ª≠ l√Ω ·∫£nh 


//------------------- !!!!!!!!!!!!!!!!!!!!!!!!!!!!!--------------------------
// CH√ö √ù : h√£y h·ªçc th√™m chi ti·∫øt c·ª• th·ªÉ v·ªÅ ph√¢n t√≠ch gi√° tr·ªã k·ª≥ d·ªã trong to√°n h·ªçc, v√† trong AI, m·ªõi ch·ªâ h·ªçc v·ªÅ kh√°i ni·ªám th√¥i ch∆∞a hi·ªÉu l·∫Øm  


//----------------------- Ph√¢n t√≠ch gi√° tr·ªã k·ª≥ d·ªã (SVD Singular Value Decomposition) trong to√°n h·ªçc 
# Kh√°i ni·ªám SVD trong to√°n h·ªçc 
	Ph√¢n r√£ gi√° tr·ªã k·ª≥ d·ªã(SVD) l√† m·ªôt c√°ch ph√¢n t√°ch m·ªôt ma tr·∫≠n th√†nh ba ma tr·∫≠n con ƒë·∫∑c bi·ªát : 
			A = U Z_ V^T    // Z_ l√† x√≠ch ma 
			
			- A : l√† ma tr·∫≠n g·ªëc(c√≥ th·ªÉ l√† b·∫•t k·ª≥ ma tr·∫≠n vu√¥ng ho·∫∑c ch·ªØ nh·∫≠t n√†o)
			- U l√† ma tr·∫≠n tr·ª±c giao(c·ªôt c·ªßa n√≥ l√† vector ƒë·∫∑c tr∆∞ng tr√°i c·ªßa A)
			- Z_ : L√† ma tr·∫≠n ƒë∆∞·ªùng ch√©o ch·ª©a c√°c gi√° tr·ªã k·ª≥ d·ªã (s·∫Øp x·∫øp theo th·ª© t·ª± gi·∫£m d·∫ßn).
			- V^T : l√† ma tr·∫≠n tr·ª±c giao(h√†ng c·ªßa n√≥ l√† vector ƒë·∫∑c tr∆∞ng ph·∫£i c·ªßa A )
	
	## √ù nghƒ©a 
		Gi·∫£m s·ªë chi·ªÅu d·ªØ li·ªáu : Ch·ªâ gi·ªØ l·∫°i c√°c gi√° tr·ªã k·ª≥ d·ªã l·ªõn nh·∫•t ƒë·ªÉ lo·∫°i b·ªè nhi·ªÖu 
		T√¨m nhanh c√°c th√†nh ph·∫ßn quan tr·ªçng nh·∫•t trong d·ªØ li·ªáu(d√πng trong PCA - Principal Component Analysis )
		X·∫•p x·ªâ ma tr·∫≠n : N·∫øu ta ch·ªâ gi·ªØ v√†i gi√° tr·ªã k·ª≥ d·ªã l·ªõn nh·∫•t, ta c√≥ th·ªÉ x·∫•p x·ªâ ma tr·∫≠n g·ªëc v·ªõi ma tr·∫≠n nh·ªè h∆°n 
		
		V√≠ d·ª•, n·∫øu A l√† ma tr·∫≠n 1000x1000 nh∆∞ng ch·ªâ c√≥ 10 gi√° tr·ªã k·ª≥ d·ªã l·ªõn, ta c√≥ th·ªÉ d√πng ma tr·∫≠n 1000x10 thay v√¨ 1000x1000 gi√∫p ti·∫øt ki·ªám kh√¥ng gian l∆∞u tr·ªØ v√† t√≠nh to√°n  
	
	
# H√¨nh dung tr·ª±c quan 
		### V√≠ d·ª• : H√¨nh dung m·ªôt ma tr·∫≠n l√†m bi·∫øn d·∫°ng ·∫£nh 
		
		H√£y t∆∞·ªüng t∆∞·ª£ng b·∫°n c√≥ m·ªôt t·∫•m ·∫£nh v√† mu·ªën n√©n ·∫£nh m√† v·∫´n gi·ªØ l·∫°i n·ªôi dung quan tr·ªçng 
			- B∆∞·ªõc 1 : Chuy·ªÉn ·∫£nh th√†nh m·ªôt ma tr·∫≠n A( m·ªói √¥ l√† gi√° tr·ªã pixel)
			- B∆∞·ªõc 2 : D√πng SVD ƒë·ªÉ ph√¢n r√£ A th√†nh U, Z_ , V^T 
			- B∆∞·ªõc 3 :  Gi·ªØ l·∫°i m·ªôt s·ªë √≠t gi√° tr·ªã trong Z_, b·ªè b·ªõt nh·ªØng gi√° tr·ªã nh·ªè h∆°n 
			- B∆∞·ªõc 4 : Nh√¢n l·∫°i c√°c ma tr·∫≠n, thu ƒë∆∞·ª£c h√¨nh ·∫£nh ƒë√£ gi·∫£m dung l∆∞·ª£ng nh∆∞ng v·∫´n gi·ªØ ƒë∆∞·ª£c n·ªôi dung ch√≠nh  
			
		-> ƒêi·ªÅu n√†y gi·ªëng nh∆∞ b·∫°n ƒëang chuy·ªÉn ƒë·ªïi m·ªôt h√¨nh ·∫£nh th√†nh c√°c l·ªõp th√¥ng tin ch√≠nh, gi·ªëng nh∆∞ v·∫Ω ph√°c th·∫£o thay v√¨ v·∫Ω to√†n b·ªô chi ti·∫øt nh·ªè 
		H√¨nh ·∫£nh sau khi x·ª≠ l√Ω tr√¥ng c√≥ v·∫ª gi·ªëng ·∫£nh g·ªëc nh∆∞ng th·ª±c t·∫ø ƒë√£ b·ªã gi·∫£m s·ªë chi·ªÅu d·ªØ li·ªáu, gi√∫p x·ª≠ l√Ω nhanh h∆°n trong AI 
		
# V√≠ d·ª• to√°n h·ªçc 
	
	
		
//----------------------- Ph√¢n t√≠ch gi√° tr·ªã k·ª≥ d·ªã (SVD Singular Value Decomposition) trong machine learning 
			
			
//------------------------ Vector ƒë·∫∑c tr∆∞ng ph·∫£i , Vector ƒë·∫∑c tr∆∞ng tr√°i 
# Vector ƒë·∫∑c tr∆∞ng tr√°i (U)
	## ƒê·ªãnh nghƒ©a : 
		Vector ƒë·∫∑c tr∆∞ng tr√°i l√† c√°c c·ªôt c·ªßa ma tr·∫≠n U 
	
	## Vai tr√≤ : 
		Ch√∫ng th·ªÉ hi·ªán c√°ch d·ªØ li·ªáu g·ªëc b·ªã k√©o d√†i ho·∫∑c n√©n theo h√†ng c·ªßa ma tr·∫≠n A 
		
	## √ù nghƒ©a : 
		N·∫øu ta coi ma tr·∫≠n A l√† m·ªôt h·ªá th·ªëng bi·∫øn ƒë·ªïi d·ªØ li·ªáu, th√¨ vector ƒë·∫∑c tr∆∞ng tr√°i cho ta bi·∫øt h∆∞·ªõng ch√≠nh c·ªßa d·ªØ li·ªáu trong kh√¥ng gian h√†ng  . 
		
	## V√≠ d·ª• d·ªÖ h√¨nh dung  	
		H√£y t∆∞·ªüng t∆∞·ª£ng b·∫°n c√≥ m·ªôt b·ªô s∆∞u t·∫≠p h√¨nh ·∫£nh. M·ªói h√¨nh l√† m·ªôt h√†ng c·ªßa ma tr·∫≠n A. C√°c vector ƒë·∫∑c tr∆∞ng tr√°i s·∫Ω cho ta bi·∫øt c√°c m·∫´u ch√≠nh c·ªßa h√¨nh ·∫£nh ƒë√≥, t·ª©c l√† nh·ªØng ƒë·∫∑c ƒëi·ªÉm quan tr·ªçng nh·∫•t trong t·ª´ng h√†ng. 
		
		·ª®ng d·ª•ng trong AI: Vector ƒë·∫∑c tr∆∞ng tr√°i th∆∞·ªùng ƒë∆∞·ª£c d√πng trong gi·∫£m s·ªë chi·ªÅu d·ªØ li·ªáu (PCA,LSA trong NLP, x·ª≠ l√Ω ·∫£nh , vv)
		
		
# Vector ƒë·∫∑c tr∆∞ng ph·∫£i 
	## ƒê·ªãnh nghƒ©a : 
		Vector ƒë·∫∑c tr∆∞ng ph·∫£i l√† c√°c c·ªôt c·ªßa ma tr·∫≠n V(ho·∫∑c c√°c h√†ng c·ªßa V^T)
		
	## Vai tr√≤ : 
		Ch√∫ng th·ªÉ hi·ªán c√°ch d·ªØ li·ªáu g·ªëc b·ªã k√©o d√†i ho·∫∑c n√©n theo c·ªôt c·ªßa ma tr·∫≠n A 
		
	## √ù nghƒ©a :  
		N·∫øu ta coi ma tr·∫≠n A l√† m·ªôt ph√©p bi·∫øn ƒë·ªïi, th√¨ vector ƒë·∫∑c tr∆∞ng ph·∫£i cho ta bi·∫øt h∆∞·ªõng ch√≠nh c·ªßa d·ªØ li·ªáu trong kh√¥ng gian c·ªôt 
		
	## V√≠ d·ª• h√¨nh dung 
		N·∫øu ta coi ma tr·∫≠n A ch·ª©a d·ªØ li·ªáu v·ªÅ ng∆∞·ªùi d√πng v√† phim, trong ƒë√≥: 
			- H√†ng l√† ng∆∞·ªùi d√πng 
			- C·ªôt l√† phim 
			
		Khi √°p d·ª•ng SVD, c√°c vector ƒë·∫∑c tr∆∞ng ph·∫£i cho ta bi·∫øt m·ªëi quan h·ªá gi·ªØa c√°c b·ªô phim t·ª©c l√† c√°c phim c√≥ ƒë·∫∑c ƒëi·ªÉm gi·ªëng nhau s·∫Ω c√≥ vector ƒë·∫∑c tr∆∞ng ph·∫£i t∆∞∆°ng t·ª± nhau . 
		·ª®ng d·ª•ng trong AI : Vector ƒë·∫∑c tr∆∞ng ph·∫£i r·∫•t quan tr·ªçng trong h·ªá th·ªëng g·ª£i √Ω (Recommendation Systems), gi√∫p ƒë·ªÅ xu·∫•t phim, nh·∫°c, s·∫£n ph·∫©m cho ng∆∞·ªùi d√πng. 
		
	
# So s√°nh Vector ƒë·∫∑c tr∆∞ng tr√°i v√† Vector ƒë·∫∑c tr∆∞ng ph·∫£i 

Ti√™u ch√≠ 						Vector ƒë·∫∑c tr∆∞ng tr√°i(U) 							Vector ƒë·∫∑c tr∆∞ng ph·∫£i(V)
	
V·ªã tr√≠ trong SVD					C·ªôt c·ªßa U										C·ªôt c·ªßa V (ho·∫∑c h√†ng c·ªßa V^T)
Bi·ªÉu di·ªÖn d·ªØ li·ªáu theo				H√†ng c·ªßa ma tr·∫≠n A								C·ªôt c·ªßa ma tr·∫≠n A 
√ù nghƒ©a								ƒê·∫∑c tr∆∞ng ch√≠nh c·ªßa h√†ng d·ªØ li·ªáu				ƒê·∫∑c tr∆∞ng ch√≠nh c·ªßa c·ªôt d·ªØ li·ªáu
·ª®ng d·ª•ng							Gi·∫£m s·ªë chi·ªÅu d·ªØ li·ªáu (PCA, x·ª≠ l√Ω ·∫£nh, NLP)		H·ªá th·ªëng g·ª£i √Ω, ph√¢n c·ª•m d·ªØ li·ªáu


# H√¨nh dung tr·ª±c quan 

		H√£y t∆∞·ªüng t∆∞·ª£ng m·ªôt b·ª©c ·∫£nh l√† m·ªôt ma tr·∫≠n A
		üì∑ B·ª©c ·∫£nh = Ma tr·∫≠n A (g·ªìm c√°c pixel)
		
		Vector ƒë·∫∑c tr∆∞ng tr√°i gi·ªëng nh∆∞ b·∫£n ph√°c th·∫£o c·ªßa b·ª©c ·∫£nh theo t·ª´ng h√†ng, gi√∫p gi·ªØ l·∫°i nh·ªØng n√©t ch√≠nh c·ªßa b·ª©c ·∫£nh.
		Vector ƒë·∫∑c tr∆∞ng ph·∫£i gi·ªëng nh∆∞ b·∫£n ph√°c th·∫£o c·ªßa b·ª©c ·∫£nh theo t·ª´ng c·ªôt, gi√∫p gi·ªØ l·∫°i th√¥ng tin theo chi·ªÅu d·ªçc.
		Khi b·∫°n gi·∫£m s·ªë chi·ªÅu d·ªØ li·ªáu b·∫±ng SVD, b·∫°n th·ª±c ch·∫•t ƒëang gi·ªØ l·∫°i nh·ªØng th√†nh ph·∫ßn quan tr·ªçng nh·∫•t c·ªßa b·ª©c ·∫£nh.

# K·∫øt lu·∫≠n 
		
	## Vector ƒë·∫∑c tr∆∞ng tr√°i(U)  gi√∫p hi·ªÉu v·ªÅ d·ªØ li·ªáu theo h∆∞·ªõng h√†ng(ƒë·ªëi t∆∞·ª£ng ch√≠nh trong t·∫≠p d·ªØ li·ªáu)
	
	## Vector ƒë·∫∑c tr∆∞ng ph·∫£i(V) gi√∫p hi·ªÉu v·ªÅ d·ªØ li·ªáu theo h∆∞·ªõng c·ªôt(m·ªëi quan h·ªá gi·ªØa c√°c thu·ªôc t√≠nh d·ªØ li·ªáu)
	
	## SVD l√† c√¥ng c·ª• c·ª±c k·ª≥ m·∫°nh trong AI, d√πng ƒë·ªÉ gi·∫£m s·ªë chi·ªÅu, t√¨m ƒë·∫∑c tr∆∞ng quan tr·ªçng, v√† ph√°t hi·ªán quan h·ªá gi·ªØa c√°c th√†nh ph·∫ßn d·ªØ li·ªáu 
	
	Gi·∫£m chi·ªÅu d·ªØ li·ªáu c√≥ th·ªÉ h√¨nh dung gi·ªëng nh∆∞ ·∫£nh to√†n k√Ω (hologram),
	
	## H√¨nh dung v·ªÅ ·∫¢nh To√†n K√Ω vs. Gi·∫£m Chi·ªÅu D·ªØ Li·ªáu
			### ·∫¢nh to√†n k√Ω (hologram):
		
				Khi nh√¨n t·ª´ nhi·ªÅu g√≥c ƒë·ªô kh√°c nhau, b·∫°n v·∫´n th·∫•y to√†n b·ªô v·∫≠t th·ªÉ, d√π m·ªói g√≥c nh√¨n ch·ªâ ch·ª©a m·ªôt ph·∫ßn th√¥ng tin.
				T√≠nh ch·∫•t: M·∫•t m·ªôt ph·∫ßn d·ªØ li·ªáu nh∆∞ng v·∫´n c√≥ th·ªÉ t√°i t·∫°o h√¨nh ·∫£nh g·∫ßn ƒë√∫ng c·ªßa v·∫≠t th·ªÉ.
			### Gi·∫£m chi·ªÅu d·ªØ li·ªáu (Dimensionality Reduction):
		
				B·∫°n n√©n to√†n b·ªô d·ªØ li·ªáu g·ªëc th√†nh m·ªôt d·∫°ng ƒë∆°n gi·∫£n h∆°n, nh∆∞ng v·∫´n gi·ªØ ƒë∆∞·ª£c nh·ªØng ƒë·∫∑c ƒëi·ªÉm quan tr·ªçng nh·∫•t.
				T√≠nh ch·∫•t: Lo·∫°i b·ªè th√¥ng tin d∆∞ th·ª´a ho·∫∑c nhi·ªÖu, nh∆∞ng v·∫´n gi·ªØ ƒë∆∞·ª£c c·∫•u tr√∫c ch√≠nh.
				
				
					üí° ƒêi·ªÉm t∆∞∆°ng ƒë·ªìng:
					C·∫£ hai ƒë·ªÅu c·ªë g·∫Øng gi·ªØ l·∫°i th√¥ng tin quan tr·ªçng nh·∫•t v·ªõi d·ªØ li·ªáu √≠t h∆°n.
					Khi b·∫°n gi·∫£m s·ªë chi·ªÅu c·ªßa d·ªØ li·ªáu AI, n√≥ v·∫´n gi·ªØ ƒë∆∞·ª£c ph·∫ßn l·ªõn √Ω nghƒ©a c·ªßa d·ªØ li·ªáu g·ªëc, gi·ªëng nh∆∞ c√°ch m·ªôt ·∫£nh to√†n k√Ω v·∫´n hi·ªÉn th·ªã ƒë∆∞·ª£c v·∫≠t th·ªÉ t·ª´ nhi·ªÅu g√≥c ƒë·ªô.
					
					
					üí° ƒêi·ªÉm kh√°c bi·ªát:
					·∫¢nh to√†n k√Ω l∆∞u th√¥ng tin theo d·∫°ng t·∫ßn s·ªë √°nh s√°ng v√† v·∫´n ch·ª©a g·∫ßn nh∆∞ to√†n b·ªô d·ªØ li·ªáu, ch·ªâ l√† b·ªã ph√¢n b·ªë kh√°c ƒëi.
					Gi·∫£m chi·ªÅu d·ªØ li·ªáu trong AI (nh∆∞ PCA, SVD) th·ª±c s·ª± lo·∫°i b·ªè d·ªØ li·ªáu √≠t quan tr·ªçng, ch·ª© kh√¥ng ch·ªâ ph√¢n b·ªë l·∫°i n√≥.
					
					
					üìå V√≠ d·ª• Tr·ª±c Quan
					üñº Gi·∫£ s·ª≠ b·∫°n c√≥ m·ªôt ·∫£nh ƒëen tr·∫Øng 1000x1000 pixel (1 tri·ªáu ƒëi·ªÉm ·∫£nh).
					
						N·∫øu ch·ª•p ·∫£nh to√†n k√Ω:
							B·ª©c ·∫£nh c√≥ th·ªÉ ƒë∆∞·ª£c l∆∞u tr·ªØ d∆∞·ªõi d·∫°ng s√≥ng √°nh s√°ng v√† t√°i t·∫°o t·ª´ nhi·ªÅu g√≥c nh√¨n, nh∆∞ng th√¥ng tin kh√¥ng b·ªã m·∫•t ƒëi nhi·ªÅu.
							
						N·∫øu d√πng gi·∫£m chi·ªÅu d·ªØ li·ªáu:
							Gi·∫£ s·ª≠ b·∫°n √°p d·ª•ng SVD v√† gi·ªØ l·∫°i ch·ªâ 100 th√†nh ph·∫ßn quan tr·ªçng nh·∫•t, b·ª©c ·∫£nh c√≥ th·ªÉ gi·∫£m xu·ªëng ch·ªâ c√≤n 100x100 pixel, nh∆∞ng v·∫´n ƒë·ªß r√µ ƒë·ªÉ nh·∫≠n di·ªán n·ªôi dung ch√≠nh.
					
					üìå ·ª®ng d·ª•ng th·ª±c t·∫ø:
						X·ª≠ l√Ω ·∫£nh: Khi gi·∫£m chi·ªÅu d·ªØ li·ªáu, AI c√≥ th·ªÉ l√†m m·ªù c√°c chi ti·∫øt nh·ªè kh√¥ng quan tr·ªçng nh∆∞ng v·∫´n gi·ªØ ƒë∆∞·ª£c n·ªôi dung ch√≠nh.
						Nh·∫≠n d·∫°ng khu√¥n m·∫∑t: AI c√≥ th·ªÉ l∆∞u tr·ªØ ch·ªâ nh·ªØng ƒë·∫∑c ƒëi·ªÉm quan tr·ªçng nh·∫•t, thay v√¨ ghi nh·ªõ to√†n b·ªô h√¨nh ·∫£nh chi ti·∫øt.
						
					ü§î K·∫øt Lu·∫≠n
						‚úî Gi·∫£m chi·ªÅu d·ªØ li·ªáu c√≥ th·ªÉ ƒë∆∞·ª£c so s√°nh v·ªõi ·∫£nh to√†n k√Ω ·ªü kh√≠a c·∫°nh c·ªë g·∫Øng gi·ªØ l·∫°i th√¥ng tin quan tr·ªçng b·∫±ng c√°ch gi·∫£m l∆∞·ª£ng d·ªØ li·ªáu c·∫ßn l∆∞u tr·ªØ.
						‚úî Nh∆∞ng AI th·ª±c s·ª± lo·∫°i b·ªè d·ªØ li·ªáu √≠t quan tr·ªçng, trong khi hologram ph√¢n ph·ªëi l·∫°i th√¥ng tin theo m·ªôt c√°ch kh√°c.
						‚úî Hi·ªÉu c√°ch n√†y s·∫Ω gi√∫p b·∫°n d·ªÖ d√†ng n·∫Øm b·∫Øt vai tr√≤ c·ªßa gi·∫£m s·ªë chi·ªÅu trong AI! 	
			



//------------------------ Kh√¥ng gian vector trong h·ªçc m√°y  			



	 ## . T·∫°i sao to√†n b·ªô AI ƒë·ªÅu s·ª≠ d·ª•ng Vector?
		
		Nh√¢n vector v·ªõi tr·ªçng s·ªë.
		T√≠nh kho·∫£ng c√°ch (Euclidean, cosine).
		T·ªëi ∆∞u h√†m m·∫•t m√°t (loss function).


//---------------------------- √Ånh x·∫° tuy·∫øn t√≠nh (Linear Mapping)

# ƒê·ªãnh nghƒ©a 
	√Ånh x·∫° tuy·∫øn t√≠nh l√† m·ªôt ph√©p bi·∫øn ƒë·ªïi t·ª´ m·ªôt kh√¥ng gian vector sang m·ªôt kh√¥ng gian vector kh√°c m√† v·∫´n gi·ªØ nguy√™n c·∫•u tr√∫c tuy·∫øn t√≠nh, N√≥i ƒë∆°n gi·∫£n n√≥ l√† m·ªôt h√†m bi·∫øn ƒë·ªïi vector nh∆∞ng v·∫´n b·∫£o to√†n ph√©p c·ªông v√† nh√¢n v√¥ h∆∞·ªõng 
	
	N·∫øu c√≥ m·ªôt √°nh x·∫° T t·ª´ kh√¥ng gian vector V sang W, th√¨ T l√† √°nh x·∫° tuy·∫øn t√≠nh n·∫øu th·ªèa m√£n  
	
	1. B·∫£o to√†n ph√©p c·ªông  
			T (u + v) = T(u) + T(v)
			
	2. B·∫£o to√†n ph√©p nh√¢n v√¥ h∆∞·ªõng  
			T(cv) = cT(v) (v·ªõi m·ªçi s·ªë th·ª±c C )
			
			
			
# H√¨nh dung tr·ª±c quan 
	H√£y t∆∞·ªüng t∆∞·ª£ng √°nh x·∫° tuy·∫øn t√≠nh c≈©ng gi·ªëng nh∆∞ m·ªôt b·ªô l·ªçc ·∫£nh. Khi b·∫°n √°p d·ª•ng b·ªô l·ªçc l√™n ·∫£nh, ·∫£nh s·∫Ω b·ªã thay ƒë·ªïi m√†u s·∫Øc, ƒë·ªô s√°ng nh∆∞ng c√°c ƒë∆∞·ªùng n√©t v·∫´n gi·ªØ nguy√™n 
	
	V√≠ d·ª• : 
		M·ªôt √°nh x·∫° tuy·∫øn t√≠nh c√≥ th·ªÉ ph√≥ng to ho·∫∑c thu nh·ªè vector, nh∆∞ng kh√¥ng l√†m cong n√≥ 
		
		M·ªôt ph√©p quay(rotation) c≈©ng l√† m·ªôt √°nh x·∫° tuy·∫øn t√≠nh 
	

	## Li√™n h·ªá v·ªõi Java 
	Trong Java, ta c√≥ th·ªÉ bi·ªÉu di·ªÖn √°nh x·∫° tuy·∫øn t√≠nh nh∆∞ m·ªôt ph∆∞∆°ng th·ª©c nh·∫≠n v√†o m·ªôt vector v√† tr·∫£ v·ªÅ m·ªôt vector m·ªõi. V√≠ d·ª•:
			public class LinearTransformation {
			private double[][] matrix; // Ma tr·∫≠n √°nh x·∫° tuy·∫øn t√≠nh
		
			public LinearTransformation(double[][] matrix) {
				this.matrix = matrix;
			}
		
			public double[] apply(double[] vector) {
				if (vector.length != matrix[0].length) {
					throw new IllegalArgumentException("Vector size must match matrix columns");
				}
				double[] result = new double[matrix.length];
				for (int i = 0; i < matrix.length; i++) {
					for (int j = 0; j < vector.length; j++) {
						result[i] += matrix[i][j] * vector[j];
					}
				}
				return result;
			}
		
			public static void main(String[] args) {
				double[][] transformationMatrix = {
					{2, 0},
					{0, 3}
				};
				LinearTransformation transformation = new LinearTransformation(transformationMatrix);
		
				double[] vector = {1, 1};
				double[] transformedVector = transformation.apply(vector);
		
				System.out.println("Transformed Vector: [" + transformedVector[0] + ", " + transformedVector[1] + "]");
			}
		}


//----------------------- C∆° s·ªü (Basis )
# Kh√°i ni·ªám 

	C∆° s·ªü c·ªßa m·ªôt kh√¥ng gian vector l√† m·ªôt t·∫≠p h·ª£p c√°c vector ƒë·ªôc l·∫≠p tuy·∫øn t√≠nh c√≥ th·ªÉ bi·ªÉu di·ªÖn t·∫•t c·∫£ c√°c vector trong kh√¥ng gian ƒë√≥. 
	N√≥i c√°ch kh√°c, c∆° s·ªü l√† m·ªôt "b·ªô khung" gi√∫p x√¢y d·ª±ng to√†n b·ªô kh√¥ng gian vector  

	N√≥ ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ chuy·ªÉn ƒë·ªïi gi·ªØa c√°c h·ªá t·ªça ƒë·ªô kh√°c nhau 

# H√¨nh dung tr·ª±c quan  

	H√£y t∆∞·ªüng t∆∞·ª£ng b·∫°n ƒëang x√¢y m·ªôt ng√¥i nh√† b·∫±ng g·∫°ch. M·ªói vi√™n g·∫°ch l√† m·ªôt vector c∆° s·ªü, v√† b·∫°n c√≥ th·ªÉ k·∫øt h·ª£p c√°c vi√™n g·∫°ch theo nhi·ªÅu c√°ch kh√°c nhau ƒë·ªÉ t·∫°o ra c√°c b·ª©c t∆∞·ªùng kh√°c nhau  

	## V√≠ d·ª• trong kh√¥ng gian 2D, c√°c vector c∆° s·ªü ph·ªï bi·∫øn nh·∫•t l√† : 
			e1 = (1,0)  , e2 =(0,1)
			
	## M·ªçi vector trong kh√¥ng gian 2D c√≥ th·ªÉ ƒë∆∞·ª£c bi·ªÉu di·ªÖn b·∫±ng t·ªï h·ª£p tuy·∫øn t√≠nh c·ªßa hai vector n√†y 
			
			(3,4) = 3(1,0) + 4(0,1)


# Li√™n h·ªá v·ªõi Java l·∫≠p tr√¨nh 
	Trong l·∫≠p tr√¨nh, m·ªôt t·∫≠p h·ª£p vector c∆° s·ªü gi·ªëng nh∆∞ m·ªôt t·∫≠p c√°c class tr·ª´u t∆∞·ª£ng(abstract class). M·ªçi vector trong kh√¥ng gian c√≥ th·ªÉ coi l√† instance c·ªßa nh·ªØng class n√†y  
	
	
	
//------------------------------ H·ªá s·ªë ma tr·∫≠n(Matrix Coefficients)

# ƒê·ªãnh nghƒ©a 
	H·ªá s·ªë ma tr·∫≠n ch√≠nh l√† c√°c gi√° tr·ªã trong ma tr·∫≠n, quy·∫øt ƒë·ªãnh c√°ch √°nh x·∫° tuy·∫øn t√≠nh bi·∫øn ƒë·ªïi vector 
		
		V√≠ d·ª• v·ªõi ma tr·∫≠n 
					A = [ [2 , -1 ] , [0 , 3]]
					
				S·ªë 2 l√† h·ªá s·ªë t·∫°i h√†ng 1 c·ªôt 1 
				S·ªë -1 l√† h·ªá s·ªë t·∫°i h√†ng 1 c·ªôt 2 
				
	=> H·ªá s·ªë ma tr·∫≠n c√≥ th·ªÉ hi·ªÉu l√† tr·ªçng s·ªë c·ªßa √°nh x·∫° tuy·∫øn t√≠nh 
	
	
//------------------------------ Ma tr·∫≠n chuy·ªÉn ƒë·ªïi(Change of Basis Matrix)	

# ƒê·ªãnh nghƒ©a 
	Ma tr·∫≠n chuy·ªÉn ƒë·ªïi l√† ma tr·∫≠n gi√∫p chuy·ªÉn t·ª´ h·ªá t·ªça ƒë·ªô n√†y sang h·ªá t·ªça ƒë·ªô kh√°c 
	N·∫øu ta c√≥ m·ªôt kh√¥ng gian v·ªõi c∆° s·ªü B = {b1, b2} v√† m·ªôt kh√¥ng gian kh√°c v·ªõi c∆° s·ªü C = {c1 , c2}, ta c√≥ th·ªÉ d√πng ma tr·∫≠n chuy·ªÉn ƒë·ªïi P ƒë·ªÉ ƒë·ªïi t·ª´ h·ªá n√†y sang h·ªá kia : 
			vc = Pvb 
			
		trong ƒë√≥ 
			vb : l√† vector trong h·ªá c∆° s·ªü B 
			P : l√† ma tr·∫≠n chuy·ªÉn ƒë·ªïi 
			vc : L√† vector trong h·ªá c∆° s·ªü C  

# ·ª®ng d·ª•ng 
	Chuy·ªÉn ƒë·ªïi gi·ªØa c√°c h·ªá t·ªça ƒë·ªô kh√°c nhau 
	√Åp d·ª•ng trong ƒë·ªì h·ªça m√°y t√≠nh v√† AI  
	
#T√≥m l·∫°i
	√Ånh x·∫° tuy·∫øn t√≠nh gi√∫p bi·∫øn ƒë·ªïi vector nh∆∞ng v·∫´n gi·ªØ t√≠nh ch·∫•t tuy·∫øn t√≠nh.
	C∆° s·ªü l√† "khung x∆∞∆°ng" c·ªßa kh√¥ng gian vector.
	H·ªá s·ªë ma tr·∫≠n l√† c√°c s·ªë quy·∫øt ƒë·ªãnh c√°ch √°nh x·∫° ho·∫°t ƒë·ªông.
	Ma tr·∫≠n chuy·ªÉn ƒë·ªïi gi√∫p ƒë·ªïi t·ª´ h·ªá c∆° s·ªü n√†y sang h·ªá c∆° s·ªü kh√°c.


‚úÖ Gi·∫£m chi·ªÅu d·ªØ li·ªáu & PCA (Principal Component Analysis): Hi·ªÉu PCA s·∫Ω gi√∫p b·∫°n th·∫•y ·ª©ng d·ª•ng th·ª±c t·∫ø c·ªßa SVD d·ªÖ d√†ng h∆°n.

üìå Sau khi n·∫Øm ch·∫Øc c√°c kh√°i ni·ªám tr√™n, vi·ªác h·ªçc SVD s·∫Ω tr·ªü n√™n d·ªÖ d√†ng h∆°n v√¨ b·∫°n ƒë√£ c√≥ n·ªÅn t·∫£ng v·ªØng ch·∫Øc.


		

//----------------------- Gi·∫£m chi·ªÅu d·ªØ li·ªáu (Dimensionality Redution)
# Kh√°i ni·ªám  
	Gi·∫£m chi·ªÅu d·ªØ li·ªáu l√† qu√° tr√¨nh gi·∫£m s·ªë l∆∞·ª£ng bi·∫øn(features) trong m·ªôt t·∫≠p h·ª£p d·ªØ li·ªáu m√† v·∫´n gi·ªØ l·∫°i c√†ng nhi·ªÅu th√¥ng tin quan tr·ªçng c√†ng t·ªët. Vi·ªác n√†y gi√∫p 
		- Gi·∫£m ƒë·ªô ph·ª©c t·∫°p t√≠nh to√°n 
		- Gi·∫£m nguy c∆° overfitting 
		- D·ªÖ tr·ª±c quan h√≥a d·ªØ li·ªáu h∆°n (nh·∫•t l√† khi d·ªØ li·ªáu >3 chi·ªÅu )
		- C·∫£i thi·ªán hi·ªáu su·∫•t m√¥ h√¨nh AI 
		
//-------- Gi·∫£m chi·ªÅu trong to√°n cao c·∫•p 
# 2.1 Ma tr·∫≠n v√† √°nh x·∫° tuy·∫øn t√≠nh trong gi·∫£m chi·ªÅu 
	M·ªôt t·∫≠p d·ªØ li·ªáu c√≥ th·ªÉ ƒë∆∞·ª£c bi·ªÉu di·ªÖn d∆∞·ªõi d·∫°ng ma tr·∫≠n X thu·ªôc R^(m.n), trong ƒë√≥ 
		m : l√† s·ªë m·∫´u (s·ªë h√†ng)
		n : l√† s·ªë chi·ªÅu(s·ªë c·ªôt =  s·ªë feature)
		
	B·∫£n ch·∫•t c·ªßa gi·∫£m chi·ªÅu l√† t√¨m m·ªôt √°nh x·∫° tuy·∫øn t√≠nh T : R^n -> R^k v·ªõi k < n sao cho gi·ªØ l·∫°i c√†ng nhi·ªÅu th√¥ng tin c√†ng t·ªët . 
	
	ƒêi·ªÅu n√†y li√™n quan ƒë·∫øn kh√¥ng gian con(subspace) trong kh√¥ng gian vector : 
	Thay v√¨ l√†m vi·ªác v·ªõi kh√¥ng gian g·ªëc R^n , ta t√¨m m·ªôt kh√¥ng gian con R^k c√≥ th·ªÉ m√¥ t·∫£ d·ªØ li·ªáu t·ªët nh·∫•t 
	
# 2.2 C√°c ph∆∞∆°ng ph√°p to√°n h·ªçc ch√≠nh  
	
	## PCA  - Ph√¢n t√≠ch th√†nh ph·∫ßn ch√≠nh(Principal Component Analysis )
		
		### √ù t∆∞·ªüng : PCA t√¨m c√°c tr·ª•c ch√≠nh(principal components) sao cho ƒë·∫øn khi chi·∫øu d·ªØ li·ªáu l√™n ch√∫ng, ta gi·ªØ ƒë∆∞·ª£c ph·∫ßn l·ªõn ph∆∞∆°ng sai d·ªØ c·ªßa d·ªØ li·ªáu .
		
		### C√°ch l√†m :	 
			1. Chu·∫©n h√≥a d·ªØ li·ªáu(mean = 0)
			2. T√≠nh ma tr·∫≠n hi·ªáp ph∆∞∆°ng sai S = 1/m . X^T X 								<* C·∫ßn t√¨m hi·ªÉu th√™m >
			3. T√≠nh vector ri√™ng(eigenvectors) v√† gi√° tr·ªã ri√™ng(eigenvalues) c·ªßa S  		<* C·∫ßn t√¨m hi·ªÉu th√™m >
			4. Ch·ªçn k vector ri√™ng c√≥ gi√° tr·ªã ri√™ng l·ªõn nh·∫•t ƒë·ªÉ t·∫°o kh√¥ng gian m·ªõi 
			
		C√¥ng th·ª©c √°nh x·∫° d·ªØ li·ªáu sang kh√¥ng gian gi·∫£m chi·ªÅu : 
			Z = X.Wk  
			
			X : L√† d·ªØ li·ªáu g·ªëc 
			Wk : l√† ma tr·∫≠n ch·ª©a k vector ri√™ng l·ªõn nh·∫•t 
			
			
	## SVD  - Ph√¢n t√≠ch gi√° tr·ªã k·ª≥ d·ªã(Singular Value Decomposition)
		SVD ph√¢n r√£ m·ªôt ma tr·∫≠n th√†nh ba ma tr·∫≠n kh√°c : 
			X = U. Z_ . V^t 
			
			Y v√† V l√† ma tr·∫≠n tr·ª±c giao 
			Z_ ch·ª©a c√°c gi√° tr·ªã k·ª≥ d·ªã s·∫Øp x·∫øp gi·∫£m d·∫ßn 
			
		-> Gi·ªØ l·∫°i k gi√° tr·ªã k·ª≥ d·ªã l·ªõn nh·∫•t v√† lo·∫°i b·ªè ph·∫ßn c√≤n l·∫°i gi√∫p gi·∫£m chi·ªÅu d·ªØ li·ªáu. 	
		-> PCA th·ª±c ch·∫•t l√† m·ªôt tr∆∞·ªùng h·ª£p ƒë·∫∑c bi·ªát c·ªßa SVD 
	
			
			
	## T-SNE & UMAP -  Gi·∫£m chi·ªÅu phi tuy·∫øn  
	
		PCA v√† SVD l√† tuy·∫øn t√≠nh. nh∆∞ng c√≥ nh·ªØng k·ªπ thu·∫≠t gi·∫£m chi·ªÅu phi tuy·∫øn m·∫°nh h∆°n nh∆∞ : 
			- T-SNE (t-Distributed Stochastic Neighbor Embedding): D√πng ph√¢n b·ªë x√°c su·∫•t ƒë·ªÉ b·∫£o to√†n c·∫•u tr√∫c d·ªØ li·ªáu 
			
			- UMAP (Uniform Manifold Approximation and Projection): Hi·ªáu qu·∫£ h∆°n T-SINE khi l√†m vi·ªác v·ªõi d·ªØ li·ªáu l·ªõn  
			

//--------------------- Gi·∫£m chi·ªÅu trong l·∫≠p tr√¨nh AI 
# S·ª≠ d·ª•ng th∆∞ vi·ªán Python h·ªó tr·ª£ 

	- Scikit-learn: PCA, TruncatedSVD ,  TSNE 
	- TensorFlow/Pytorch : D√πng SVD ho·∫∑c Autoencoder 
	
# Code minh h·ªça PCA trong Python 
		Gi·∫£ s·ª≠ ta c√≥ d·ªØ li·ªáu ng·∫´u nhi√™n t·ª´ 3 chi·ªÅu mu·ªën gi·∫£m xu·ªëng 2 chi·ªÅu  
		

Ph∆∞∆°ng ph√°p					Tuy·∫øn t√≠nh / Phi tuy·∫øn					Khi n√†o d√πng?
PCA							Tuy·∫øn t√≠nh							Khi d·ªØ li·ªáu c√≥ c·∫•u tr√∫c tuy·∫øn t√≠nh, d·ªÖ t√≠nh to√°n
SVD							Tuy·∫øn t√≠nh							T∆∞∆°ng t·ª± PCA, d√πng trong NLP (LSA)
T-SNE						Phi tuy·∫øn							Khi d·ªØ li·ªáu ph·ª©c t·∫°p, d√πng ƒë·ªÉ tr·ª±c quan h√≥a
UMAP						Phi tuy·∫øn							Khi c·∫ßn gi·∫£m chi·ªÅu nhanh h∆°n T-SNE


			
5. K·∫øt lu·∫≠n
Gi·∫£m chi·ªÅu d·ªØ li·ªáu l√† m·ªôt k·ªπ thu·∫≠t quan tr·ªçng trong to√°n cao c·∫•p v√† AI, gi√∫p t·ªëi ∆∞u h√≥a t√≠nh to√°n v√† l√†m m√¥ h√¨nh hi·ªáu qu·∫£ h∆°n.

N·∫øu mu·ªën gi·∫£m chi·ªÅu tuy·∫øn t√≠nh ‚Üí PCA, SVD
N·∫øu d·ªØ li·ªáu ph·ª©c t·∫°p ‚Üí T-SNE, UMAP
N·∫øu l√†m v·ªõi ·∫£nh, NLP ‚Üí SVD, Autoencoder		
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////	
</pre><a id='backBottom' href='../AI-math-learning-list.html' style='display:none;'>üîô Quay l·∫°i danh s√°ch</a><br><button onclick='toggleTheme()'>üåô Chuy·ªÉn giao di·ªán</button></div><script>function toggleTheme() {   let mode = document.body.classList.contains('dark-mode') ? 'light-mode' : 'dark-mode';   document.body.className = mode; localStorage.setItem('theme', mode);   syncTheme();}function applyTheme() {   let savedTheme = localStorage.getItem('theme') || 'dark-mode';   document.body.className = savedTheme;   syncTheme();}function syncTheme() {   let preElement = document.querySelector('pre');   if (document.body.classList.contains('dark-mode')) { preElement.style.background = '#1e1e1e'; preElement.style.color = '#e0e0e0'; }   else { preElement.style.background = '#f5f5f5'; preElement.style.color = '#333333'; }}function checkPageHeight() {   let contentHeight = document.body.scrollHeight;   let windowHeight = window.innerHeight;   if (contentHeight > windowHeight * 1.2) {       document.getElementById('backBottom').style.display = 'block';   } else {       document.getElementById('backBottom').style.display = 'none';   }}</script></body></html>