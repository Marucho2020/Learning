<html><head><title>Lesson 34 == PyTorch trong h·ªçc m√°y cho ng∆∞·ªùi m·ªõi b·∫Øt ƒë·∫ßu ==========//</title><style>body { font-family: Arial, sans-serif; transition: background 0.3s, color 0.3s; }.dark-mode { background-color: #121212; color: #e0e0e0; }.light-mode { background-color: #ffffff; color: #333333; }h1 { text-align: center; color: #73d9f5; }pre { padding: 15px; border-radius: 5px;       white-space: pre-wrap; word-wrap: break-word;       overflow-x: auto; max-width: 100%;       transition: background 0.3s, color 0.3s; }.dark-mode pre { background: #1e1e1e; color: #e0e0e0; }.light-mode pre { background: #f5f5f5; color: #333333; }#backTop, #backBottom {    font-size: 2em; padding: 20px 40px;    background: #bb86fc; color: white; text-decoration: none;    border-radius: 10px; display: inline-block; text-align: center; }#backTop:hover, #backBottom:hover { background: #9b67e2; }button { font-size: 1.5em; padding: 15px 30px;    background: #03dac6; color: #121212; border: none;    cursor: pointer; border-radius: 5px; display: block; margin: 10px auto; }button:hover { background: #02b8a3; }.dark-mode a { color: #03dac6; } .light-mode a { color: #007bff; }</style></head><body onload='applyTheme(); checkPageHeight()'><div class='container'><a id='backTop' href='../AI-learning-list.html'>üîô Quay l·∫°i danh s√°ch</a><br><h1>Lesson 34 -- PyTorch trong h·ªçc m√°y cho ng∆∞·ªùi m·ªõi b·∫Øt ƒë·∫ßu -//</h1><pre># 1. Gi·ªõi thi·ªáu
	Trong nh·ªØng nƒÉm g·∫ßn ƒë√¢y, h·ªçc m√°y ƒë√£ tr·ªü th√†nh m·ªôt lƒ©nh v·ª±c quan tr·ªçng v√† ph√°t tri·ªÉn nhanh ch√≥ng trong tr√≠ tu·ªá nh√¢n t·∫°o. ƒê·ªÉ x√¢y d·ª±ng v√† tri·ªÉn khai c√°c m√¥ h√¨nh h·ªçc m√°y hi·ªáu qu·∫£, vi·ªác l·ª±a ch·ªçn m·ªôt framework ph√π h·ª£p l√† v√¥ c√πng quan tr·ªçng. PyTorch, ƒë∆∞·ª£c ph√°t tri·ªÉn b·ªüi Facebook‚Äôs AI Research lab (FAIR), ƒë√£ n·ªïi l√™n nh∆∞ m·ªôt trong nh·ªØng c√¥ng c·ª• m·∫°nh m·∫Ω v√† linh ho·∫°t nh·∫•t cho c·∫£ nghi√™n c·ª©u v√† ·ª©ng d·ª•ng th·ª±c ti·ªÖn. B√†i vi·∫øt n√†y s·∫Ω cung c·∫•p m·ªôt h∆∞·ªõng d·∫´n to√†n di·ªán v·ªÅ PyTorch d√†nh cho ng∆∞·ªùi m·ªõi b·∫Øt ƒë·∫ßu, gi√∫p b·∫°n hi·ªÉu v√† √°p d·ª•ng c√°c kh√°i ni·ªám c∆° b·∫£n trong h·ªçc m√°y m·ªôt c√°ch hi·ªáu qu·∫£



	## 1.1. PyTorch l√† g√¨?
		PyTorch l√† m·ªôt th∆∞ vi·ªán m√£ ngu·ªìn m·ªü d√†nh cho h·ªçc m√°y d·ª±a tr√™n Python, ƒë∆∞·ª£c s·ª≠ d·ª•ng r·ªông r√£i trong vi·ªác ph√°t tri·ªÉn v√† tri·ªÉn khai c√°c m√¥ h√¨nh h·ªçc s√¢u. V·ªõi c·∫•u tr√∫c linh ho·∫°t v√† d·ªÖ s·ª≠ d·ª•ng, PyTorch cho ph√©p c√°c nh√† nghi√™n c·ª©u v√† l·∫≠p tr√¨nh vi√™n t·∫°o ra c√°c m√¥ h√¨nh ph·ª©c t·∫°p m·ªôt c√°ch nhanh ch√≥ng v√† hi·ªáu qu·∫£.


	## 1.2. T·∫°i sao ch·ªçn PyTorch cho h·ªçc m√°y?
		‚Äì D·ªÖ s·ª≠ d·ª•ng v√† linh ho·∫°t: PyTorch c√≥ c√∫ ph√°p g·∫ßn g≈©i v·ªõi Python, gi√∫p vi·ªác vi·∫øt v√† hi·ªÉu code tr·ªü n√™n d·ªÖ d√†ng h∆°n. Kh·∫£ nƒÉng linh ho·∫°t trong vi·ªác x√¢y d·ª±ng v√† t√πy ch·ªânh m√¥ h√¨nh gi√∫p PyTorch ph√π h·ª£p v·ªõi nhi·ªÅu lo·∫°i d·ª± √°n kh√°c nhau.
		
		‚Äì T√≠nh to√°n ƒë·ªông (Dynamic Computation Graphs): Kh√°c v·ªõi m·ªôt s·ªë framework kh√°c, PyTorch s·ª≠ d·ª•ng ƒë·ªì th·ªã t√≠nh to√°n ƒë·ªông, cho ph√©p thay ƒë·ªïi c·∫•u tr√∫c c·ªßa m·∫°ng trong qu√° tr√¨nh ch·∫°y. ƒêi·ªÅu n√†y ƒë·∫∑c bi·ªát h·ªØu √≠ch khi l√†m vi·ªác v·ªõi c√°c m√¥ h√¨nh ph·ª©c t·∫°p v√† d·ªØ li·ªáu kh√¥ng ƒë·ªìng nh·∫•t. 
		
		‚Äì H·ªó tr·ª£ GPU m·∫°nh m·∫Ω: PyTorch t√≠ch h·ª£p t·ªët v·ªõi GPU, gi√∫p tƒÉng t·ªëc qu√° tr√¨nh hu·∫•n luy·ªán v√† tri·ªÉn khai m√¥ h√¨nh.
		
		‚Äì C·ªông ƒë·ªìng v√† t√†i li·ªáu phong ph√∫: PyTorch c√≥ m·ªôt c·ªông ƒë·ªìng ng∆∞·ªùi d√πng l·ªõn v√† t√†i li·ªáu h·ªó tr·ª£ ƒë·∫ßy ƒë·ªß, gi√∫p vi·ªác h·ªçc t·∫≠p v√† gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ tr·ªü n√™n d·ªÖ d√†ng h∆°n.
		
		‚Äì T√≠ch h·ª£p v·ªõi c√°c c√¥ng c·ª• kh√°c: PyTorch d·ªÖ d√†ng t√≠ch h·ª£p v·ªõi c√°c th∆∞ vi·ªán v√† c√¥ng c·ª• kh√°c nh∆∞ NumPy, SciPy, v√† scikit-learn, m·ªü r·ªông kh·∫£ nƒÉng v√† ·ª©ng d·ª•ng c·ªßa n√≥ trong nhi·ªÅu lƒ©nh v·ª±c.
		
		V·ªõi nh·ªØng ∆∞u ƒëi·ªÉm tr√™n, PyTorch ƒë√£ tr·ªü th√†nh l·ª±a ch·ªçn h√†ng ƒë·∫ßu cho c·∫£ ng∆∞·ªùi m·ªõi b·∫Øt ƒë·∫ßu v√† c√°c chuy√™n gia trong lƒ©nh v·ª±c h·ªçc m√°y v√† h·ªçc s√¢u.
		


# 2. C√†i ƒë·∫∑t PyTorch 

	Tr∆∞·ªõc khi b·∫Øt ƒë·∫ßu l√†m vi·ªác v·ªõi PyTorch, ch√∫ng ta c·∫ßn ƒë·∫£m b·∫£o m√¥i tr∆∞·ªùng h·ªá th·ªëng ph√π h·ª£p v√† th·ª±c hi·ªán c√†i ƒë·∫∑t ƒë√∫ng c√°ch.
	
	## 2.1. Y√™u c·∫ßu h·ªá th·ªëng
		ƒê·ªÉ c√†i ƒë·∫∑t v√† ch·∫°y PyTorch m·ªôt c√°ch hi·ªáu qu·∫£, h·ªá th·ªëng c·ªßa b·∫°n c·∫ßn ƒë√°p ·ª©ng c√°c y√™u c·∫ßu sau:
		
		‚Äì H·ªá ƒëi·ªÅu h√†nh: PyTorch h·ªó tr·ª£ Windows, Linux v√† macOS.
		
		‚Äì Python: N√™n s·ª≠ d·ª•ng phi√™n b·∫£n Python 3.6 tr·ªü l√™n.
		
		‚Äì Tr√¨nh qu·∫£n l√Ω g√≥i: S·ª≠ d·ª•ng `pip` ho·∫∑c `conda` ƒë·ªÉ c√†i ƒë·∫∑t.
		
		‚Äì CUDA (t√πy ch·ªçn): N·∫øu b·∫°n mu·ªën s·ª≠ d·ª•ng GPU ƒë·ªÉ tƒÉng t·ªëc qu√° tr√¨nh t√≠nh to√°n, c·∫ßn c√†i ƒë·∫∑t CUDA c·ªßa NVIDIA. Phi√™n b·∫£n CUDA t∆∞∆°ng th√≠ch s·∫Ω ph·ª• thu·ªôc v√†o phi√™n b·∫£n PyTorch b·∫°n mu·ªën c√†i ƒë·∫∑t.		


	## 2.2. Th·ª±c hi·ªán c√†i ƒë·∫∑t
		D∆∞·ªõi ƒë√¢y l√† h∆∞·ªõng d·∫´n c√†i ƒë·∫∑t PyTorch b·∫±ng `pip` v√† `conda`.
		
		## C√°ch 1: C√†i ƒë·∫∑t b·∫±ng pip
			C√†i ƒë·∫∑t Python v√† pip: N·∫øu b·∫°n ch∆∞a c√≥, h√£y t·∫£i v√† c√†i ƒë·∫∑t Python t·ª´ [python.org](https://www.python.org/downloads/). T·∫£i v√† c√†i ƒë·∫∑t pip t·ª´ pip.pypa.io (https://pip.pypa.io/en/stable/installation/).
			
		T·∫°o m√¥i tr∆∞·ªùng ·∫£o (khuy·∫øn ngh·ªã):
			python -m venv myenv
			source myenv/bin/activate # Tr√™n Linux/Mac
			myenv\Scripts\activate # Tr√™n Windows			


		C√†i ƒë·∫∑t PyTorch:
			‚Äì Kh√¥ng s·ª≠ d·ª•ng GPU:
				pip install torch torchvision torchaudio
		
		
		‚Äì S·ª≠ d·ª•ng GPU v·ªõi CUDA:
			X√°c ƒë·ªãnh phi√™n b·∫£n CUDA ph√π h·ª£p v√† ch·∫°y l·ªánh:
				pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu118
		
			(Thay `cu118` b·∫±ng phi√™n b·∫£n CUDA c·ªßa b·∫°n, v√≠ d·ª•: `cu116`)
		
		
		
		## C√†i ƒë·∫∑t b·∫±ng conda 
			C√†i ƒë·∫∑t Anaconda ho·∫∑c Miniconda: T·∫£i v√† c√†i ƒë·∫∑t t·ª´ [anaconda.com](https://www.anaconda.com/products/distribution) ho·∫∑c [miniconda](https://docs.conda.io/en/latest/miniconda.html).
			
			T·∫°o m√¥i tr∆∞·ªùng m·ªõi: 
			
				conda create -n myenv python=3.8
				conda activate myenv
		
		
			C√†i ƒë·∫∑t PyTorch: 
			
				‚Äì Kh√¥ng s·ª≠ d·ª•ng GPU:
					conda install pytorch torchvision torchaudio cpuonly -c pytorch
		
				‚Äì S·ª≠ d·ª•ng GPU v·ªõi CUDA:
					conda install pytorch torchvision torchaudio cudatoolkit=11.8 -c pytorch -c nvidia
					(Thay `cudatoolkit=11.8` b·∫±ng phi√™n b·∫£n CUDA t∆∞∆°ng ·ª©ng)
					
		
				Ki·ªÉm tra c√†i ƒë·∫∑t
					Sau khi c√†i ƒë·∫∑t, h√£y ki·ªÉm tra xem PyTorch ƒë√£ ƒë∆∞·ª£c c√†i ƒë·∫∑t ƒë√∫ng c√°ch ch∆∞a:
					
					import torch
					print(torch.__version__)
					print(torch.cuda.is_available())  # Ki·ªÉm tra GPU	
					
					N·∫øu k·∫øt qu·∫£ tr·∫£ v·ªÅ phi√™n b·∫£n PyTorch v√† `True` cho GPU (n·∫øu c√≥), b·∫°n ƒë√£ c√†i ƒë·∫∑t th√†nh c√¥ng PyTorch v√† s·∫µn s√†ng ƒë·ªÉ b·∫Øt ƒë·∫ßu.
					
					
# 3. Kh√°i ni·ªám c∆° b·∫£n trong PyTorch 
	
	##	3.1. Tensors: N·ªÅn t·∫£ng c·ªßa PyTorch
	Tensors l√† g√¨? 
		Tensor l√† m·ªôt c·∫•u tr√∫c d·ªØ li·ªáu c∆° b·∫£n trong PyTorch, t∆∞∆°ng t·ª± nh∆∞ m·∫£ng (array) trong NumPy nh∆∞ng ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ ch·∫°y hi·ªáu qu·∫£ tr√™n c·∫£ CPU v√† GPU. Tensor c√≥ th·ªÉ c√≥ nhi·ªÅu chi·ªÅu, t·ª´ scalar (0 chi·ªÅu) ƒë·∫øn tensor nhi·ªÅu chi·ªÅu.
		
		
	## 3.2. T·∫°o v√† thao t√°c v·ªõi Tensors
	
		### T·∫°o tensor t·ª´ d·ªØ li·ªáu
		
import torch

# T·∫°o tensor t·ª´ list
data = [[1, 2], [3, 4]]
x_data = torch.tensor(data)


		## T·∫°o tensor ng·∫´u nhi√™n

# Tensor v·ªõi gi√° tr·ªã ng·∫´u nhi√™n
rand_tensor = torch.rand(2, 3)

# Tensor v·ªõi gi√° tr·ªã b·∫±ng 0
zero_tensor = torch.zeros(2, 3)

# Tensor v·ªõi gi√° tr·ªã b·∫±ng 1
one_tensor = torch.ones(2, 3)




	## C√°c thao t√°c c∆° b·∫£n 

# C·ªông hai tensor
y1 = x_data + x_data

# Nh√¢n hai tensor
y2 = x_data * x_data

# Ma tr·∫≠n nh√¢n
y3 = x_data @ x_data.T




	## Chuy·ªÉn tensor sang GPU 
	
if torch.cuda.is_available():
    x_data = x_data.to('cuda')





	## 3.2. Autograd: T·ª± ƒë·ªông t√≠nh to√°n gradient 
		

		## Autograd l√† g√¨? 
			`autograd` l√† m·ªôt t√≠nh nƒÉng m·∫°nh m·∫Ω trong PyTorch cho ph√©p t·ª± ƒë·ªông t√≠nh to√°n gradient c·ªßa c√°c tensor. ƒêi·ªÅu n√†y ƒë·∫∑c bi·ªát h·ªØu √≠ch trong vi·ªác hu·∫•n luy·ªán m√¥ h√¨nh h·ªçc s√¢u b·∫±ng c√°ch t·ª± ƒë·ªông h√≥a qu√° tr√¨nh lan truy·ªÅn ng∆∞·ª£c (backpropagation).
			
			

		## S·ª≠ d·ª•ng Autograd 
			Khai b√°o tensor v·ªõi gradient
			
				x = torch.ones(2, 2, requires_grad=True)

			Th·ª±c hi·ªán c√°c ph√©p t√≠nh

y = x + 2
z = y * y * 3
out = z.mean()


			T√≠nh to√°n gradient 
				out.backward()
				print(x.grad)




# 3.3. Neural Networks: X√¢y d·ª±ng m·∫°ng n∆°-ron v·ªõi nn.Module

	## Gi·ªõi thi·ªáu v·ªÅ nn.Module 
	`torch.nn` l√† m·ªôt module trong PyTorch cung c·∫•p c√°c c√¥ng c·ª• ƒë·ªÉ x√¢y d·ª±ng v√† hu·∫•n luy·ªán c√°c m√¥ h√¨nh h·ªçc s√¢u. `nn.Module` l√† l·ªõp c∆° b·∫£n cho t·∫•t c·∫£ c√°c m√¥ h√¨nh m·∫°ng n∆°-ron trong PyTorch.


	## X√¢y d·ª±ng m√¥ h√¨nh ƒë∆°n gi·∫£n 
		
import torch.nn as nn

class SimpleNN(nn.Module):
    def __init__(self):
        super(SimpleNN, self).__init__()
        self.linear = nn.Linear(10, 1)
    
    def forward(self, x):
        out = self.linear(x)
        return out

model = SimpleNN()



	## S·ª≠ d·ª•ng m√¥ h√¨nh

input = torch.randn(1, 10)
output = model(input)
print(output)



	## C√°c l·ªõp ph·ªï bi·∫øn trong nn.Module
	
	
‚Äì nn.Linear: L·ªõp k·∫øt n·ªëi ƒë·∫ßy ƒë·ªß (fully connected).
‚Äì nn.Conv2d: L·ªõp t√≠ch ch·∫≠p 2D.
‚Äì nn.ReLU: H√†m k√≠ch ho·∫°t ReLU.
‚Äì nn.Softmax: H√†m k√≠ch ho·∫°t Softmax.
‚Äì nn.Sequential: K·∫øt h·ª£p c√°c l·ªõp theo th·ª© t·ª±.
	
	
	## V√≠ d·ª•: M·∫°ng ph√¢n lo·∫°i h√¨nh ·∫£nh ƒë∆°n gi·∫£n
	
	
class ImageClassifier(nn.Module):
    def __init__(self):
        super(ImageClassifier, self).__init__()
        self.model = nn.Sequential(
            nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2, 2),
            nn.Flatten(),
            nn.Linear(16 * 16 * 16, 10),
            nn.Softmax(dim=1)
        )
    
    def forward(self, x):
        return self.model(x)

model = ImageClassifier()	
	
	V·ªõi hi·ªÉu bi·∫øt v·ªÅ Tensors, Autograd v√† c√°ch x√¢y d·ª±ng m·∫°ng n∆°-ron b·∫±ng `nn.Module`, b·∫°n ƒë√£ c√≥ n·ªÅn t·∫£ng v·ªØng ch·∫Øc ƒë·ªÉ b·∫Øt ƒë·∫ßu x√¢y d·ª±ng v√† hu·∫•n luy·ªán c√°c m√¥ h√¨nh h·ªçc m√°y v·ªõi PyTorch.
	
	
#  4. X·ª≠ l√Ω d·ªØ li·ªáu v·ªõi PyTorch 

	Trong h·ªçc m√°y, d·ªØ li·ªáu ƒë√≥ng vai tr√≤ quan tr·ªçng v√† vi·ªác x·ª≠ l√Ω d·ªØ li·ªáu m·ªôt c√°ch hi·ªáu qu·∫£ l√† b∆∞·ªõc kh√¥ng th·ªÉ thi·∫øu. PyTorch cung c·∫•p c√°c c√¥ng c·ª• m·∫°nh m·∫Ω ƒë·ªÉ t·∫£i v√† x·ª≠ l√Ω d·ªØ li·ªáu th√¥ng qua `Dataset` v√† `DataLoader`.

	## 4.1. Dataset v√† DataLoader 
	
		Dataset 
			torch.utils.data.Dataset l√† m·ªôt l·ªõp tr·ª´u t∆∞·ª£ng ƒë·∫°i di·ªán cho t·∫≠p d·ªØ li·ªáu. B·∫°n c√≥ th·ªÉ t·∫°o m·ªôt l·ªõp k·∫ø th·ª´a t·ª´ `Dataset` v√† tri·ªÉn khai c√°c ph∆∞∆°ng th·ª©c ƒë·ªÉ truy c·∫≠p d·ªØ li·ªáu c·ªßa b·∫°n.



		V√≠ d·ª•: T·∫°o m·ªôt Dataset t√πy ch·ªânh
import torch
from torch.utils.data import Dataset

class CustomDataset(Dataset):
    def __init__(self, data, labels):
        self.data = data
        self.labels = labels
    
    def __len__(self):
        return len(self.labels)
    
    def __getitem__(self, idx):
        x = self.data[idx]
        y = self.labels[idx]
        return x, y

# D·ªØ li·ªáu m·∫´u
data = torch.randn(100, 10)
labels = torch.randint(0, 2, (100,))

dataset = CustomDataset(data, labels)



	## DataLoader
		`torch.utils.data.DataLoader` cung c·∫•p m·ªôt c√°ch thu·∫≠n ti·ªán ƒë·ªÉ l·∫∑p qua t·∫≠p d·ªØ li·ªáu, h·ªó tr·ª£ chia batch, x√°o tr·ªôn d·ªØ li·ªáu v√† s·ª≠ d·ª•ng ƒëa lu·ªìng ƒë·ªÉ tƒÉng t·ªëc ƒë·ªô t·∫£i d·ªØ li·ªáu.


	## S·ª≠ d·ª•ng DataLoader 
		
from torch.utils.data import DataLoader

dataloader = DataLoader(dataset, batch_size=16, shuffle=True, num_workers=2)

for batch_data, batch_labels in dataloader:
    # Hu·∫•n luy·ªán m√¥ h√¨nh v·ªõi batch_data v√† batch_labels
    pass


	## S·ª≠ d·ª•ng c√°c Dataset c√≥ s·∫µn
		PyTorch cung c·∫•p nhi·ªÅu t·∫≠p d·ªØ li·ªáu ph·ªï bi·∫øn th√¥ng qua `torchvision.datasets`.


	V√≠ d·ª•: S·ª≠ d·ª•ng MNIST dataset 

import torchvision
from torchvision import datasets, transforms

transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))
])

mnist_train = datasets.MNIST(root='./data', train=True, download=True, transform=transform)
mnist_test = datasets.MNIST(root='./data', train=False, download=True, transform=transform)

train_loader = DataLoader(mnist_train, batch_size=64, shuffle=True)
test_loader = DataLoader(mnist_test, batch_size=64, shuffle=False)



	## 4.2. Bi·∫øn ƒë·ªïi d·ªØ li·ªáu v·ªõi torchvision.transforms
		torchvision.transforms cung c·∫•p c√°c c√¥ng c·ª• ƒë·ªÉ bi·∫øn ƒë·ªïi v√† ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu h√¨nh ·∫£nh.


		### C√°c bi·∫øn ƒë·ªïi ph·ªï bi·∫øn 
			
			‚Äì transforms.ToTensor(): Chuy·ªÉn ƒë·ªïi h√¨nh ·∫£nh PIL ho·∫∑c NumPy array th√†nh tensor.
			‚Äì transforms.Normalize(mean, std): Chu·∫©n h√≥a tensor h√¨nh ·∫£nh v·ªõi gi√° tr·ªã trung b√¨nh v√† ƒë·ªô l·ªách chu·∫©n.
			‚Äì transforms.Resize(size): Thay ƒë·ªïi k√≠ch th∆∞·ªõc h√¨nh ·∫£nh.
			‚Äì transforms.RandomCrop(size): C·∫Øt ng·∫´u nhi√™n m·ªôt ph·∫ßn c·ªßa h√¨nh ·∫£nh.
			‚Äì transforms.RandomHorizontalFlip(): L·∫≠t ngang h√¨nh ·∫£nh m·ªôt c√°ch ng·∫´u nhi√™n.


		### V√≠ d·ª•: Chu·∫©n b·ªã chu·ªói bi·∫øn ƒë·ªïi cho d·ªØ li·ªáu h√¨nh ·∫£nh

			transform = transforms.Compose([
				transforms.Resize((64, 64)),
				transforms.RandomHorizontalFlip(),
				transforms.ToTensor(),
				transforms.Normalize(mean=[0.5, 0.5, 0.5],
									std=[0.5, 0.5, 0.5])
			])



			√Åp d·ª•ng bi·∫øn ƒë·ªïi cho Dataset 
				dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)
				dataloader = DataLoader(dataset, batch_size=32, shuffle=True)



		

		### T·∫°o bi·∫øn ƒë·ªïi t√πy ch·ªânh
			B·∫°n c≈©ng c√≥ th·ªÉ t·∫°o c√°c bi·∫øn ƒë·ªïi t√πy ch·ªânh b·∫±ng c√°ch k·∫ø th·ª´a t·ª´ `torchvision.transforms` ho·∫∑c s·ª≠ d·ª•ng c√°c h√†m lambda. 
			
			
		
		
		### 
class ToGrayScale:
    def __call__(self, sample):
        image = sample.convert('L')
        return image

transform = transforms.Compose([
    ToGrayScale(),
    transforms.ToTensor()
])		

V·ªõi hi·ªÉu bi·∫øt v·ªÅ `Dataset`, `DataLoader` v√† `transforms`, b·∫°n c√≥ th·ªÉ d·ªÖ d√†ng t·∫£i, ti·ªÅn x·ª≠ l√Ω v√† qu·∫£n l√Ω d·ªØ li·ªáu cho c√°c d·ª± √°n h·ªçc m√°y c·ªßa m√¨nh, ƒë·∫£m b·∫£o qu√° tr√¨nh hu·∫•n luy·ªán di·ªÖn ra hi·ªáu qu·∫£ v√† thu·∫≠n l·ª£i.



## 5. X√¢y d·ª±ng m√¥ h√¨nh h·ªçc m√°y ƒë∆°n gi·∫£n

	Trong ph·∫ßn n√†y, ch√∫ng ta s·∫Ω √°p d·ª•ng nh·ªØng ki·∫øn th·ª©c ƒë√£ h·ªçc ƒë·ªÉ x√¢y d·ª±ng, hu·∫•n luy·ªán v√† ƒë√°nh gi√° m·ªôt m√¥ h√¨nh h·ªçc m√°y ƒë∆°n gi·∫£n s·ª≠ d·ª•ng PyTorch.

	Ch√∫ng ta s·∫Ω x√¢y d·ª±ng m·ªôt m√¥ h√¨nh m·∫°ng n∆°-ron ƒë∆°n gi·∫£n ƒë·ªÉ ph√¢n lo·∫°i ·∫£nh t·ª´ t·∫≠p d·ªØ li·ªáu MNIST.



## 6. C√°c k·ªπ thu·∫≠t t·ªëi ∆∞u h√≥a trong PyTorch

	ƒê·ªÉ c·∫£i thi·ªán hi·ªáu su·∫•t v√† t·ªëc ƒë·ªô h·ªôi t·ª• c·ªßa m√¥ h√¨nh, PyTorch cung c·∫•p nhi·ªÅu k·ªπ thu·∫≠t t·ªëi ∆∞u h√≥a nh∆∞ s·ª≠ d·ª•ng c√°c optimizer kh√°c nhau v√† ƒëi·ªÅu ch·ªânh learning rate.
	
	## 6.1. Optimizers
		### Gi·ªõi thi·ªáu v·ªÅ Optimizer
		
		Optimizer l√† thu·∫≠t to√°n ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ c·∫≠p nh·∫≠t tr·ªçng s·ªë c·ªßa m√¥ h√¨nh nh·∫±m gi·∫£m thi·ªÉu h√†m m·∫•t m√°t. PyTorch cung c·∫•p nhi·ªÅu optimizer kh√°c nhau trong module `torch.optim`.
	
		### C√°c optimizer ph·ªï bi·∫øn 
			‚Äì SGD (Stochastic Gradient Descent):
optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)
			
			‚Äì Adam: 
optimizer = optim.Adam(model.parameters(), lr=0.001)

			- ‚Äì RMSprop:		
optimizer = optim.RMSprop(model.parameters(), lr=0.001)			
	
		### So s√°nh c√°c optimizer 
			‚Äì SGD: ƒê∆°n gi·∫£n v√† hi·ªáu qu·∫£ cho nhi·ªÅu b√†i to√°n, nh∆∞ng c√≥ th·ªÉ ch·∫≠m h·ªôi t·ª•.
			‚Äì Adam: K·∫øt h·ª£p gi·ªØa Momentum v√† RMSprop, th∆∞·ªùng h·ªôi t·ª• nhanh h∆°n v√† ph√π h·ª£p cho nhi·ªÅu lo·∫°i m√¥ h√¨nh.
			‚Äì RMSprop: T·ªët cho c√°c b√†i to√°n v·ªõi gradient kh√¥ng ·ªïn ƒë·ªãnh.		
	
	
	
		### Thay ƒë·ªïi optimizer trong m√¥ h√¨nh
			# Chuy·ªÉn t·ª´ SGD sang Adam
				optimizer = optim.Adam(model.parameters(), lr=0.001)		
		
		
		
		
		
	## 	6.2. Learning rate schedulers 
		Gi·ªõi thi·ªáu v·ªÅ Learning Rate Scheduler 
		
		Learning rate scheduler ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ ƒëi·ªÅu ch·ªânh learning rate trong qu√° tr√¨nh hu·∫•n luy·ªán, gi√∫p m√¥ h√¨nh h·ªôi t·ª• t·ªët h∆°n v√† tr√°nh m·∫Øc k·∫πt trong c√°c ƒëi·ªÉm t·ªëi ∆∞u c·ª•c b·ªô.
		
		### 	C√°c scheduler ph·ªï bi·∫øn 
			‚Äì StepLR: Gi·∫£m learning rate sau m·ªói v√†i epoch.
				scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)
		
			- ‚Äì ReduceLROnPlateau: Gi·∫£m learning rate khi metric kh√¥ng c·∫£i thi·ªán.
				scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min')
			
			- ‚Äì ExponentialLR: Gi·∫£m learning rate theo h√†m m≈©. 
				scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)


		### S·ª≠ d·ª•ng scheduler trong qu√° tr√¨nh hu·∫•n luy·ªán 
for epoch in range(1, num_epochs + 1):
    train(model, device, train_loader, optimizer, criterion, epoch)
    scheduler.step()		

# 7. L∆∞u v√† t·∫£i m√¥ h√¨nh
	Vi·ªác l∆∞u tr·ªØ v√† t·∫£i l·∫°i m√¥ h√¨nh l√† m·ªôt ph·∫ßn quan tr·ªçng trong qu√° tr√¨nh ph√°t tri·ªÉn v√† tri·ªÉn khai m√¥ h√¨nh h·ªçc m√°y. PyTorch cung c·∫•p c√°c ph∆∞∆°ng th·ª©c ƒë∆°n gi·∫£n v√† hi·ªáu qu·∫£ ƒë·ªÉ th·ª±c hi·ªán ƒëi·ªÅu n√†y.

	## 7.1. L∆∞u tr·ªØ m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán 
		
		### L∆∞u state_dict c·ªßa m√¥ h√¨nh 
	state_dict l√† m·ªôt t·ª´ ƒëi·ªÉn ch·ª©a t·∫•t c·∫£ c√°c tham s·ªë h·ªçc ƒë∆∞·ª£c (weights v√† biases) c·ªßa m√¥ h√¨nh.		

		 #### L∆∞u state_dict		
			torch.save(model.state_dict(), 'model.pth')
		
			∆Øu ƒëi·ªÉm:
				‚Äì Linh ho·∫°t: D·ªÖ d√†ng t·∫£i v√†o c√°c m√¥ h√¨nh c√≥ c·∫•u tr√∫c t∆∞∆°ng t·ª±.
				‚Äì K√≠ch th∆∞·ªõc nh·ªè h∆°n so v·ªõi l∆∞u to√†n b·ªô m√¥ h√¨nh.		
		
		#### L∆∞u to√†n b·ªô m√¥ h√¨nh 
			torch.save(model, 'model_complete.pth')
			
			∆Øu ƒëi·ªÉm:
				‚Äì D·ªÖ s·ª≠ d·ª•ng: Bao g·ªìm c·∫£ c·∫•u tr√∫c v√† tham s·ªë c·ªßa m√¥ h√¨nh.
				‚Äì Ti·ªán l·ª£i khi tri·ªÉn khai m√¥ h√¨nh m√† kh√¥ng c·∫ßn ƒë·ªãnh nghƒ©a l·∫°i ki·∫øn tr√∫c.
		
		
		#### L∆∞u tr·ªØ optimizer state_dict 
			ƒê·ªÉ ti·∫øp t·ª•c qu√° tr√¨nh hu·∫•n luy·ªán t·ª´ ƒëi·ªÉm d·ª´ng, b·∫°n c≈©ng n√™n l∆∞u state_dict c·ªßa optimizer.
			
torch.save({
    'epoch': epoch,
    'model_state_dict': model.state_dict(),
    'optimizer_state_dict': optimizer.state_dict(),
    'loss': loss,
}, 'checkpoint.pth')			
			
		
		
	## 	7.2. T·∫£i m√¥ h√¨nh ƒë·ªÉ s·ª≠ d·ª•ng
		T·∫£i state_dict v√†o m√¥ h√¨nh
		
		### ƒê·ªãnh nghƒ©a l·∫°i m√¥ h√¨nh v√† t·∫£i state_dict
	
model = SimpleNet()
model.load_state_dict(torch.load('model.pth'))
model.eval()  # ƒê·∫∑t m√¥ h√¨nh v√†o ch·∫ø ƒë·ªô ƒë√°nh gi√°
	
	
		### T·∫£i checkpoint 
checkpoint = torch.load('checkpoint.pth')
model.load_state_dict(checkpoint['model_state_dict'])
optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
epoch = checkpoint['epoch']
loss = checkpoint['loss']		
	
	
		### T·∫£i to√†n b·ªô m√¥ h√¨nh
model = torch.load('model_complete.pth')
model.eval()		
		
		
		
		### S·ª≠ d·ª•ng m√¥ h√¨nh ƒë√£ l∆∞u ƒë·ªÉ d·ª± ƒëo√°n 
			
		
	V√≠ d·ª•: D·ª± ƒëo√°n v·ªõi d·ªØ li·ªáu m·ªõi	
# Gi·∫£ s·ª≠ b·∫°n c√≥ m·ªôt ·∫£nh ƒë·∫ßu v√†o m·ªõi
input_image = ...  # Ti·ªÅn x·ª≠ l√Ω ·∫£nh t∆∞∆°ng t·ª± nh∆∞ khi hu·∫•n luy·ªán
input_tensor = transform(input_image).unsqueeze(0)  # Th√™m batch dimension

# D·ª± ƒëo√°n
with torch.no_grad():
    output = model(input_tensor)
    predicted_class = output.argmax(dim=1).item()
    print(f'Predicted class: {predicted_class}')		
		
		
		
		### L∆∞u v√† t·∫£i m√¥ h√¨nh tr√™n GPU v√† CPU 
		### L∆∞u m√¥ h√¨nh tr√™n GPU v√† t·∫£i tr√™n CPU 

Khi l∆∞u m√¥ h√¨nh ƒë∆∞·ª£c hu·∫•n luy·ªán tr√™n GPU v√† mu·ªën t·∫£i tr√™n CPU:
		
		L∆∞u tr√™n GPU
			torch.save(model.state_dict(), 'model.pth')
		
		T·∫£i tr√™n CPU 
device = torch.device('cpu')
model = SimpleNet()
model.load_state_dict(torch.load('model.pth', map_location=device))

		
		T·∫£i tr√™n GPU
device = torch.device('cuda')
model = SimpleNet().to(device)
model.load_state_dict(torch.load('model.pth'))		
		
		
		
		
# 8. K·∫øt lu·∫≠n 		
	Trong b√†i vi·∫øt n√†y, ch√∫ng ta ƒë√£ ƒëi qua m·ªôt h∆∞·ªõng d·∫´n to√†n di·ªán v·ªÅ c√°c kh√≠a c·∫°nh c∆° b·∫£n c·ªßa PyTorch, t·ª´ c√†i ƒë·∫∑t, hi·ªÉu bi·∫øt v·ªÅ tensors, autograd, x√¢y d·ª±ng m√¥ h√¨nh m·∫°ng n∆°-ron, x·ª≠ l√Ω d·ªØ li·ªáu, hu·∫•n luy·ªán, ƒë√°nh gi√°, ƒë·∫øn c√°c k·ªπ thu·∫≠t t·ªëi ∆∞u h√≥a v√† c√°ch l∆∞u tr·ªØ m√¥ h√¨nh. V·ªõi ki·∫øn th·ª©c n√†y, b·∫°n ƒë√£ c√≥ m·ªôt n·ªÅn t·∫£ng v·ªØng ch·∫Øc ƒë·ªÉ b·∫Øt ƒë·∫ßu h√†nh tr√¨nh trong lƒ©nh v·ª±c h·ªçc m√°y v√† h·ªçc s√¢u b·∫±ng PyTorch.	
		
		
	## 	Nh·ªØng ƒëi·ªÉm ch√≠nh ƒë√£ h·ªçc ƒë∆∞·ª£c: 
		
‚Äì PyTorch l√† m·ªôt framework m·∫°nh m·∫Ω v√† linh ho·∫°t cho vi·ªác ph√°t tri·ªÉn c√°c m√¥ h√¨nh h·ªçc s√¢u, v·ªõi c√∫ ph√°p th√¢n thi·ªán v√† h·ªó tr·ª£ t√≠nh to√°n tr√™n GPU.

‚Äì Tensors l√† n·ªÅn t·∫£ng c·ªßa PyTorch, cung c·∫•p c·∫•u tr√∫c d·ªØ li·ªáu hi·ªáu qu·∫£ cho c√°c t√≠nh to√°n s·ªë h·ªçc v√† ma tr·∫≠n.

‚Äì Autograd gi√∫p t·ª± ƒë·ªông h√≥a qu√° tr√¨nh t√≠nh to√°n gradient, l√†m cho vi·ªác tri·ªÉn khai c√°c thu·∫≠t to√°n h·ªçc m√°y tr·ªü n√™n d·ªÖ d√†ng h∆°n.

‚Äì Module nn cung c·∫•p c√°c c√¥ng c·ª• ƒë·ªÉ x√¢y d·ª±ng c√°c m√¥ h√¨nh m·∫°ng n∆°-ron t·ª´ ƒë∆°n gi·∫£n ƒë·∫øn ph·ª©c t·∫°p.

‚Äì Dataset v√† DataLoader gi√∫p qu·∫£n l√Ω v√† x·ª≠ l√Ω d·ªØ li·ªáu m·ªôt c√°ch hi·ªáu qu·∫£, h·ªó tr·ª£ qu√° tr√¨nh hu·∫•n luy·ªán m√¥ h√¨nh.

‚Äì C√°c k·ªπ thu·∫≠t t·ªëi ∆∞u h√≥a nh∆∞ s·ª≠ d·ª•ng optimizer v√† learning rate scheduler c·∫£i thi·ªán hi·ªáu su·∫•t v√† t·ªëc ƒë·ªô h·ªôi t·ª• c·ªßa m√¥ h√¨nh.

‚Äì Vi·ªác l∆∞u tr·ªØ v√† t·∫£i m√¥ h√¨nh l√† quan tr·ªçng ƒë·ªÉ tri·ªÉn khai v√† ti·∫øp t·ª•c hu·∫•n luy·ªán trong t∆∞∆°ng lai.		
		
		
		
		
		
		
		
		
	
</pre><a id='backBottom' href='../AI-learning-list.html' style='display:none;'>üîô Quay l·∫°i danh s√°ch</a><br><button onclick='toggleTheme()'>üåô Chuy·ªÉn giao di·ªán</button></div><script>function toggleTheme() {   let mode = document.body.classList.contains('dark-mode') ? 'light-mode' : 'dark-mode';   document.body.className = mode; localStorage.setItem('theme', mode);   syncTheme();}function applyTheme() {   let savedTheme = localStorage.getItem('theme') || 'dark-mode';   document.body.className = savedTheme;   syncTheme();}function syncTheme() {   let preElement = document.querySelector('pre');   if (document.body.classList.contains('dark-mode')) { preElement.style.background = '#1e1e1e'; preElement.style.color = '#e0e0e0'; }   else { preElement.style.background = '#f5f5f5'; preElement.style.color = '#333333'; }}function checkPageHeight() {   let contentHeight = document.body.scrollHeight;   let windowHeight = window.innerHeight;   if (contentHeight > windowHeight * 1.2) {       document.getElementById('backBottom').style.display = 'block';   } else {       document.getElementById('backBottom').style.display = 'none';   }}</script></body></html>