<html><head><title>Lesson 20 == Linear Regression Table ==========//</title><style>body { font-family: Arial, sans-serif; transition: background 0.3s, color 0.3s; }.dark-mode { background-color: #121212; color: #e0e0e0; }.light-mode { background-color: #ffffff; color: #333333; }h1 { text-align: center; color: #73d9f5; }pre { padding: 15px; border-radius: 5px;       white-space: pre-wrap; word-wrap: break-word;       overflow-x: auto; max-width: 100%;       transition: background 0.3s, color 0.3s; }.dark-mode pre { background: #1e1e1e; color: #e0e0e0; }.light-mode pre { background: #f5f5f5; color: #333333; }#backTop, #backBottom {    font-size: 2em; padding: 20px 40px;    background: #bb86fc; color: white; text-decoration: none;    border-radius: 10px; display: inline-block; text-align: center; }#backTop:hover, #backBottom:hover { background: #9b67e2; }button { font-size: 1.5em; padding: 15px 30px;    background: #03dac6; color: #121212; border: none;    cursor: pointer; border-radius: 5px; display: block; margin: 10px auto; }button:hover { background: #02b8a3; }.dark-mode a { color: #03dac6; } .light-mode a { color: #007bff; }</style></head><body onload='applyTheme(); checkPageHeight()'><div class='container'><a id='backTop' href='../DataScience-learning.html'>ğŸ”™ Quay láº¡i danh sÃ¡ch</a><br><h1>Lesson 20 -- Linear Regression Table -//</h1><pre>

# 1. KhÃ¡i Niá»‡m Tá»•ng QuÃ¡t Vá» Báº£ng Há»“i Quy

	Báº£ng há»“i quy lÃ  má»™t báº£ng tÃ³m táº¯t káº¿t quáº£ tá»« mÃ´ hÃ¬nh há»“i quy tuyáº¿n tÃ­nh. Há»“i quy tuyáº¿n tÃ­nh lÃ  phÆ°Æ¡ng phÃ¡p thá»‘ng kÃª Ä‘á»ƒ mÃ´ hÃ¬nh hÃ³a má»‘i quan há»‡ giá»¯a má»™t biáº¿n phá»¥ thuá»™c (dependent variable) â€“ thÆ°á»ng gá»i lÃ  Y (biáº¿n báº¡n muá»‘n dá»± Ä‘oÃ¡n) â€“ vÃ  má»™t hoáº·c nhiá»u biáº¿n Ä‘á»™c láº­p (independent variables) â€“ thÆ°á»ng gá»i lÃ  X (biáº¿n giáº£i thÃ­ch).


	CÃ´ng thá»©c cÆ¡ báº£n cá»§a há»“i quy tuyáº¿n tÃ­nh Ä‘Æ¡n giáº£n (simple linear regression):
		 Y = \beta_0 + \beta_1 X + \epsilon 

		$\beta_0$: Há»‡ sá»‘ cháº·n (intercept) â€“ giÃ¡ trá»‹ dá»± Ä‘oÃ¡n cá»§a Y khi X = 0.
		$\beta_1$: Há»‡ sá»‘ gÃ³c (slope) â€“ má»©c Ä‘á»™ thay Ä‘á»•i cá»§a Y khi X tÄƒng 1 Ä‘Æ¡n vá»‹.
		$\epsilon$: Sai sá»‘ ngáº«u nhiÃªn (error term).

	Báº£ng há»“i quy giÃºp báº¡n:

		- ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh cÃ³ tá»‘t khÃ´ng (vÃ­ dá»¥: mÃ´ hÃ¬nh giáº£i thÃ­ch bao nhiÃªu pháº§n trÄƒm biáº¿n thiÃªn cá»§a dá»¯ liá»‡u?).
		- Kiá»ƒm tra Ã½ nghÄ©a thá»‘ng kÃª cá»§a cÃ¡c há»‡ sá»‘ (cÃ³ pháº£i má»‘i quan há»‡ lÃ  ngáº«u nhiÃªn khÃ´ng?).
		- Dá»± Ä‘oÃ¡n vÃ  ra quyáº¿t Ä‘á»‹nh dá»±a trÃªn dá»¯ liá»‡u.



# 2. CÃ¡c ThÃ nh Pháº§n ChÃ­nh Cá»§a Báº£ng Há»“i Quy
	Dá»±a trÃªn output tiÃªu chuáº©n tá»« thÆ° viá»‡n nhÆ° statsmodels (sáº½ giáº£i thÃ­ch á»Ÿ pháº§n code), báº£ng thÆ°á»ng Ä‘Æ°á»£c chia thÃ nh 3 pháº§n chÃ­nh:

	## Pháº§n 1: TÃ³m táº¯t mÃ´ hÃ¬nh (Model Summary):

		- Dep. Variable: Biáº¿n phá»¥ thuá»™c (Y).
		- Model: Loáº¡i mÃ´ hÃ¬nh (OLS).
		- Method: PhÆ°Æ¡ng phÃ¡p Æ°á»›c lÆ°á»£ng (Least Squares).
		- No. Observations: Sá»‘ lÆ°á»£ng dá»¯ liá»‡u (n).
		- Df Residuals: Äá»™ tá»± do pháº§n dÆ° (n - k - 1, vá»›i k lÃ  sá»‘ biáº¿n Ä‘á»™c láº­p).
		- Df Model: Äá»™ tá»± do mÃ´ hÃ¬nh (k).


	## Pháº§n 2: Thá»‘ng kÃª há»“i quy tá»•ng quÃ¡t (Omnibus Statistics):

		- R-squared: Tá»· lá»‡ biáº¿n thiÃªn cá»§a Y Ä‘Æ°á»£c giáº£i thÃ­ch bá»Ÿi X (0-1, cÃ ng cao cÃ ng tá»‘t, vÃ­ dá»¥ 0.8 nghÄ©a lÃ  80%).
		- Adjusted R-squared: PhiÃªn báº£n Ä‘iá»u chá»‰nh cho sá»‘ biáº¿n (trÃ¡nh overfitting).
		- F-statistic: GiÃ¡ trá»‹ F Ä‘á»ƒ kiá»ƒm tra mÃ´ hÃ¬nh cÃ³ Ã½ nghÄ©a khÃ´ng (p-value cá»§a F < 0.05 thÃ¬ mÃ´ hÃ¬nh tá»‘t).
		- Prob (F-statistic): p-value cá»§a F-test.


	## Pháº§n 3: Há»‡ sá»‘ vÃ  thá»‘ng kÃª cá»§a chÃºng (Coefficients Table)
	
		- coef: GiÃ¡ trá»‹ há»‡ sá»‘ ($\beta_0$ cho Intercept, $\beta_1$ cho X).
		- std err: Sai sá»‘ chuáº©n (standard error) â€“ Ä‘á»™ biáº¿n Ä‘á»™ng cá»§a há»‡ sá»‘.
		- t: GiÃ¡ trá»‹ t-statistic (coef / std err) Ä‘á»ƒ kiá»ƒm tra há»‡ sá»‘ cÃ³ khÃ¡c 0 khÃ´ng.
		- P>|t|: p-value (náº¿u < 0.05, há»‡ sá»‘ cÃ³ Ã½ nghÄ©a thá»‘ng kÃª).
		- [0.025, 0.975]: Khoáº£ng tin cáº­y 95% cho há»‡ sá»‘.
	
		NgoÃ i ra, cÃ³ cÃ¡c thá»‘ng kÃª cháº©n Ä‘oÃ¡n nhÆ° Durbin-Watson (kiá»ƒm tra tá»± tÆ°Æ¡ng quan), Jarque-Bera (kiá»ƒm tra phÃ¢n phá»‘i chuáº©n cá»§a pháº§n dÆ°).
	
	
# 	3. VÃ­ Dá»¥ Cá»¥ Thá»ƒ Tá»« BÃ i Há»c: Báº£ng Há»“i Quy Vá»›i Average_Pulse LÃ m Biáº¿n Giáº£i ThÃ­ch
	BÃ i há»c sá»­ dá»¥ng dá»¯ liá»‡u sá»©c khá»e (full_health_data tá»« "data.csv"), vá»›i:	
	
Duration,Average_Pulse,Max_Pulse,Calorie_Burnage,Hours_Work,Hours_Sleep
30,80,120,240,8,7
45,85,130,280,7,8
...,...,...,...,...,...	
	
		MÃ´ hÃ¬nh kiá»ƒm tra xem nhá»‹p tim trung bÃ¬nh cÃ³ áº£nh hÆ°á»Ÿng Ä‘áº¿n lÆ°á»£ng calo Ä‘á»‘t chÃ¡y khÃ´ng. Káº¿t quáº£ Ä‘iá»ƒn hÃ¬nh: Há»‡ sá»‘ $\beta_1$ dÆ°Æ¡ng, nghÄ©a lÃ  nhá»‹p tim cao hÆ¡n dáº«n Ä‘áº¿n Ä‘á»‘t calo nhiá»u hÆ¡n.
	
	
# 4. HÆ°á»›ng Dáº«n Táº¡o Báº£ng Há»“i Quy Trong Python
	
		BÃ i há»c cung cáº¥p code vÃ­ dá»¥ sá»­ dá»¥ng thÆ° viá»‡n statsmodels â€“ má»™t thÆ° viá»‡n máº¡nh máº½ cho mÃ´ hÃ¬nh thá»‘ng kÃª trong Python. ÄÃ¢y lÃ  cÃ¡ch chuyÃªn nghiá»‡p hÆ¡n so vá»›i scikit-learn (sklearn), vÃ¬ statsmodels cung cáº¥p output chi tiáº¿t kiá»ƒu R (ngÃ´n ngá»¯ thá»‘ng kÃª).
	
import pandas as pd
import statsmodels.formula.api as smf

# Äá»c dá»¯ liá»‡u tá»« file CSV
full_health_data = pd.read_csv("data.csv", header=0, sep=",")

# Táº¡o mÃ´ hÃ¬nh OLS: Y ~ X (Calorie_Burnage ~ Average_Pulse)
model = smf.ols('Calorie_Burnage ~ Average_Pulse', data=full_health_data)

# Fit mÃ´ hÃ¬nh (Æ°á»›c lÆ°á»£ng há»‡ sá»‘)
results = model.fit()

# In báº£ng há»“i quy
print(results.summary())


	## Giáº£i ThÃ­ch Chi Tiáº¿t Code 


		- import pandas as pd: ThÆ° viá»‡n Ä‘á»ƒ xá»­ lÃ½ dá»¯ liá»‡u báº£ng (DataFrame).
		- import statsmodels.formula.api as smf: Pháº§n formula.api cho phÃ©p viáº¿t cÃ´ng thá»©c kiá»ƒu R (Y ~ X), dá»… Ä‘á»c hÆ¡n.
		- pd.read_csv("data.csv", header=0, sep=","): Äá»c file CSV, header=0 nghÄ©a lÃ  dÃ²ng Ä‘áº§u lÃ  tÃªn cá»™t, sep="," lÃ  dáº¥u phÃ¢n cÃ¡ch.
		- smf.ols('Calorie_Burnage ~ Average_Pulse', data=full_health_data): Táº¡o mÃ´ hÃ¬nh OLS. '~' nghÄ©a lÃ  "phá»¥ thuá»™c vÃ o". Náº¿u nhiá»u biáº¿n X, viáº¿t Y ~ X1 + X2.
		- model.fit(): Æ¯á»›c lÆ°á»£ng há»‡ sá»‘ báº±ng phÆ°Æ¡ng phÃ¡p bÃ¬nh phÆ°Æ¡ng nhá» nháº¥t (least squares) â€“ giáº£m thiá»ƒu tá»•ng bÃ¬nh phÆ°Æ¡ng sai sá»‘.
		- results.summary(): Tráº£ vá» báº£ng há»“i quy Ä‘áº§y Ä‘á»§ dÆ°á»›i dáº¡ng text.

			LÆ°u Ã½: Báº¡n cáº§n file "data.csv" Ä‘á»ƒ cháº¡y. Náº¿u khÃ´ng cÃ³, báº¡n cÃ³ thá»ƒ táº£i tá»« W3Schools hoáº·c táº¡o dá»¯ liá»‡u máº«u. Statsmodels khÃ´ng yÃªu cáº§u scale dá»¯ liá»‡u, nhÆ°ng trong thá»±c táº¿, kiá»ƒm tra giáº£ Ä‘á»‹nh (linearity, normality, homoscedasticity) trÆ°á»›c khi tin tÆ°á»Ÿng mÃ´ hÃ¬nh.


# 5. Giáº£i ThÃ­ch Chi Tiáº¿t Output Cá»§a Báº£ng Há»“i Quy

	Giáº£ sá»­ chÃºng ta cháº¡y code vá»›i dá»¯ liá»‡u máº«u tá»« W3Schools (dá»¯ liá»‡u sá»©c khá»e vá»›i ~100 quan sÃ¡t), output Ä‘iá»ƒn hÃ¬nh cá»§a results.summary() trÃ´ng nhÆ° tháº¿ nÃ y (dá»±a trÃªn dá»¯ liá»‡u thá»±c táº¿ tÆ°Æ¡ng tá»±):

                            OLS Regression Results                            
==============================================================================
Dep. Variable:        Calorie_Burnage   R-squared:                       0.752
Model:                            OLS   Adj. R-squared:                  0.749
Method:                 Least Squares   F-statistic:                     295.2
Date:                Mon, 28 Oct 2025   Prob (F-statistic):           1.32e-32
Time:                        12:00:00   Log-Likelihood:                -612.34
No. Observations:                  100   AIC:                             1229.
Df Residuals:                       98   BIC:                             1234.
Df Model:                            1                                         
Covariance Type:            nonrobust                                         
=================================================================================
                    coef    std err          t      P>|t|      [0.025      0.975]
---------------------------------------------------------------------------------
Intercept       -100.5     20.1    -5.00      0.000    -140.4     -60.6
Average_Pulse      3.2      0.186    17.18      0.000       2.83       3.57
==============================================================================
Omnibus:                        1.234   Durbin-Watson:                   1.95
Prob(Omnibus):                  0.540   Jarque-Bera (JB):                1.12
Skew:                          -0.15    Prob(JB):                        0.57
Kurtosis:                       2.78   Cond. No.                         500.
==============================================================================

	PhÃ¢n TÃ­ch Chi Tiáº¿t (NhÆ° ChuyÃªn Gia):
	
		Dep. Variable: Calorie_Burnage â€“ biáº¿n báº¡n dá»± Ä‘oÃ¡n
		
		R-squared: 0.752: MÃ´ hÃ¬nh giáº£i thÃ­ch 75.2% biáº¿n thiÃªn cá»§a calo
		Ä‘á»‘t chÃ¡y báº±ng nhá»‹p tim. Tá»‘t cho dá»¯ liá»‡u thá»±c táº¿ (khÃ´ng pháº£i 100% vÃ¬ cÃ³ noise).
		
		Adj. R-squared: 0.749: Gáº§n giá»‘ng R-squared vÃ¬ chá»‰ 1 biáº¿n X, nhÆ°ng náº¿u thÃªm biáº¿n thá»«a, nÃ³ sáº½ giáº£m.

		F-statistic: 295.2, Prob(F): 1.32e-32: MÃ´ hÃ¬nh cÃ³ Ã½ nghÄ©a (p < 0.05), khÃ´ng pháº£i ngáº«u nhiÃªn.

		Há»‡ sá»‘:

			Intercept: -100.5 (p=0.000): Khi nhá»‹p tim = 0, calo Ä‘á»‘t = -100.5 (cÃ³ thá»ƒ khÃ´ng thá»±c táº¿, nhÆ°ng toÃ¡n há»c ok).
			Average_Pulse: 3.2 (p=0.000): Má»—i nhá»‹p tim tÄƒng 1, calo tÄƒng 3.2. Ã nghÄ©a cao (t=17.18 lá»›n).
			Khoáº£ng tin cáº­y: Há»‡ sá»‘ Average_Pulse náº±m giá»¯a 2.83 vÃ  3.57 vá»›i 95% cháº¯c cháº¯n.
	
		Cháº©n Ä‘oÃ¡n:
		
			Durbin-Watson ~2: KhÃ´ng tá»± tÆ°Æ¡ng quan (tá»‘t).
			Jarque-Bera p=0.57: Pháº§n dÆ° phÃ¢n phá»‘i gáº§n chuáº©n (tá»‘t cho giáº£ Ä‘á»‹nh OLS).
			Cond. No. 500: KhÃ´ng multicollinearity nghiÃªm trá»ng.		
		
		Náº¿u p-value > 0.05, há»‡ sá»‘ khÃ´ng Ã½ nghÄ©a â€“ cÃ³ thá»ƒ loáº¡i biáº¿n X.
		
		
		
		
</pre><a id='backBottom' href='../DataScience-learning.html' style='display:none;'>ğŸ”™ Quay láº¡i danh sÃ¡ch</a><br><button onclick='toggleTheme()'>ğŸŒ™ Chuyá»ƒn giao diá»‡n</button></div><script>function toggleTheme() {   let mode = document.body.classList.contains('dark-mode') ? 'light-mode' : 'dark-mode';   document.body.className = mode; localStorage.setItem('theme', mode);   syncTheme();}function applyTheme() {   let savedTheme = localStorage.getItem('theme') || 'dark-mode';   document.body.className = savedTheme;   syncTheme();}function syncTheme() {   let preElement = document.querySelector('pre');   if (document.body.classList.contains('dark-mode')) { preElement.style.background = '#1e1e1e'; preElement.style.color = '#e0e0e0'; }   else { preElement.style.background = '#f5f5f5'; preElement.style.color = '#333333'; }}function checkPageHeight() {   let contentHeight = document.body.scrollHeight;   let windowHeight = window.innerHeight;   if (contentHeight > windowHeight * 1.2) {       document.getElementById('backBottom').style.display = 'block';   } else {       document.getElementById('backBottom').style.display = 'none';   }}</script></body></html>