<html><head><title>Lesson 16 ==  ==  == Recurrent Neural Network (RNN)	: Ứng dụng và cách hoạt động. ==========//</title><style>body { font-family: Arial, sans-serif; transition: background 0.3s, color 0.3s; }.dark-mode { background-color: #121212; color: #e0e0e0; }.light-mode { background-color: #ffffff; color: #333333; }h1 { text-align: center; color: #73d9f5; }pre { padding: 15px; border-radius: 5px;       white-space: pre-wrap; word-wrap: break-word;       overflow-x: auto; max-width: 100%;       transition: background 0.3s, color 0.3s; }.dark-mode pre { background: #1e1e1e; color: #e0e0e0; }.light-mode pre { background: #f5f5f5; color: #333333; }#backTop, #backBottom {    font-size: 2em; padding: 20px 40px;    background: #bb86fc; color: white; text-decoration: none;    border-radius: 10px; display: inline-block; text-align: center; }#backTop:hover, #backBottom:hover { background: #9b67e2; }button { font-size: 1.5em; padding: 15px 30px;    background: #03dac6; color: #121212; border: none;    cursor: pointer; border-radius: 5px; display: block; margin: 10px auto; }button:hover { background: #02b8a3; }.dark-mode a { color: #03dac6; } .light-mode a { color: #007bff; }</style></head><body onload='applyTheme(); checkPageHeight()'><div class='container'><a id='backTop' href='../AI-learning-list.html'>🔙 Quay lại danh sách</a><br><h1>Lesson 16 --  --  -- Recurrent Neural Network (RNN)	: Ứng dụng và cách hoạt động. -//</h1><pre>

# Khái niệm 
	Recurrent Neural Networks(RNN) là một loại mạng nơ-ron đặc biệt được thiết kế để xử lý dữ liệu tuần tự. Khác với các mạng nơ-ron thông thường, RNN có khả năng ghi nhớ thông tin từ các bước trước đó nhờ cơ chế phản hồi (recurrent), cho phép mô hình có thể tận dụng ngữ cảnh của dữ liệu trước để dự đoán hoặc suy luận dữ liệu hiện tại. Điều này làm cho RNN đặc biệt hiệu quả trong việc phân tích dữ liệu chuỗi thời gian, xử lý ngôn ngữ tự nhiên, dịch máy, và nhận diện giọng nói, nơi mà thông tin từ quá khứ là rất quan trọng để hiểu chính xác hiện tại. 
	

# Cách hoạt động của Recurrent Neural Network(RNN)	
	
https://aicandy.vn/wp-content/uploads/2024/09/aicandy_RNN.png

	
	## Hidden State 
		Điểm khác biệt lớn nhất của RNN so với các mạng nơ-ron truyền thống là khả năng lưu trữ và cập nhật thông tin qua các bước của chuỗi thời gian. Tại mỗi bước thời gian(timestep), RNN duy trì một biến gọi là trạng thái ẩn (h_t), biểu diễn bộ nhớ của mô hình về các thông tin đã nhận được từ những bước trước đó. Trạng thái ẩn này được cập nhật tại mỗi bước thời gian dựa trên đầu vào và hiện tại và trạng thái ẩn từ bước trước đó. 
		Công thức tính toán trạng thái ẩn tại mỗi bước thời gian có thể được biểu diễn như sau 
			h_t = f(W_{xh}x_t + W_{hh}h_{t-1} + b_h)
			
			
		Trong đó : 
			h_t : Trạng thái ẩn tại thời điểm t 
			x_t : Đầu vào tại thời điểm t 
			W_{xh} : Ma trận trọng số kết nối đầu vào với trạng thái ẩn. 
			W_{hh} : Ma trận trọng số kết nối trạng thái ẩn trước đó với trạng thái ẩn hiện tại 
			b_h	   : tham số bias cho trạng thái ẩn 
			f 	: Hàm kích hoạt (thường là hàm tanh hoặc ReLU 
			
			)
			
	## Output  
		RNN có thể tạo đầu ra tại mỗi bước thời gian, thường được tính toán dựa trên trạng thái ẩn tại thời điểm đó. Đầu ra y_t tại thời điểm t được tính bằng công thức : 
				y_t = W_{hy}h_t + b_y
				

		Trong đó : 
			y_t : Đầu ra tại thời điểm t 
			W_{hy}	: Ma trận trọng số kết nối trạng thái ẩn với đầu ra 
			b_y		: Tham số bias cho đầu ra 
			
	## Backpropagation 
		Backpropagation là thuật toán lan truyền ngược trong các mạng nơ-ron thông thường. Ở mỗi lớp của mạng nơ-ron, giá trị đầu ra được tính toán dựa trên đầu vào các trọng số tương ứng. Sau đó , để tối ưu hóa mô hình, ta cần tính toán gradient của hàm mất mát \mathcal{L} theo các trọng số này , giúp ta điều chỉnh các trọng số sao cho mô hình có thể đưa ra dự đoán chính xác hơn 
		
		Công thức tổng quát của lan truyền ngược là : 
			\frac{\partial \mathcal{L}}{\partial W} = \frac{\partial \mathcal{L}}{\partial y} \cdot \frac{\partial y}{\partial W}
			
		Trong đó : 
			\frac{\partial \mathcal{L}}{\partial W}		: là gradient của hàm mất mát theo trọng số W 
			\frac{\partial \mathcal{L}}{\partial y}		: là gradient của hàm mất mát theo đầu ra y 
			\frac{\partial y}{\partial W}				: là gradient của đầu ra theo trọng số W 
			
			Quá trình này được áp dụng cho tất cả các trọng số trong mạng và được thực hiện từ đầu ra trở ngược lại đầu vào, từng lớp một. Khi đã tính được gradient các trọng số sẽ được cập nhật bằng cách sử dụng một phương pháp tối ưu hóa như gradient descent 
			



	##	Backpropagation Through Time (BPTT) 
			
		Trong các mạng RNN, dữ liệu được xử lý tuần tự qua nhiều bước thời gian. Điều này có nghĩa là trạng thái ẩn tại thời điểm t phụ thuộc vào cả đầu vào tại thời điểm đó và trạng thái ẩn từ bước tước đó. Do đó, khi tính toán gradient, ta không chỉ lan truyền ngược qua các lớp như trong mạng nơ-ron truyền thống mà còn phải lan truyền qua các bước thời gian trước đó. Đây là lý do thuật toán BPTT được ra đời. 
			https://aicandy.vn/wp-content/uploads/2024/09/aicandy_RNN_backpropagation.jpg
		
		Trong BPTT, mạng RNN được mở rộng qua thời gian, mỗi bước thời gian của RNN được coi như một lớp riêng biệt. Khi lan truyền ngược, gradient không chỉ được lan truyền qua các trọng số của các lớp trong mạng, mà còn phải lan truyền ngược qua các bước thời gian để tính toán ảnh hưởng của các trạng thái ẩn trước đó đến lỗi hiện tại 
		
		### Công thức tổng quát của BPTT là : 
		
			\frac{\partial \mathcal{L}}{\partial W} = \sum_{t=1}^{T} \frac{\partial \mathcal{L}_t}{\partial y_t} \cdot \frac{\partial y_t}{\partial h_t} \cdot \frac{\partial h_t}{\partial h_{t-1}} \cdot \frac{\partial h_{t-1}}{\partial W}


		Trong đó : 
			\frac{\partial \mathcal{L}_t}{\partial y_t} : là gradient của hàm mất mát tại bước thời gian t theo đầu ra yt 
			\frac{\partial y_t}{\partial h_t}	: là gradient của đầu ra tại thời điểm t theo trạng thái ẩn ht 
			\frac{\partial h_t}{\partial h_{t-1}}	: là gradient của trạng thái ẩn hiện tại theo trạng thái ẩn trước đó 
			\frac{\partial h_{t-1}}{\partial W}		: là gradient của trạng thái ẩn trước theo trọng số W 
			
			
	## Triển khai RNN bằng PyTorch 
			Dưới đây là cách triển khai một mạng RNN đơn giản bằng PyTorch. Mạng sẽ dự đoán số tiếp theo của chuỗi [1, 2, 3, 4].
			RNNByPytorch.py


		Giải thích:	

	https://aicandy.vn/recurrent-neural-network-rnn-ung-dung-va-cach-hoat-dong/




				
				
				
				
				
		
</pre><a id='backBottom' href='../AI-learning-list.html' style='display:none;'>🔙 Quay lại danh sách</a><br><button onclick='toggleTheme()'>🌙 Chuyển giao diện</button></div><script>function toggleTheme() {   let mode = document.body.classList.contains('dark-mode') ? 'light-mode' : 'dark-mode';   document.body.className = mode; localStorage.setItem('theme', mode);   syncTheme();}function applyTheme() {   let savedTheme = localStorage.getItem('theme') || 'dark-mode';   document.body.className = savedTheme;   syncTheme();}function syncTheme() {   let preElement = document.querySelector('pre');   if (document.body.classList.contains('dark-mode')) { preElement.style.background = '#1e1e1e'; preElement.style.color = '#e0e0e0'; }   else { preElement.style.background = '#f5f5f5'; preElement.style.color = '#333333'; }}function checkPageHeight() {   let contentHeight = document.body.scrollHeight;   let windowHeight = window.innerHeight;   if (contentHeight > windowHeight * 1.2) {       document.getElementById('backBottom').style.display = 'block';   } else {       document.getElementById('backBottom').style.display = 'none';   }}</script></body></html>