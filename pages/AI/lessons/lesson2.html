<html><head><title>Lession 4  Lession 4  //</title><style>body { font-family: Arial, sans-serif; transition: background 0.3s, color 0.3s; }.dark-mode { background-color: #121212; color: #e0e0e0; }.light-mode { background-color: #ffffff; color: #333333; }h1 { text-align: center; color: #73d9f5; }pre { padding: 15px; border-radius: 5px;       white-space: pre-wrap; word-wrap: break-word;       overflow-x: auto; max-width: 100%;       transition: background 0.3s, color 0.3s; }.dark-mode pre { background: #1e1e1e; color: #e0e0e0; }.light-mode pre { background: #f5f5f5; color: #333333; }#backTop, #backBottom {    font-size: 2em; padding: 20px 40px;    background: #bb86fc; color: white; text-decoration: none;    border-radius: 10px; display: inline-block; text-align: center; }#backTop:hover, #backBottom:hover { background: #9b67e2; }button { font-size: 1.5em; padding: 15px 30px;    background: #03dac6; color: #121212; border: none;    cursor: pointer; border-radius: 5px; display: block; margin: 10px auto; }button:hover { background: #02b8a3; }.dark-mode a { color: #03dac6; } .light-mode a { color: #007bff; }</style></head><body onload='applyTheme(); checkPageHeight()'><div class='container'><a id='backTop' href='../AI-learning-list.html'>ğŸ”™ Quay láº¡i danh sÃ¡ch</a><br><h1>Lession 4  Lession 4  //</h1><pre>


# 1 CÆ¡ báº£n vá» trÃ­ tuá»‡ nhÃ¢n táº¡o 
		
		
	## Artificial Intelligence - AI 
		Artificial Intelligence : lÃ  lÄ©nh vá»±c nghiÃªn cá»©u vÃ  phÃ¡t triá»ƒn cÃ¡c há»‡ thá»‘ng mÃ¡y tÃ­nh cÃ³ kháº£ nÄƒng thá»±c hiá»‡n cÃ¡c nhiá»‡m vá»¥ mÃ  trÆ°á»›c Ä‘Ã¢y yÃªu cáº§u trÃ­ tuá»‡ cá»§a con ngÆ°á»i, nhÆ° nháº­n dáº¡ng giá»ng nÃ³i, nháº­n dáº¡ng hÃ¬nh áº£nh, ra quyáº¿t Ä‘á»‹nh vÃ  ngÃ´n ngá»¯ 
		
	## Machine Learning - ML 
		Machine Learning : LÃ  má»™t nhÃ¡nh cá»§a AI , táº­p trung vÃ o viá»‡c phÃ¡t triá»ƒn cÃ¡c thuáº­t toÃ¡n vÃ  mÃ´ hÃ¬nh cho phÃ©p mÃ¡y tÃ­nh há»c tá»« dá»¯ liá»‡u mÃ  khÃ´ng cáº§n láº­p trÃ¬nh rÃµ rÃ ng. CÃ¡c á»©ng dá»¥ng phá»• biáº¿n cá»§a há»c mÃ¡y bao gá»“m phÃ¢n loáº¡i, há»“i quy, vÃ  dá»± Ä‘oÃ¡n 
		
	## Deep Learning - DL 
		Deeplearning : LÃ  má»™t pháº§n cá»§a há»c mÃ¡y, sá»­ dá»¥ng cÃ¡c máº¡ng nÆ¡ ron nhÃ¢n táº¡o vá»›i nhiá»u lá»›p(deep neural networks) Ä‘á»ƒ mÃ´ phá»ng cÃ¡ch bá»™ nÃ£o con ngÆ°á»i hoáº¡t Ä‘á»™ng, tá»« Ä‘Ã³ giáº£i quyáº¿t cÃ¡c bÃ i toÃ¡n phá»©c táº¡p nhÆ° nháº­n dáº¡ng giá»ng nÃ³i vÃ  thá»‹ giÃ¡c mÃ¡y tÃ­nh. 
	
	## Natural Language Processing - NLP 
		Natural Language Processing : lÃ  lÄ©nh vá»±c nghiÃªn cá»©u vÃ  phÃ¡t triá»ƒn cÃ¡c thuáº­t toÃ¡n cho phÃ©p mÃ¡y tÃ­nh hiá»ƒu, diá»…n giáº£i vÃ  pháº£n há»“i ngÃ´n ngá»¯ tá»± nhiÃªn cá»§a con ngÆ°á»i. CÃ¡c á»©ng dá»¥ng cá»§a NLP bao gá»“m chat bot, dá»‹ch mÃ¡y vÃ  phÃ¢n tÃ­ch cáº£m xÃºc . 
		
	## Computer Vision 
		Computer Vision : LÃ  lÄ©nh vá»±c cá»§a AI chuyÃªn vá» viá»‡c cho phÃ©p mÃ¡y tÃ­nh nhÃ¬n tháº¥y vÃ  hiá»ƒu Ä‘Æ°á»£c thÃ´ng tin tá»« hÃ¬nh áº£nh vÃ  video. NÃ³ Ä‘Æ°á»£c á»©ng dá»¥ng trong nhiá»u lÄ©nh vá»±c nhÆ° nháº­n dáº¡ng khuÃ´n máº·t, xe tá»± lÃ¡i vÃ  phÃ¢n tÃ­ch video 
		
	## Artificial General Intelligence - AGI 
		Artificial General Intelligence : LÃ  hÃ¬nh thá»©c AI tiÃªn tiáº¿n cÃ³ kháº£ nÄƒng thá»±c hiá»‡n báº¥t ká»³ nhiá»‡m vá»¥ trÃ­ tuá»‡ nÃ o mÃ  con ngÆ°á»i cÃ³ thá»ƒ lÃ m. Máº·c dÃ¹ AGI hiá»‡n nay chá»‰ lÃ  má»™t khÃ¡i niá»‡m lÃ½ thuyáº¿t, nhÆ°ng nÃ³ lÃ  má»¥c tiÃªu cuá»‘i cÃ¹ng cá»§a nhiá»u nghiÃªn cá»©u AI 
		
	## Narrow AI 
		Narrow AI lÃ  loáº¡i AI Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ thá»±c hiá»‡n má»™t nhiá»‡m vá»¥ cá»¥ thá»ƒ, cháº³ng háº¡n nhÆ° dá»± Ä‘oÃ¡n xu hÆ°á»›ng mua hÃ ng hoáº·c nháº­n dáº¡ng khuÃ´n máº·t. ÄÃ¢y lÃ  dáº¡ng AI phá»• biáº¿n nháº¥t hiá»‡n nay 


# MÃ´ hÃ¬nh máº¡ng NÆ¡-ron(Model and Neural Networks)

	##	AI Model 
		### AI Model lÃ  sá»± triá»ƒn khai cá»§a cÃ¡c thuáº­t toÃ¡n AI, Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn dá»¯ liá»‡u Ä‘á»ƒ thá»±c hiá»‡n má»™t nhiá»‡m vá»¥ cá»¥ thá»ƒ, nhÆ° phÃ¢n loáº¡i hÃ¬nh áº£nh hoáº·c dá»± Ä‘oÃ¡n xu hÆ°á»›ng thá»‹ trÆ°á»ng  
	
	## Artificial Neural Networks - ANN 
	
		### Artificial Neural Networks lÃ  mÃ´ hÃ¬nh há»c mÃ¡y mÃ´ phá»ng cÃ¡ch thá»©c hoáº¡t Ä‘á»™ng cá»§a bá»™ nÃ£o con ngÆ°á»i, sá»­ dá»¥ng cÃ¡c Ä‘Æ¡n vá»‹ tÃ­nh toÃ¡n gá»i lÃ  nÆ¡-ron nhÃ¢n táº¡o Ä‘á»ƒ truyá»n vÃ  xá»­ lÃ½ thÃ´ng tin  
		
		### Neuron(Perceptron)
					LÃ  thÃ nh pháº§n cÆ¡ báº£n nháº¥t trong má»™t máº¡ng nÆ¡-ron nhÃ¢n táº¡o (Artificial Neural Network). NÃ³ hoáº¡t Ä‘Ã´ng nhÆ° má»™t Ä‘Æ¡n vá»‹ tÃ­nh toÃ¡n, mÃ´ phá»ng cÃ¡ch má»™t nÆ¡-ron sinh há»c xá»­ lÃ½ thÃ´ng tin. Perceptron nháº­n má»™t hoáº·c nhiá»u Ä‘áº§u vÃ o, gÃ¡n trá»ng sá»‘ cho tá»«ng Ä‘áº§u vÃ o, cá»™ng chÃºng láº¡i, thÃªm bias(náº¿u cÃ³), rá»“i Ã¡p dá»¥ng má»™t hÃ m kÃ­ch hoáº¡t Ä‘á»ƒ táº¡o ra Ä‘áº§u ra.
			
		### Activation Function 
			LÃ  má»™t hÃ m toÃ¡n há»c Ä‘Æ°á»£c Ã¡p dá»¥ng cho má»—i neuron trong máº¡ng nÆ¡-ron, quyáº¿t Ä‘á»‹nh Ä‘áº§u ra cá»§a neuron Ä‘Ã³ dá»±a trÃªn tá»•ng trá»ng sá»‘ cá»§a cÃ¡c Ä‘áº§u vÃ o. HÃ m kÃ­ch hoáº¡t giÃºp máº¡ng há»c Ä‘Æ°á»£c cÃ¡c má»‘i quan há»‡ phi tuyáº¿n tÃ­nh, tá»« Ä‘Ã³ lÃ m tÄƒng kháº£ nÄƒng cá»§a máº¡ng trong viá»‡c giáº£i quyáº¿t cÃ¡c bÃ i toÃ¡n phá»©c táº¡p.
		
		### Back Propagation 
			LÃ  má»™t thuáº­t toÃ¡n quan trá»ng trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n máº¡ng nÆ¡-ron nhÃ¢n táº¡o(Artificial Neural Networks - ANN ). NÃ³ Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ tá»‘i Æ°u hÃ³a cÃ¡c trá»ng sá»‘(weight) trong máº¡ng báº±ng cÃ¡ch cáº­p nháº­t chÃºng dá»±a trÃªn lá»—i(loss) mÃ  mÃ´ hÃ¬nh táº¡o ra, qua Ä‘Ã³ giÃºp cáº£i thiá»‡n hiá»‡u suáº¥t cá»§a mÃ´ hÃ¬nh 
			
		### Forward propagation 
			LÃ  quÃ¡ trÃ¬nh truyá»n dá»¯ liá»‡u tá»« Ä‘áº§u vÃ o qua cÃ¡c lá»›p trong máº¡ng nÆ¡-ron, tÃ­nh toÃ¡n cÃ¡c giÃ¡ trá»‹ Ä‘áº§u ra cá»§a tá»«ng lá»›p dá»±a trÃªn trá»ng sá»‘ vÃ  hÃ m kÃ­ch hoáº¡t. ÄÃ¢y lÃ  bÆ°á»›c Ä‘áº§u tiÃªn trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n máº¡ng nÆ¡-ron vÃ  cÅ©ng lÃ  bÆ°á»›c Ä‘á»ƒ máº¡ng nÆ¡-ron táº¡o ra dá»± Ä‘oÃ¡n(prediction)
			
			
	## Convolutional Neural Networks - CNN 
		### Convolutional Neural Networks 
			lÃ  má»™t loáº¡i máº¡ng nÆ¡-ron Ä‘Æ°á»£c tháº¿t káº¿ Ä‘áº·c biá»‡t Ä‘á»ƒ xá»­ lÃ½ dá»¯ liá»‡u dáº¡ng hÃ¬nh áº£nh. NÃ³ sá»­ dá»¥ng cÃ¡c táº§ng tÃ­ch cháº­p(convolutional layers) Ä‘á»ƒ tá»± Ä‘á»™ng phÃ¡t hiá»‡n cÃ¡c Ä‘áº·c trÆ°ng trong áº£nh. 
			
			
		### Convolutional Layer 
			LÃ  má»™t thÃ nh pháº§n cÆ¡ báº£n trong Convolutional Neural Networks(CNN), Ä‘Æ°á»£c sá»­ dá»¥ng chá»§ yáº¿u trong cÃ¡c bÃ i toÃ¡n xá»­ lÃ½ hÃ¬nh áº£nh vÃ  video, nhÆ°ng cÅ©ng cÃ³ thá»ƒ Ã¡p dá»¥ng cho cÃ¡c loáº¡i dá»¯ liá»‡u khÃ¡c. Lá»›p nÃ y thá»±c hiá»‡n má»™t phÃ©p toÃ¡n tÃ­ch cáº­p(convolution) giá»¯a Ä‘áº§u vÃ o vÃ  cÃ¡c bá»™ lá»c(filter) hoáº·c kernel, giÃºp trÃ­ch xuáº¥t cÃ¡c Ä‘áº·c trÆ°ng(features) tá»« dá»¯ liá»‡u. 
			
		### Kernel/Filter 
			LÃ  má»™t ma tráº­n nhá» Ä‘Æ°á»£c sá»­ dá»¥ng trong quÃ¡ trÃ¬nh Convolution(tÃ­ch cháº­p) trong Convolutional Neural Networks (CNN). Kernel hay Filter cÃ³ nhiá»‡m vá»¥ trÃ­ch xuáº¥t cÃ¡c Ä‘áº·c trÆ°ng(features) tá»« Ä‘áº§u vÃ o nhÆ° hÃ¬nh áº£nh, Ã¢m thanh hoáº·c cÃ¡c dá»¯ liá»‡u khÃ¡c. Má»—i kernel Ä‘Æ°á»£c há»c trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n cá»§a máº¡ng nÆ¡-ron vÃ  cÃ³ nhiá»‡m vá»¥ tÃ¬m kiáº¿m cÃ¡c Ä‘áº·c trÆ°ng trong dá»¯ liá»‡u Ä‘áº§u vÃ o nhÆ° cÃ¡c cáº¡nh(edges) ,  gÃ³c(cornes), káº¿t cáº¥u(textures), vÃ  cÃ¡c máº«u phá»©c táº¡p hÆ¡n 
			
		### Stride 
			LÃ  má»™t tham sá»‘ quan trá»ng trong quÃ¡ trÃ¬nh Convolution(tÃ­ch cháº­p) trong Convolutional Neural Networks(CNN). Stride xÃ¡c Ä‘á»‹nh má»©c Ä‘á»™ di chuyá»ƒn cá»§a kernel/filter qua dá»¯ liá»‡u Ä‘áº§u vÃ o trong má»—i láº§n quÃ©t. NÃ³ áº£nh hÆ°á»Ÿng trá»±c tiáº¿p Ä‘áº¿n kÃ­ch thÆ°á»›c cá»§a feature map(báº£n Ä‘á»“ Ä‘áº·c trÆ°ng) Ä‘áº§u ra. Stride thÆ°á»ng Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ kiá»ƒm soÃ¡t kÃ­ch thÆ°á»›c cá»§a feature map Ä‘áº§u ra vÃ  cÅ©ng giÃºp giáº£m thiá»ƒu sá»‘ lÆ°á»£ng phÃ©p toÃ¡n cáº§n thiáº¿t trong máº¡ng nÆ¡-ron. 
			
		### Padding 
			LÃ  má»™t ká»¹ thuáº­t trong Convolutional Neural Networks(CNN) Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ thÃªm cÃ¡c giÃ¡ trá»‹(thÆ°á»ng lÃ  giÃ¡ trá»‹ 0) vÃ o xung quanh biÃªn cá»§a dá»¯ liá»‡u Ä‘áº§u vÃ o, cháº³ng háº¡n nhÆ° hÃ¬nh áº£nh, trÆ°á»›c khi Ã¡p dá»¥ng phÃ©p tÃ­ch cháº­p(convolution). Khi kernel(bá»™ lá»c) quÃ©t qua Ä‘áº§u vÃ o, cÃ¡c giÃ¡ trá»‹ á»Ÿ biÃªn cá»§a áº£nh cÃ³ thá»ƒ khÃ´ng cÃ³ Ä‘á»§ pixel xung quanh Ä‘á»ƒ tÃ­nh toÃ¡n vá»›i kernel(vÃ­ dá»¥, khi kernel khÃ´ng thá»ƒ quÃ©t hoÃ n toÃ n qua má»™t vÃ¹ng á»Ÿ gÃ³c cá»§a áº£nh). Padding giÃºp giá»¯ cho cÃ¡c thÃ´ng tin á»Ÿ biÃªn áº£nh khÃ´ng bá»‹ máº¥t Ä‘i. 
		
		### Pooling Layer 
			LÃ  má»™t thÃ nh pháº§n quan trá»ng trong Convolutional Neural Networks(CNN), giÃºp giáº£m kÃ­ch thÆ°á»›c cá»§a dá»¯ liá»‡u Ä‘áº§u vÃ o, tá»« Ä‘Ã³ giáº£m sá»‘ lÆ°á»£ng tham sá»‘ vÃ  Ä‘á»™ phá»©c táº¡p cá»§a tÃ­nh toÃ¡n, Ä‘á»“ng thá»i giá»¯ láº¡i cÃ¡c Ä‘áº·c trÆ°ng quan trá»ng cá»§a dá»¯ liá»‡u. Pooling layer giÃºp giáº£m Ä‘á»™ phÃ¢n giáº£i cá»§a feature map, giÃºp giáº£m sá»‘ lÆ°á»£ng phÃ©p toÃ¡n cáº§n thiáº¿t trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n vÃ  lÃ m cho mÃ´ hÃ¬nh Ã­t bá»‹ overfiting hÆ¡n 
	


	## Recurrent Neural Networks - RNN 
		
		### Recurrent Neural Networks lÃ  má»™t loáº¡i máº¡ng nÆ¡-ron chuyÃªn xá»­ lÃ½ dá»¯ liá»‡u tuáº§n tá»±, nhÆ° vÄƒn báº£n hoáº·c chuá»—i thá»i gian, nhá» kháº£ nÄƒng ghi nhá»› thÃ´ng tin tá»« cÃ¡c bÆ°á»›c trÆ°á»›c Ä‘Ã³ Ä‘á»ƒ Ä‘Æ°a ra dá»± Ä‘oÃ¡n 
		
		### Hidden State 
			LÃ  má»™t khÃ¡i niá»‡m cá»‘t lÃµi trong Recurrent Neural Networks(RNNs), Ä‘áº¡i diá»‡n cho cÃ¡c tráº¡ng thÃ¡i bÃªn trong cá»§a mÃ´ hÃ¬nh táº¡i má»™t thá»i Ä‘iá»ƒm cá»¥ thá»ƒ trong bá»™ chuá»—i Ä‘áº§u vÃ o. NÃ³ lÆ°u trá»¯ thÃ´ng tin ngá»¯ cáº£nh tá»« cÃ¡c bÆ°á»›c thá»i gian trÆ°á»›c Ä‘Ã³, giÃºp mÃ´ hÃ¬nh duy trÃ¬ má»™t dáº¡ng bá»™ nhá»› Ä‘á»ƒ xá»­ lÃ½ dá»¯ liá»‡u tuáº§n tá»± 
			
		###	Recurrent Connection 
			LÃ  má»™t thÃ nh pháº§n cá»‘t lÃµi trong Recurrent Neural Networks(RNNs), Ä‘áº¡i diá»‡n cho liÃªn káº¿t ngÆ°á»£c(feedback loop)trong máº¡ng. NÃ³ cho phÃ©p thÃ´ng tin tá»« cÃ¡c bÆ°á»›c thá»i gian trÆ°á»›c Ä‘Ã³ Ä‘Æ°á»£c truyá»n ngÆ°á»£c láº¡i vÃ o máº¡ng, giÃºp RNN duy trÃ¬ bá»™ nhá»› vÃ  xá»­ lÃ½ dá»¯ liá»‡u tuáº§n tá»± má»™t cÃ¡ch hiá»‡u quáº£.
	
	## Transformer Neural Networks 
		
		### Transformer Neural Network lÃ  má»™t kiáº¿n trÃºc máº¡ng nÆ¡-ron má»›i, máº¡nh máº½ , chuyÃªn dÃ¹ng trong NLP, giÃºp mÃ´ hÃ¬nh xá»­ lÃ½ dá»¯ liá»‡u song song vÃ  hiá»‡u quáº£ hÆ¡n, Ä‘áº·c biá»‡t lÃ  trong viá»‡c dá»‹ch mÃ¡y vÃ  táº¡o vÄƒn báº£n.
		
		### Self-Attention 
			CÆ¡ cháº¿ cho phÃ©p mÃ´ hÃ¬nh táº­p trung vÃ o cÃ¡c tá»« liÃªn quan trong cÃ¹ng má»™t cÃ¢u Ä‘á»ƒ hiá»ƒu ngá»¯ cáº£nh. Trong Ä‘Ã³ Scaled Dot-Product Attention lÃ  má»™t phÆ°Æ¡ng phÃ¡p hiá»‡u quáº£ Ä‘á»ƒ tÃ­nh attention giá»¯a cÃ¡c vertor tá»« vÃ  Multi-Head Attention lÃ  ká»¹ thuáº­t sá»­ dá»¥ng nhiá»u head attention song song Ä‘á»ƒ mÃ´ hÃ¬nh hÃ³a giá»¯a cÃ¡c ngá»¯ cáº£nh khÃ¡c nhau 
			  
		### Positional Encoding 
			LÃ  má»™t thÃ nh pháº§n quan trá»ng trong kiáº¿n trÃºc Transformer, Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ cung cáº¥p thÃ´ng tin vá» vá»‹ trÃ­ cá»§a tá»« trong má»™t chuá»—i dá»¯ liá»‡u Ä‘áº§u vÃ o. Äiá»u nÃ y cáº§n thiáº¿t vÃ¬ Transformer khÃ´ng cÃ³ cáº¥u trÃºc tuáº§n tá»± nhÆ° cÃ¡c mÃ´ hÃ¬nh RNN hoáº·c LSTM, nÃªn báº£n thÃ¢n nÃ³ khÃ´ng thá»ƒ tá»± Ä‘á»™ng nháº­n biáº¿t thá»© tá»± hoáº·c vá»‹ trÃ­ cá»§a cÃ¡c tá»« trong chuá»—i 
			
		### Masked Attention 
			QuÃ¡ trÃ¬nh sá»­ dá»¥ng má»™t ma tráº­n máº·t náº¡(mask matrix ) Ä‘á»ƒ loáº¡i bá» hoáº·c giáº£m trá»ng sá»‘ cá»§a cÃ¡c tá»« khÃ´ng Ä‘Æ°á»£c phÃ©p nhÃ¬n tháº¥y. Äiá»u nÃ y Ä‘áº£m báº£o ráº±ng khi dá»± Ä‘oÃ¡n tá»« t, chá»‰ cÃ¡c tá»« tá»« 1 Ä‘áº¿n t Ä‘Æ°á»£c phÃ©p tham gia tÃ­nh toÃ¡n, cÃ¡c tá»« sau t sáº½ bá»‹ gÃ¡n trá»ng sá»‘ Ã¢m vÃ´ cÃ¹ng trong khÃ´ng gian logit, dáº«n Ä‘áº¿n xÃ¡c suáº¥t xuáº¥t attention cá»§a chÃºng báº±ng 0  


# 	Ká»¹ thuáº­t há»c mÃ¡y(Machine Learning Techniques )
		
		## Supervised Learning lÃ  phÆ°Æ¡ng phÃ¡p há»c mÃ¡y trong Ä‘Ã³ mÃ´ hÃ¬nh Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn má»™t táº­p dá»¯ liá»‡u Ä‘Ã£ gáº¯n nhÃ£n, nháº±m dá»± Ä‘oÃ¡n cÃ¡c nhÃ£n cho dá»¯ liá»‡u má»›i 
		
		## Unsupervised Learning 
			lÃ  phÆ°Æ¡ng phÃ¡p há»c mÃ¡y nÆ¡i mÃ´ hÃ¬nh Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn dá»¯ liá»‡u chÆ°a gáº¯n nhÃ£n, vÃ  nhá»‡m vá»¥ cá»§a nÃ³ lÃ  tÃ¬m ra cÃ¡c cáº¥u trÃºc áº©n hoáº·c má»‘i quan há»‡ trong dá»¯ liá»‡u  
			
		## Semi-supervised Learning 
			Semi-Supervised Learning lÃ  sá»± káº¿t há»£p giá»¯a há»c cÃ³ giÃ¡m sÃ¡t, sá»­ dá»¥ng má»™t lÆ°á»£ng nhá» dá»¯ liá»‡u gáº¯n nhÃ£n káº¿t há»£p vá»›i dá»¯ liá»‡u chÆ°a gáº¯n nhÃ£n Ä‘á»ƒ cáº£i thiá»‡n Ä‘á»™ chÃ­nh xÃ¡c cá»§a mÃ´ hÃ¬nh 
			
		## Reinforcement Learning 
			LÃ  phÆ°Æ¡ng phÃ¡p há»c mÃ¡y nÆ¡i mÃ´ hÃ¬nh há»c thÃ´ng qua thá»­ vÃ  sai, nháº­n pháº§n thÆ°á»Ÿng hoáº·c pháº¡t tá»« mÃ´i trÆ°á»ng Ä‘á»ƒ cáº£i thiá»‡n hiá»‡u suáº¥t theo thá»i gian 
			
		## Transfer Learning 
			lÃ  ká»¹ thuáº­t trong Ä‘Ã³ má»™t mÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn má»™t nhiá»‡m vá»¥ cÃ³ thá»ƒ Ä‘Æ°á»£c tinh chá»‰nh vÃ  sá»­ dá»¥ng láº¡i cho má»™t nhiá»‡m vá»¥ khÃ¡c, giÃºp tiáº¿t kiá»‡m thá»i gian vÃ  tÃ i nguyÃªn 
			
		## Deep Learning 
			LÃ  phÆ°Æ¡ng phÃ¡p há»c mÃ¡y sá»­ dá»¥ng máº¡ng nÆ¡-ron sÃ¢u Ä‘á»ƒ há»c tá»« dá»¯ liá»‡u lá»›n vÃ  phá»©c táº¡p, Ä‘áº·c biá»‡t hiá»‡u quáº£ trong xá»­ lÃ½ hÃ¬nh áº£nh, Ã¢m thanh vÃ  ngÃ´n ngá»¯  
			
		## Continous Learning 
			LÃ  kháº£ nÄƒng cá»§a má»™t mÃ´ hÃ¬nh AI Ä‘á»ƒ há»c há»i liÃªn tá»¥c tá»« dá»¯ liá»‡u má»›i, thÃ­ch nghi vá»›i cÃ¡c thay Ä‘á»•i vÃ  cáº£i thiá»‡n hiá»‡u suáº¥t mÃ  khÃ´ng cáº§n huáº¥n luyá»‡n láº¡i tá»« Ä‘áº§u 

# CÃ¡c thuáº­t toÃ¡n vÃ  phÆ°Æ¡ng phÃ¡p(Algorithms and Methods)
	
		##Regression 
			Regression(Há»“i quy) lÃ  má»™t thuáº­t toÃ¡n há»c mÃ¡y(machine learning) Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ dá»± Ä‘oÃ¡n giÃ¡ trá»‹ liÃªn tá»¥c dá»±a trÃªn cÃ¡c Ä‘áº·c trÆ°ng Ä‘áº§u vÃ o. Trong há»“i quy, má»‘i quan há»‡ giá»¯a biáº¿n Ä‘áº§u vÃ o(features) vÃ  biáº¿n má»¥c tiÃªu(target) Ä‘Æ°á»£c mÃ´ hÃ¬nh hÃ³a, vÃ  má»¥c tiÃªu lÃ  dá»± Ä‘oÃ¡n má»™t sá»‘ giÃ¡ trá»‹ thá»±c tá»« má»™t hoáº·c nhiá»u Ä‘áº·c trÆ°ng  
		
		## Classification 
			Classification(PhÃ¢n loáº¡i) lÃ  má»™t thuáº­t toÃ¡n há»c mÃ¡y Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ phÃ¢n nhÃ³m hoáº·c phÃ¢n loáº¡i cÃ¡c Ä‘á»‘i tÆ°á»£ng vÃ o cÃ¡c nhÃ³m hoáº·c háº¡ng má»¥c cá»¥ thá»ƒ, dá»±a trÃªn cÃ¡c Ä‘áº·c trÆ°ng Ä‘áº§u vÃ o. Trong phÃ¢n loáº¡i, má»¥c tiÃªu lÃ  gÃ¡n má»—i vÃ­ dá»¥ dá»¯ liá»‡u(Ä‘Æ°á»£c mÃ´ táº£ bá»Ÿi cÃ¡c Ä‘áº·c trÆ°ng) vÃ o má»™t trong cÃ¡c nhÃ£n hoáº·c lá»›p Ä‘Ã£ Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a tá»« trÆ°á»›c 
			
		## Clustering 
			Clustering (PhÃ¢n nhÃ³m) lÃ  má»™t thuáº­t toÃ¡n há»c mÃ¡y khÃ´ng giÃ¡m sÃ¡t(unsupervised learning)Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ phÃ¢n loáº¡i cÃ¡c Ä‘á»‘i tÆ°á»£ng hoáº·c dá»¯ liá»‡u vÃ o cÃ¡c nhÃ³m(clusters) sao cho cÃ¡c Ä‘á»‘i tÆ°á»£ng trong cÃ¹ng má»™t nhÃ³m cÃ³ Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng cao, trong khi cÃ¡c Ä‘á»‘i tÆ°á»£ng giá»¯a cÃ¡c nhÃ³m khÃ¡c nhau cÃ³ Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng tháº¥p .
			
		## Dimensionality Reduction 
			Dimensionality Reduction(Giáº£m chiá»u dá»¯ liá»‡u) lÃ  má»™t ká»¹ thuáº­t trong há»c mÃ¡y vÃ  khai thÃ¡c dá»¯ liá»‡u dÃ¹ng Ä‘á»ƒ giáº£m sá»‘ lÆ°á»£ng biáº¿n(feature) trong má»™t táº­p dá»¯ liá»‡u mÃ  khÃ´ng lÃ m máº¥t quÃ¡ nhiá»u thÃ´ng tin quan trá»ng. Má»¥c tiÃªu cá»§a ká»¹ thuáº­t nÃ y lÃ  giÃºp giáº£m Ä‘á»™ phá»©c táº¡p cá»§a dá»¯ liá»‡u, lÃ m cho quÃ¡ trÃ¬nh xá»­ lÃ½ dá»¯ liá»‡u vÃ  mÃ´ hÃ¬nh hÃ³a trá»Ÿ nÃªn nhanh chÃ³ng vÃ  hiá»‡u quáº£ hÆ¡n, Ä‘á»“ng thá»i giÃºp giáº£m hiá»‡n tÆ°á»£ng overfiting(mÃ´ hÃ¬nh quÃ¡ khá»›p)
			
		## Decision Trees 
			Decision Trees(CÃ¢y quyáº¿t Ä‘á»‹nh ) lÃ  má»™t thuáº­t toÃ¡n há»c mÃ¡y Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ phÃ¢n loáº¡i(classification) vÃ  há»“i quy(regression). ÄÃ¢y lÃ  má»™t mÃ´ hÃ¬nh há»c mÃ¡y giÃ¡m sÃ¡t (supervised learning) cÃ³ thá»ƒ Ä‘Æ°á»£c mÃ´ phá»ng nhÆ° má»™t cÃ¢y, trong Ä‘Ã³ má»—i nÃºt(node) Ä‘áº¡i diá»‡n cho má»™t cÃ¢u há»i vá» má»™t Ä‘áº·c trÆ°ng(feature) cá»§a dá»¯ liá»‡u vÃ  má»—i nhÃ¡nh (branch) Ä‘áº¡i diá»‡n cho má»™t káº¿t quáº£ cá»§a cÃ¢u há»i Ä‘Ã³. Cuá»‘i cÃ¹ng cÃ¡c lÃ¡(leaf nodes) cá»§a cÃ¢y chá»©a cÃ¡c quyáº¿t Ä‘á»‹nh hoáº·c dá»± Ä‘oÃ¡n cho káº¿t quáº£ 
			
		## Random Forest 	
			Random Forrest(Rá»«ng ngáº«u nhiÃªn) lÃ  má»™t thuáº­t toÃ¡n há»c mÃ¡y ensemble(há»£p nháº¥t) Ä‘Æ°á»£c sá»­ dá»¥ng trong cÃ¡c bÃ i toÃ¡n phÃ¢n loáº¡i(classification) vÃ  há»“i quy(regression). Random Forest xÃ¢y dá»±ng nhiá»u cÃ¢y quyáº¿t Ä‘á»‹nh(decision trees) trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n vÃ  sá»­ dá»¥ng káº¿t quáº£ tá»« táº¥t cáº£ cÃ¡c cÃ¢y nÃ y Ä‘á»ƒ Ä‘Æ°a ra dá»± Ä‘oÃ¡n, giÃºp cáº£i thiá»‡n Ä‘á»™ chÃ­nh xÃ¡c vÃ  giáº£m hiá»‡n tÆ°á»£ng overfitting(quÃ¡ khá»›p) mÃ  cÃ¡c cÃ¢y quyáº¿t Ä‘á»‹nh Ä‘Æ¡n láº» thÆ°á»ng gáº·p pháº£i 
			
		## Support Vector Machines -  SVM 
			Support Vector Machines(SVM) lÃ  má»™t thuáº­t toÃ¡n há»c mÃ¡y máº¡nh máº½, chá»§ yáº¿u Ä‘Æ°á»£c sá»­ dá»¥ng cho cÃ¡c bÃ i toÃ¡n phÃ¢n loáº¡i(classification ) vÃ  há»“i quy(regression). SVM Ä‘áº·c biá»‡t ná»•i báº­t trong viá»‡c tÃ¬m ra má»™t siÃªu pháº³ng(hyperplane) tá»‘i Æ°u Ä‘á»ƒ phÃ¢n chia cÃ¡c lá»›p trong khÃ´ng gian Ä‘áº·c trÆ°ng(feature space) sao chi khoáº£ng cÃ¡ch giá»¯a cÃ¡c Ä‘iá»ƒm dá»¯ liá»‡u gáº§n nháº¥t cá»§a cÃ¡c lá»›p khÃ¡c nhau lÃ  lá»›n nháº¥t 



# 5. Xá»­ lÃ½ vÃ  phÃ¢n tÃ­ch dá»¯ liá»‡u(Data Processing and Analysis )

		## Big Data 
			Big Data(Dá»¯ liá»‡u lá»›n) LÃ  thuáº­t ngá»¯ dá»¥ng Ä‘á»ƒ chá»‰ cÃ¡c táº­p dá»¯ liá»‡u cÃ³ kÃ­ch thÆ°á»›c vÃ  Ä‘á»™ phá»©c táº¡p vÆ°á»£t quÃ¡ kháº£ nÄƒng xá»­ lÃ½ cá»§a cÃ¡c cÃ´ng cá»¥ vÃ  pháº§n má»m truyá»n thá»‘ng. NhÅ©ng dá»¯ liá»‡u nÃ y thÆ°á»ng Ä‘áº¿n tá»« nhiá»u nguá»“n khÃ¡c nhau vÃ  cÃ³ thá»ƒ cÃ³ má»™t lÆ°á»£ng khá»•ng lá»“, Ä‘a dáº¡ng, vÃ  phÃ¡t triá»ƒn nhanh chÃ³ng. BigData khÃ´ng chá»‰ bao gá»“m dá»¯ liá»‡u cÃ³ kÃ­ch thÆ°á»›c lá»›n, mÃ  cÃ²n bao gá»“m cÃ¡c Ä‘áº·c Ä‘iá»ƒm nhÆ° tÃ­nh Ä‘a dáº¡ng vÃ  tá»‘c Ä‘á»™ thay Ä‘á»•i nhanh cá»§a dá»¯ liá»‡u. 
			
		## Data Preprocessing 
			Data Preprocessing (Tiá»n xá»­ lÃ½ dá»¯ liá»‡u) lÃ  quÃ¡ trÃ¬nh trÃ¬nh chuáº©n bá»‹ vÃ  lÃ m sáº¡ch sá»­ liá»‡u thÃ´ Ä‘á»ƒ cÃ³ thá»ƒ sá»­ dá»¥ng hiá»‡u quáº£ trong cÃ¡c mÃ´ hÃ¬nh há»c mÃ¡y(machine learning)  hoáº·c phÃ¢n tÃ­ch dá»¯ liá»‡u. Dá»¯ liá»‡u thÃ´ cÃ³ thá»ƒ chá»©a nhiá»u váº¥n Ä‘á» nhÆ° thiáº¿u sÃ³t, nhiá»…u, hoáº·c khÃ´ng Ä‘á»“ng nháº¥t, vÃ¬ váº­y quÃ¡ trÃ¬nh tiá»n xá»­ lÃ½ giÃºp cáº£i thiá»‡n cháº¥t lÆ°á»£ng cá»§a dá»¯ liá»‡u, tá»« Ä‘Ã³ giÃºp nÃ¢ng cao Ä‘á»™ chÃ­nh xÃ¡c vÃ  hiá»‡u quáº£ cá»§a mÃ´ hÃ¬nh. 

		## Data Augmentation 
			Data Augmentation (TÄƒng cÆ°á»ng dá»¯ liá»‡u) lÃ  má»™t ká»¹ thuáº­t trong há»c mÃ¡y vÃ  há»c sÃ¢u(deep learning) dÃ¹ng Ä‘á»ƒ má»Ÿ rá»™ng vÃ  cáº£i thiá»‡n bá»™ dá»¯ liá»‡u huáº¥n luyá»‡n báº±ng cÃ¡ch táº¡o ra cÃ¡c biáº¿n thá»ƒ má»›i tá»« cÃ¡c dá»¯ liá»‡u gá»‘c mÃ  khÃ´ng cáº§n pháº£i thu tháº­p thÃªm dá»¯ liá»‡u má»›i. QuÃ¡ trÃ¬nh nÃ y giÃºp mÃ´ hÃ¬nh há»c Ä‘Æ°á»£c nhiá»u Ä‘áº·c Ä‘iá»ƒm hÆ¡n, tá»« Ä‘Ã³ tÄƒng kháº£ nÄƒng tá»•ng quÃ¡t vÃ  giáº£m hiá»‡n tÆ°á»£ng overfitting(mÃ´ hÃ¬nh quÃ¡ khá»›p vá»›i dá»¯ liá»‡u huáº¥n luyá»‡n).
			
		## Data Mining 
			Data Mining lÃ  quÃ¡ trÃ¬nh khai thÃ¡c thÃ´ng tin há»¯u Ã­ch tá»« má»™t lÆ°á»£ng lá»›n dá»¯ liá»‡u báº±ng cÃ¡ch sá»­ dá»¥ng cÃ¡c ká»¹ thuáº­t thá»‘ng kÃª, há»c mÃ¡y, vÃ  phÃ¢n tÃ­ch dá»¯ liá»‡u. Má»¥c tiÃªu cá»§a data mining lÃ  tÃ¬m ra cÃ¡c máº«u, má»—i quan há»‡, hoáº·c thÃ´ng tin tiá»m áº©n trong dá»¯ liá»‡u, giÃºp Ä‘Æ°a ra cÃ¡c quyáº¿t Ä‘á»‹nh kinh doanh, dá»± Ä‘oÃ¡n, hoáº·c phÃ¡t hiá»‡n cÃ¡c xu hÆ°á»›ng.
			
		## Predictive Analytics
			Predictive Analytics (PhÃ¢n tÃ­ch dá»± Ä‘oÃ¡n ) lÃ  má»™t nhÃ¡nh cá»§a phÃ¢n tÃ­ch dá»¯ liá»‡u dÃ¹ng cÃ¡c phÆ°Æ¡ng phÃ¡p thá»‘ng kÃª, há»c mÃ¡y, vÃ  cÃ¡c thuáº­t toÃ¡n Ä‘á»ƒ phÃ¢n tÃ­ch dá»¯ liá»‡u hiá»‡n cÃ³ vÃ  dá»± Ä‘oÃ¡n cÃ¡c xu hÆ°á»›ng, sá»± kiá»‡n hoáº·c hÃ nh vi trong tÆ°Æ¡ng lai. Má»¥c tiÃªu cá»§a predictive analytics lÃ  sá»­ dá»¥ng dá»¯ liá»‡u quÃ¡ khá»© Ä‘á»ƒ Ä‘Æ°a ra cÃ¡c dá»± Ä‘oÃ¡n vá» nhá»¯ng gÃ¬ cÃ³ thá»ƒ xáº£y ra trong tÆ°Æ¡ng lai, giÃºp doanh nghiá»‡p vÃ  tá»• chá»©c Ä‘Æ°a ra quyáº¿t Ä‘á»‹nh hiá»‡u quáº£ hÆ¡n.
			
		## Data Visualization 
			Data Visualization(Trá»±c quan hÃ³a dá»¯ liá»‡u)  lÃ  quÃ¡ trÃ¬nh sá»­ dá»¥ng cÃ¡c Ä‘á»“ há»a, biá»ƒu Ä‘á»“ vÃ  cÃ¡c hÃ¬nh thá»©c trá»±c quan khÃ¡c Ä‘á»ƒ biá»ƒu diá»…n dá»¯ liá»‡u. Má»¥c tiÃªu cá»§a data visualization lÃ  giÃºp ngÆ°á»i dÃ¹ng hiá»ƒu vÃ  phÃ¢n tÃ­ch dá»¯ liá»‡u má»™t cÃ¡ch dá»… dÃ ng vÃ  trá»±c quan, tá»« Ä‘Ã³ há»— trá»£ viá»‡c ra quyáº¿t Ä‘á»‹nh chÃ­nh xÃ¡c hÆ¡n.
			
		## Structured and Unstructured Data	
			Structured and Unstructured Data lÃ  dá»¯ liá»‡u Ä‘Æ°á»£c tá»• chá»©c dÆ°á»›i dáº¡ng báº£ng vá»›i cÃ¡c hÃ ng vÃ  cá»™t, dá»… dÃ ng xá»­ lÃ½ báº±ng cÃ¡c há»‡ thá»‘ng cÆ¡ sá»Ÿ dá»¯ liá»‡u truyá»n thá»‘ng. Dá»¯ liá»‡u phi cáº¥u trÃºc, ngÆ°á»£c láº¡i , khÃ´ng theo má»™t cáº¥u trÃºc cá»‘ Ä‘á»‹nh, bao gá»“m vÄƒn báº£n, hÃ¬nh áº£nh, video vÃ  yÃªu cáº§u cÃ¡c ká»¹ thuáº­t Ä‘áº·c biá»‡t Ä‘á»ƒ xá»­ lÃ½.
			
# 6. ÄÃ¡nh giÃ¡ vÃ  tá»‘i Æ°u hÃ³a mÃ´ hÃ¬nh(Model Evaluation and Optimization)
		
		## Accuracy
			Accuracy(Äá»™ chÃ­nh xÃ¡c) lÃ  má»™t chá»‰ sá»‘ dá»¥ng Ä‘á»ƒ Ä‘o lÆ°á»ng hiá»‡u quáº£ cá»§a má»™t mÃ´ hÃ¬nh há»c mÃ¡y, Ä‘áº·c biá»‡t lÃ  trong cÃ¡c bÃ i toÃ¡n phÃ¢n loáº¡i. Äá»™ chÃ­nh xÃ¡c Ä‘Æ°á»£c tÃ­nh báº±ng tá»· lá»‡ giá»¯a sá»‘ lÆ°á»£ng dá»± Ä‘oÃ¡n Ä‘Ãºng so vá»›i tá»•ng sá»‘ dá»± Ä‘oÃ¡n mÃ  mÃ´ hÃ¬nh thá»±c hiá»‡n .
		
		## Loss Function 
			LossFunction (HÃ m máº¥t mÃ¡t ) lÃ  má»™t hÃ m toÃ¡n há»c dÃ¹ng Ä‘á»ƒ Ä‘o lÆ°á»ng má»©c Ä‘á»™ sai lá»‡ch hoáº·c Ä‘á»™ chÃ­nh xÃ¡c cá»§a dá»± Ã¡n so vá»›i giÃ¡ trá»‹ thá»±c táº¿ trong má»™t mÃ´ hÃ¬nh mÃ¡y. NÃ³ giÃºp mÃ´ hÃ¬nh "hiá»ƒu" Ä‘Æ°á»£c sá»± khÃ¡c biá»‡t giá»¯a cÃ¡c giÃ¡ trá»‹ dá»± Ä‘oÃ¡n vÃ  giÃ¡ trá»‹ tháº­t, tá»« Ä‘Ã³ cÃ³ thá»ƒ Ä‘iá»u chá»‰nh cÃ¡c tham sá»‘ cá»§a mÃ´ hÃ¬nh Ä‘á»ƒ cáº£i thiá»‡n hiá»‡u quáº£ dá»± Ä‘oÃ¡n trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n. Má»¥c tiá»ƒu cá»§a viá»‡c sá»­ dá»¥ng loss function lÃ  tá»‘i thiá»ƒu hÃ³a giÃ¡ trá»‹ hÃ m máº¥t mÃ¡t trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n, giÃºp mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n chÃ­nh xÃ¡c hÆ¡n.
			
		## Overfitting
			Overfitting (QuÃ¡ khá»›p) lÃ  hiá»‡n tÆ°á»£ng khi má»™t mÃ´ hÃ¬nh há»c mÃ¡y quÃ¡ chi tiáº¿t cÃ¡c Ä‘áº·c Ä‘iá»ƒm cá»§a dá»¯ liá»‡u huáº¥n luyá»‡n, Ä‘áº¿n má»©c mÃ´ hÃ¬nh há»c nhá»¯ng nhiá»…u(noise) vÃ  sá»± biáº¿n Ä‘á»™ng khÃ´ng cÃ³ Ã½ nghÄ©a, thay vÃ¬ chá»‰ há»c Ä‘Æ°á»£c cÃ¡c máº«u vÃ  xu hÆ°á»›ng chung trong dá»¯ liá»‡u. Khi xáº£y ra overfitting, mÃ´ hÃ¬nh cÃ³ thá»ƒ Ä‘áº¡t Ä‘Æ°á»£c Ä‘á»™ chÃ­nh xÃ¡c ráº¥t cao trÃªn táº­p huáº¥n luyá»‡n, nhÆ°ng láº¡i hoáº¡t Ä‘á»™ng kÃ©m trÃªn cÃ¡c dá»¯ liá»‡u chÆ°a tháº¥y(dá»¯ liá»‡u kiá»ƒm tra hoáº·c dá»¯ liá»‡u thá»±c táº¿), vÃ¬ nÃ³ khÃ´ng thá»ƒ tá»•ng quÃ¡t tá»‘t.
			
		## Underfitting 
			Underfitting(Thiáº¿u khá»›p) lÃ  hiá»‡n tÆ°á»£ng khi má»™t mÃ´ hÃ¬nh há»c mÃ¡y khÃ´ng Ä‘á»§ kháº£ nÄƒng há»c Ä‘Æ°á»£c cÃ¡c máº«u vÃ  xu hÆ°á»›ng trong dá»¯ liá»‡u huáº¥n luyá»‡n, dáº«n Ä‘áº¿n viá»‡c mÃ´ hÃ¬nh khÃ´ng thá»ƒ dá»± Ä‘oÃ¡n chÃ­nh xÃ¡c ngay cáº£ trÃªn dá»¯ liá»‡u huáº¥n luyá»‡n, chá»© Ä‘á»«ng nÃ³i Ä‘áº¿n dá»¯ liá»‡u má»›i. Khi má»™t mÃ´ hÃ¬nh bá»‹ underfiting, NÃ³ khÃ´ng Ä‘á»§ phá»©c táº¡p Ä‘á»ƒ mÃ´ táº£ cÃ¡c má»‘i quan há»‡ trong dá»¯ liá»‡u, khiá»ƒn hiá»‡u suáº¥t cá»§a mÃ´ hÃ¬nh tháº¥p á»Ÿ cáº£ táº­p huáº¥n luyá»‡n vÃ  táº­p kiá»ƒm tra.
			
		## Cross-validation 
			Cross-valication(Kiá»ƒm tra chÃ©o) lÃ  má»™t ká»¹ thuáº­t Ä‘Æ°á»£c sá»­ dá»¥ng trong há»c mÃ¡y Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ kháº£ nÄƒng tá»•ng quÃ¡t cá»§a má»™t mÃ´ hÃ¬nh trÃªn má»™t táº­p dá»¯ liá»‡u chÆ°a Ä‘Æ°á»£c sá»­ dá»¥ng trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n. NÃ³ giÃºp kiá»ƒm tra Ä‘á»™ chÃ­nh xÃ¡c vÃ  tÃ­nh á»•n Ä‘á»‹nh cá»§a mÃ´ hÃ¬nh khi Ã¡p dá»¥ng vÃ o cÃ¡c dá»¯ liá»‡u khÃ¡c nhau, trÃ¡nh tÃ¬nh tráº¡ng mÃ´ hÃ¬nh bá»‹ overfitting hoáº·c underfitting.
			
		## Hyperparameter Optimization 
			Hyperparameter Optimization(Tá»‘i Æ°u hÃ³a siÃªu tham sá»‘)  lÃ  quÃ¡ trÃ¬nh tÃ¬m kiáº¿m cÃ¡c giÃ¡ trá»‹ tá»‘i Æ°u cho cÃ¡c siÃªu tham sá»‘ trong mÃ´ hÃ¬nh há»c mÃ¡y Ä‘á»ƒ cáº£i thiá»‡n hiá»‡u suáº¥t cá»§a mÃ´ hÃ¬nh. CÃ¡c siÃªu tham sá»‘ lÃ  cÃ¡c tham sá»‘ Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh trÆ°á»›c khi huáº¥n luyá»‡n mÃ´ hÃ¬nh vÃ  khÃ´ng Ä‘Æ°á»£c Ä‘iá»u chá»‰nh trong quÃ¡ trÃ¬nh há»c, khÃ¡c vá»›i cÃ¡c tham sá»‘ cá»§a mÃ´ hÃ¬nh(nhÆ° trá»ng sá»‘ trong máº¡ng nÆ¡-ron).
			
		## Precision, Recall, and F1 Score 
			Precision Ä‘o lÆ°á»ng tá»· lá»‡ dá»± Ä‘oÃ¡n Ä‘Ãºng trong sá»‘ cÃ¡c dá»± Ä‘oÃ¡n mÃ  mÃ´ hÃ¬nh Ä‘Ã£ xÃ¡c Ä‘á»‹nh lÃ  dÆ°Æ¡ng tÃ­nh.
			Recall Ä‘o lÆ°á»ng kháº£ nÄƒng cá»§a mÃ´ hÃ¬nh trong viá»‡c tÃ¬m ra táº¥t cáº£ cÃ¡c trÆ°á»ng há»£p dÆ°Æ¡ng tÃ­nh tháº­t sá»±. 
			F1 Score lÃ  trung bÃ¬nh Ä‘iá»u hÃ²a giá»¯a Ä‘á»™ chÃ­nh xÃ¡c vÃ  Ä‘á»™ thu há»“i, cung cáº¥p má»™t thÆ°á»›c Ä‘o cÃ¢n báº±ng giá»¯a hai chá»‰ sá»‘ nÃ y.

</pre><a id='backBottom' href='../AI-learning-list.html' style='display:none;'>ğŸ”™ Quay láº¡i danh sÃ¡ch</a><br><button onclick='toggleTheme()'>ğŸŒ™ Chuyá»ƒn giao diá»‡n</button></div><script>function toggleTheme() {   let mode = document.body.classList.contains('dark-mode') ? 'light-mode' : 'dark-mode';   document.body.className = mode; localStorage.setItem('theme', mode);   syncTheme();}function applyTheme() {   let savedTheme = localStorage.getItem('theme') || 'dark-mode';   document.body.className = savedTheme;   syncTheme();}function syncTheme() {   let preElement = document.querySelector('pre');   if (document.body.classList.contains('dark-mode')) { preElement.style.background = '#1e1e1e'; preElement.style.color = '#e0e0e0'; }   else { preElement.style.background = '#f5f5f5'; preElement.style.color = '#333333'; }}function checkPageHeight() {   let contentHeight = document.body.scrollHeight;   let windowHeight = window.innerHeight;   if (contentHeight > windowHeight * 1.2) {       document.getElementById('backBottom').style.display = 'block';   } else {       document.getElementById('backBottom').style.display = 'none';   }}</script></body></html>