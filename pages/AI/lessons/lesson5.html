<html><head><title>Lession 7  Há»“i quy tuyáº¿n tÃ­nh //</title><style>body { font-family: Arial, sans-serif; transition: background 0.3s, color 0.3s; }.dark-mode { background-color: #121212; color: #e0e0e0; }.light-mode { background-color: #ffffff; color: #333333; }h1 { text-align: center; color: #73d9f5; }pre { padding: 15px; border-radius: 5px;       white-space: pre-wrap; word-wrap: break-word;       overflow-x: auto; max-width: 100%;       transition: background 0.3s, color 0.3s; }.dark-mode pre { background: #1e1e1e; color: #e0e0e0; }.light-mode pre { background: #f5f5f5; color: #333333; }#backTop, #backBottom {    font-size: 2em; padding: 20px 40px;    background: #bb86fc; color: white; text-decoration: none;    border-radius: 10px; display: inline-block; text-align: center; }#backTop:hover, #backBottom:hover { background: #9b67e2; }button { font-size: 1.5em; padding: 15px 30px;    background: #03dac6; color: #121212; border: none;    cursor: pointer; border-radius: 5px; display: block; margin: 10px auto; }button:hover { background: #02b8a3; }.dark-mode a { color: #03dac6; } .light-mode a { color: #007bff; }</style></head><body onload='applyTheme(); checkPageHeight()'><div class='container'><a id='backTop' href='../java-learning-list.html'>ğŸ”™ Quay láº¡i danh sÃ¡ch</a><br><h1>Lession 7  Há»“i quy tuyáº¿n tÃ­nh //</h1><pre>
# 1. Giá»›i thiá»‡u 
	
		Há»“i quy tuyáº¿n tÃ­nh lÃ  má»™t ká»¹ thuáº­t thá»‘ng kÃª cÆ¡ báº£n Ä‘Æ°á»£c sá»­ dá»¥ng rá»™ng rÃ£i trong phÃ¢n tÃ­ch dá»¯ liá»‡u vÃ  há»c mÃ¡y. Má»¥c tiÃªu cá»§a há»“i quy tuyáº¿n tÃ­nh lÃ  xÃ¢y dá»±ng má»™t mÃ´ hÃ¬nh toÃ¡n há»c Ä‘á»ƒ dá»± Ä‘oÃ¡n giÃ¡ trá»‹ cá»§a má»™t biáº¿n phá»¥ thuá»™c (output) dá»±a trÃªn má»™t hoáº·c nhiá»u biáº¿n Ä‘á»™c láº­p(input). MÃ´ hÃ¬nh há»“i quy tuyáº¿n tÃ­nh giáº£ Ä‘á»‹nh ráº±ng má»‘i quan há»‡ giá»¯a cÃ¡c biáº¿n nÃ y lÃ  tuyáº¿n tÃ­nh, nghÄ©a lÃ  cÃ³ thá»ƒ biá»ƒu diá»…n dÆ°á»›i dáº¡ng má»™t Ä‘Æ°á»ng tháº³ng trong khÃ´ng gian sá»‘ liá»‡u. 
		https://aicandy.vn/wp-content/uploads/2024/09/aicandy_hoiquytuyentinh.jpg
		
		
		SimpleLinearRegression : Há»“i quy tuyáº¿n tÃ­nh Ä‘Æ¡n giáº£n 
		Multiple Linear Regression : Há»“i quy tuyáº¿n tÃ­nh Ä‘a biáº¿n 
		
		
# 2.  PhÃ¢n loáº¡i : 
	## 2.1 Há»“i quy tuyáº¿n tÃ­nh Ä‘Æ¡n giáº£n 
		Há»“i quy tuyáº¿n tÃ­nh Ä‘Æ¡n giáº£m mÃ´ hÃ¬nh hÃ³a má»‘i quan há»‡ giá»¯a má»™t biáº¿n Ä‘á»™c láº­p X vÃ  má»™t biáº¿n phá»¥ thuá»™c Y . CÃ´ng thá»©c cá»§a mÃ´ hÃ¬nh há»“i quy tuyáº¿n tÃ­nh Ä‘Æ¡n giáº£n lÃ  : 
						
						Y = b0 + b1X + e 
		
		Trong Ä‘Ã³ : 
			- Y lÃ  biáº¿n phá»¥ thuá»™c (output) <mjx-c class="mjx-c1D44C TEX-I"></mjx-c>
			- X lÃ  biáº¿n Ä‘á»™c láº­p (input)		<mjx-c class="mjx-c1D44B TEX-I"></mjx-c>
			- B0 lÃ  háº±ng sá»‘ (intercept)  <mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D6FD TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em;"><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c30"></mjx-c></mjx-mn></mjx-script></mjx-msub>
			- B1 lÃ  há»‡ sá»‘ há»“i quy (slope) , Ä‘áº¡i diá»‡n cho má»©c thay Ä‘á»•i cá»§a Y khi X thay Ä‘á»•i má»™t Ä‘Æ¡n vá»‹   <mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D6FD TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em;"><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-script></mjx-msub>
			- e lÃ  sai sá»‘(error tern), biá»ƒu thá»‹ pháº§n biáº¿n Ä‘á»™ng cá»§a Y khÃ´ng Ä‘Æ°á»£c giáº£i thÃ­ch bá»Ÿi X  <mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D716 TEX-I"></mjx-c></mjx-mi></mjx-math>
			
		#### Trong toÃ¡n há»c 
			- e lÃ  pháº§n chÃªnh lá»‡ch giá»¯a giÃ¡ trá»‹ thá»±c táº¿ y vÃ  giÃ¡ trá»‹ dá»± Ä‘oÃ¡n y^ mÃ  mÃ´ hÃ¬nh tÃ­nh Ä‘Æ°á»£c 
			- NÃ³ biá»ƒu thá»‹ nhá»¯ng yáº¿u tá»‘ khÃ´ng Ä‘Æ°á»£c mÃ´ hÃ¬nh hÃ³a hoáº·c cÃ¡c yáº¿u tá»‘ ngáº«u nhiÃªn khÃ´ng náº±m trong dá»¯ liá»‡u X 
			
		#### Trong AI 
			- Sai sá»‘ e lÃ  má»™t thÆ°á»›c Ä‘o Ä‘á»ƒ mÃ´ hÃ¬nh biáº¿t nÃ³ dá»± Ä‘oÃ¡n kÃ©m chÃ­nh xÃ¡c á»Ÿ má»©c nÃ o 
			- Má»¥c tiÃªu khi huáº¥n luyá»‡n má»™t mÃ´ hÃ¬nh lÃ  lÃ m cho tá»•ng e hoáº·c má»™t dáº¡ng khÃ¡c cá»§a sai sá»‘ nhÆ° bÃ¬nh phÆ°Æ¡ng cá»§a e cÃ ng nhá» cÃ ng tá»‘t, tá»©c lÃ  lÃ m mÃ´ hÃ¬nh khá»›p tá»‘t nháº¥t vá»›i dá»¯ liá»‡u. 
			
		### LiÃªn quan Ä‘áº¿n MachineLearning 
			- Trong há»c mÃ¡y, sai sá»‘ nÃ y Ä‘Æ°á»£c tá»‘i Æ°u hÃ³a qua cÃ¡c phÆ°Æ¡ng phÃ¡p nhÆ° gradient sescent. MÃ´ hÃ¬nh sáº½ Ä‘iá»u chá»‰nh cÃ¡c tham sá»‘ b0, b1 Ä‘á»ƒ giáº£m sai sá»‘ e 
			- Náº¿u e quÃ¡ lá»›n hoáº·c phÃ¢n phá»‘i khÃ´ng ngáº«u nhiÃªn(VÃ­ dá»¥ cÃ³ máº«u hÃ¬nh láº·p láº¡i), Ä‘iá»u nÃ y cho tháº¥y mÃ´ hÃ¬nh chÆ°a phÃ¹ há»£p hoáº·c dá»¯ liá»‡u cÃ³ váº¥n Ä‘á»   
	
	## 2.2  Há»“i quy tuyáº¿n tÃ­nh Ä‘a biáº¿n 
		Há»“i quy tuyáº¿n tÃ­nh Ä‘a biáº¿n má»Ÿ rá»™ng mÃ´ hÃ¬nh trÃªn báº±ng cÃ¡ch sá»­ dá»¥ng nhiá»u biáº¿n Ä‘á»™c láº­p Ä‘á»ƒ dá»± Ä‘oÃ¡n biáº¿n phá»¥ thuá»™c. CÃ´ng thá»©c tá»•ng quÃ¡t cá»§a mÃ´ hÃ¬nh há»“i quy tuyáº¿n tÃ­nh Ä‘a biáº¿n lÃ  : 
			
				Y = B0 + B1.X1 + B2.X2 + ..... + Bn.Xn + e 
				
			- Trong Ä‘Ã³ : 
				X1 , X2 , .... Xn lÃ  cÃ¡c biáº¿n Ä‘á»™c láº­p 
				B1,B2,Bn lÃ  cÃ¡c há»‡ sá»‘ há»“i quy tÆ°Æ¡ng á»©ng, biá»ƒu thá»‹ má»©c thay Ä‘á»•i cá»§a Y má»—i khi Xi thay Ä‘á»•i má»™t Ä‘Æ¡n vá»‹ 
				b0 : LÃ  giÃ¡ trá»‹ y khi cáº£ x1 vÃ  x2 Ä‘á»u báº±ng 0 , Ä‘Ã¢y lÃ  Ä‘iá»ƒm khá»Ÿi Ä‘áº§u trÃªn trá»¥c y 
				b1: lÃ  há»‡ sá»‘ há»“i quy cá»§a x1. NÃ³ cho biáº¿t khi x1 tÄƒng lÃªn 1 Ä‘Æ¡n vá»‹, y sáº½ thay Ä‘á»•i bao nhiÃªu 
				b2 : LÃ  há»‡ sá»‘ há»“i quy cá»§a x2. NÃ³ cho biáº¿t khi x2 tÄƒng lÃªn 1 Ä‘Æ¡n vá»‹ (vá»›i x1 giá»¯ nguyÃªn), y sáº½ thay Ä‘á»•i bao nhiÃªu 
				
			-> MÃ´ hÃ¬nh nÃ y cá»‘ gáº¯ng tÃ¬m ra má»‘i quan há»‡ giá»¯a 2 biáº¿n Ä‘áº§u vÃ o (x1,x2)vÃ  má»™t biáº¿n Ä‘áº§u ra(y). NÃ³ tÃ­nh toÃ¡n Ä‘á»ƒ tÃ¬m ra má»™t máº·t pháº³ng trong khÃ´ng gian 3d sao cho máº·t pháº³ng nÃ y phÃ¹ há»£p nháº¥t vá»›i cÃ¡c Ä‘iá»ƒm dá»¯ liá»‡u  
				
# 3 CÃ¡ch tÃ­nh há»‡ sá»‘ há»“i quy 
	
	Há»‡ sá»‘ há»“i quy B Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh báº±ng cÃ¡ch tá»‘i hiá»ƒu hÃ³a tá»•ng bÃ¬nh phÆ°Æ¡ng sai sá»‘(Residual Sum of Squares - RSS ) 
	giá»¯a giÃ¡ trá»‹ dá»± Ä‘oÃ¡n vÃ  giÃ¡ trá»‹ thá»±c táº¿. PhÆ°Æ¡ng phÃ¡p phá»• biáº¿n nháº¥t Ä‘á»ƒ Æ°á»›c lÆ°á»£ng cÃ¡c há»‡ sá»‘ há»“i quy lÃ  phÆ°Æ¡ng phÃ¡p bÃ¬nh phÆ°Æ¡ng tá»‘i thiá»ƒu (Ordinary Least Squares - OLS )
	
	## PhÆ°Æ¡ng phÃ¡p bÃ¬nh phÆ°Æ¡ng tá»‘i thiá»ƒu 
		CÃ´ng thá»©c Ä‘á»ƒ tÃ­nh há»‡ sá»‘ há»“i quy trong há»“i quy tuyáº¿n tÃ­nh Ä‘Æ¡n giáº£n : 
		### 1. B1 há»‡ sá»‘ gÃ³c 
			<MathJax Original Source>
			\hat{\beta_1} = \frac{\sum_{i=1}^{n} (X_i â€“ \bar{X})(Y_i â€“ \bar{Y})}{\sum_{i=1}^{n} (X_i â€“ \bar{X})^2}
			
			
		- Trong Ä‘Ã³ : 
			b1  vÃ  b0 lÃ  cÃ¡c giÃ¡ trá»‹ Æ°á»›c lÆ°á»£ng cá»§a B1 vÃ  B0. 
			Xi  vÃ  Yi lÃ  cÃ¡c giÃ¡ trá»‹ biáº¿n Ä‘á»™c láº­p cá»§a biáº¿n phá»¥ thuá»™c táº¡i Ä‘iá»ƒm dá»¯ liá»‡u thá»© i 
			X_ vÃ  Y_ lÃ  giÃ¡ trá»‹ trung bÃ¬nh cá»§a X vÃ  Y 
 
â€‹	

	### 2. B0 : Há»‡ sá»‘ cháº·n  
				b0 = y_ - b1 x_
	
		
#4. MÃ´ hÃ¬nh há»“i quy tuyáº¿n tÃ­nh vá»›i Python 
	## 4.1 Thá»±c hiá»‡n há»“i quy tuyáº¿n tÃ­nh Ä‘Æ¡n giáº£n báº±ng Python ()
		
		### e.g VÃ­ dá»¥ vá» cÃ¡ch thá»±c hiá»‡n há»“i quy tuyáº¿n tÃ­nh Ä‘Æ¡n giáº£n báº±ng Python sá»­ dá»¥ng thÆ° viÃªn scikit-learn Ä‘á»ƒ dá»± Ä‘oÃ¡n má»™t biáº¿n y dá»±a trÃªn biáº¿n x 
					import numpy as np
					import matplotlib.pyplot as plt 
					from sklearn.linear_model import LinearRegression 
					
					''' VÃ­ dá»¥ vá» cÃ¡ch thá»±c hiá»‡n há»“i quy tuyáº¿n tÃ­nh Ä‘Æ¡n giáº£n báº±ng Python sá»­ dá»¥ng thÆ° viÃªn scikit-learn'''
					
					# Dá»¯ liá»‡u máº«u 
					X = np.array([1,2,3,4,5]).reshape(-1,1)
					y = np.array([1,3,3,2,5])
					
					# Khá»Ÿi táº¡o mÃ´ hÃ¬nh 
					model = LinearRegression()
					
					# Huáº¥n luyá»‡n mÃ´ hÃ¬nh 
					model.fit(X,y)
					
					# Dá»± Ä‘oÃ¡n 
					y_pred =  model.predict(X)
					
					# Há»‡ sá»‘ há»“i quy 
					print(f"Há»‡ sá»‘ há»“i quy : {model.coef_[0]}")
					print(f"Há»‡ sá»‘ há»“i quy : {model.intercept_}")
					
					# Váº½ Ä‘á»“ thá»‹ 
					plt.scatter(X , y,color='blue')
					plt.plot(X , y_pred , color='red')
					plt.xlabel('X')
					plt.ylabel('Y')
					plt.title('Há»“i quy tuyáº¿n tÃ­nh Ä‘Æ¡n giáº£n')
					plt.show()

			
		### Giáº£i thÃ­ch 
			1. ThÆ° viá»‡n sá»­ dá»¥ng 
				numpy : Xá»­ lÃ½ dá»¯ liá»‡u dÆ°á»›i dáº¡ng máº£ng sá»‘ há»c 
				matplotlib.pyplot:Váº½ Ä‘á»“ thá»‹ Ä‘á»ƒ trá»±c quan hÃ³a dá»¯ liá»‡u 
				sklearn.linear_model.LinearRegression : Cung cáº¥p mÃ´ hÃ¬nh há»“i quy tuyáº¿n tÃ­nh 
			
			2. Dá»¯ liá»‡u máº«u : 
				X = np.array([1,2,3,4,5]).reshape(-1,1): ÄÃ¢y lÃ  biáº¿n Ä‘á»™c láº­p X, Ä‘Æ°á»£c Ä‘á»‹nh dáº¡ng thÃ nh máº£ng cá»™t (vÃ¬ scikit-learn yÃªu cáº§u Ä‘áº§u vÃ o pháº£i cÃ³ Ä‘á»‹nh dáº¡ng nÃ y )
				
				y = np.array([1,3,3,2,5]): LÃ  biáº¿n phá»¥ thuá»™c y mÃ  báº¡n muá»‘n dá»± Ä‘oÃ¡n  
			
			3. Khá»Ÿi táº¡o mÃ´ hÃ¬nh huáº¥n luyá»‡n : 
				model = LinearRegression(): Khá»Ÿi táº¡o má»™t mÃ´ hÃ¬nh há»“i quy tuyáº¿n tÃ­nh  
				
				model.fit(X,y) : Huáº¥n luyá»‡n mÃ´ hÃ¬nh báº±ng cÃ¡ch tÃ¬m ra cÃ¡c há»‡ sá»‘ há»“i quy b0 vÃ  b1 dá»±a trÃªn dá»¯ liá»‡u X vÃ  y 
				
			4. Dá»± Ä‘oÃ¡n 
				y_pred = model.predict(X): Dá»± Ä‘oÃ¡n giÃ¡ trá»‹ y dá»±a trÃªn dá»¯ liá»‡u X 
				
			5. In cÃ¡c há»‡ sá»‘ há»“i quy : 
				model.coef_ : Há»‡ sá»‘ gÃ³c b1, cho biáº¿t má»©c Ä‘á»™ thay Ä‘á»•i cá»§a y khi x thay Ä‘á»•i 
				
				model.intercept_ : Há»‡ sá»‘ cháº·n b0, giÃ¡ trá»‹ y khi x = 0 
				
			6. Váº½ Ä‘á»“ thá»‹ : 
				plt.scatter(X , y , color = 'blue') : Váº½ cÃ¡c Ä‘iá»ƒm dá»¯ liá»‡u thá»±c táº¿(X , y).
				
				plt.plot(X , y_pred, color = 'red') : váº½ Ä‘Æ°á»ng há»“i quy tuyáº¿n tÃ­nh 
				
				plt.xlabel  , plt.ylabel , plt.title : Äáº·t nhÃ£n vÃ  tiÃªu Ä‘á» cho Ä‘á»“ thá»‹. 
				
			--
			
				
			
			
	# 4.2 Thá»±c hiá»‡n há»“i quy tuyáº¿n tÃ­nh Ä‘a biáº¿n báº±ng Python 
		
			import numpy as np
			from sklearn.linear_model import LinearRegression
			import matplotlib.pyplot as plt
			from mpl_toolkits.mplot3d import Axes3D
			
			# Dá»¯ liá»‡u máº«u
			X = np.array([[1, 1], [1, 2], [2, 2], [2, 3]])
			y = np.dot(X, np.array([1, 2])) + 3
			
			# Khá»Ÿi táº¡o mÃ´ hÃ¬nh
			model = LinearRegression()
			
			# Huáº¥n luyá»‡n mÃ´ hÃ¬nh
			model.fit(X, y)
			
			# Dá»± Ä‘oÃ¡n
			y_pred = model.predict(X)
			
			# Há»‡ sá»‘ há»“i quy
			print(f"Há»‡ sá»‘ há»“i quy: {model.coef_}")
			print(f"Intercept: {model.intercept_}")
			
			# Váº½ Ä‘á»“ thá»‹ 3D
			fig = plt.figure()
			ax = fig.add_subplot(111, projection='3d')
			
			# Dá»¯ liá»‡u gá»‘c (cháº¥m xanh)
			ax.scatter(X[:, 0], X[:, 1], y, color='blue', label='Dá»¯ liá»‡u thá»±c táº¿')
			
			# Dá»¯ liá»‡u dá»± Ä‘oÃ¡n (máº·t pháº³ng há»“i quy)
			x1_range = np.linspace(X[:, 0].min(), X[:, 0].max(), 10)
			x2_range = np.linspace(X[:, 1].min(), X[:, 1].max(), 10)
			x1_grid, x2_grid = np.meshgrid(x1_range, x2_range)
			y_grid = model.intercept_ + model.coef_[0] * x1_grid + model.coef_[1] * x2_grid
			ax.plot_surface(x1_grid, x2_grid, y_grid, alpha=0.5, color='red', label='Máº·t pháº³ng há»“i quy')
			
			# GÃ¡n nhÃ£n cho cÃ¡c trá»¥c
			ax.set_xlabel('X1')
			ax.set_ylabel('X2')
			ax.set_zlabel('Y')
			ax.set_title('Há»“i quy tuyáº¿n tÃ­nh Ä‘a biáº¿n')
			ax.legend()
			
			plt.show()
		
		
		
		### Giáº£i thÃ­ch vá» cÃ¡c biáº¿n 
		
		- X : ÄÃ¢y lÃ  dá»¯ liá»‡u Ä‘áº§u vÃ o biáº¿n Ä‘á»™c láº­p, cÃ³ 4 hÃ ng vÃ  2 cá»™t : 
			- Má»—i hÃ ng Ä‘áº¡i diá»‡n cho má»™t quan sÃ¡t, vÃ  má»—i cá»™t lÃ  má»™t biáº¿n Ä‘á»™c láº­p(feature)
			
		
		
		- y : ÄÃ¢y lÃ  dá»¯ liá»‡u Ä‘áº§u ra(Biáº¿n phá»¥ thuá»™c), Ä‘Æ°á»£c tÃ­nh báº±ng cÃ´ng thá»©c  y = X .[1,2] + 3
			
		-  np.dot(X , np.array([1,2])) thá»±c hiá»‡n phÃ©p ma tráº­n giá»¯a X vÃ  [1,2]
		 
		-  Sau Ä‘Ã³ cá»™ng thÃªm 3 vÃ o tá»«ng pháº§n tá»­, káº¿t quáº£ lÃ  : 
					y = [6,8,10,13]
		 
	
		- model   = LinearRegression()  : Khá»Ÿi táº¡o má»™t mÃ´ hÃ¬nh há»“i quy tuyáº¿n tÃ­nh 
		
		- model.fit(X , y): Huáº¥n luyá»‡n mÃ´ hÃ¬nh trÃªn dá»¯ liá»‡u X vÃ  y. 
			+ MÃ´ hÃ¬nh há»c cÃ¡ch tÃ¬m ra cÃ¡c tham sá»‘ b0(intercept) vÃ  b1,b2(cÃ¡c há»‡ sá»‘ há»“i quy sao cho):  y = b0 + b1.x1 + b2.x2 
			+ Trong trÆ°á»ng há»£p nÃ y, mÃ´ hÃ¬nh sáº½ tÃ¬m ra b0 = 3 , b1 = 1 vÃ  b2 = 2  
			
		- y_pred = model.predict(X) : TÃ­nh toÃ¡n giÃ¡ trá»‹ y dá»± Ä‘oÃ¡n(giÃ¡ trá»‹ mÃ´ hÃ¬nh Æ°á»›c lÆ°á»£ng) tá»« dá»¯ liá»‡u Ä‘áº§u vÃ o X 
			+ Káº¿t quáº£ : Ypred = [6,8,10,13]
			
		
		- Máº·t pháº³ng há»“i quy cho tháº¥y mÃ´ hÃ¬nh cá»§a báº¡n Ä‘Ã£ há»c Ä‘Æ°á»£t quy luáº­t : Khi x1 hoáº·c x2 tÄƒng, y cÅ©ng tÄƒng theo má»™t tá»· lá»‡ nháº¥t Ä‘á»‹nh. 
		

#. 5 Há»“i quy tuyáº¿n tÃ­nh sá»­ dá»¥ng PyTorch 
	-> Náº¿u báº¡n muá»‘n há»“i quy tuyáº¿n tÃ­nh trong mÃ´i trÆ°á»ng há»c mÃ¡y nÃ¢ng cao, báº¡n cÃ³ thá»ƒ sá»­ dá»¥ng PyTorch 
	
#5.1 Há»“i quy tuyáº¿n tÃ­nh Ä‘Æ¡n giáº£n vá»›i PyTorch 
	
		import torch
		import torch.nn as nn
		import torch.optim as optim
		import matplotlib.pyplot as plt
		
		# Dá»¯ liá»‡u máº«u
		X = torch.tensor([[1.0], [2.0], [3.0], [4.0]])
		y = torch.tensor([[2.0], [4.0], [6.0], [8.0]])
		
		# MÃ´ hÃ¬nh há»“i quy tuyáº¿n tÃ­nh
		model = nn.Linear(1, 1)  # 1 Ä‘áº§u vÃ o, 1 Ä‘áº§u ra
		
		# HÃ m máº¥t mÃ¡t vÃ  tá»‘i Æ°u hÃ³a
		criterion = nn.MSELoss()  # Sai sá»‘ bÃ¬nh phÆ°Æ¡ng trung bÃ¬nh
		optimizer = optim.SGD(model.parameters(), lr=0.01)  # Gradient Descent
		
		# Huáº¥n luyá»‡n mÃ´ hÃ¬nh
		losses = []  # Danh sÃ¡ch lÆ°u giÃ¡ trá»‹ loss Ä‘á»ƒ váº½ biá»ƒu Ä‘á»“
		
		for epoch in range(1000):  # Huáº¥n luyá»‡n trong 1000 epoch
			model.train()
		
			# Dá»± Ä‘oÃ¡n
			y_pred = model(X)
		
			# TÃ­nh toÃ¡n máº¥t mÃ¡t
			loss = criterion(y_pred, y)
			losses.append(loss.item())  # LÆ°u giÃ¡ trá»‹ loss
		
			# Tá»‘i Æ°u hÃ³a
			optimizer.zero_grad()  # XÃ³a gradient cÅ©
			loss.backward()  # TÃ­nh toÃ¡n gradient
			optimizer.step()  # Cáº­p nháº­t trá»ng sá»‘
		
			# In thÃ´ng tin má»—i 100 epoch
			if (epoch + 1) % 100 == 0:
				print(f'Epoch: {epoch + 1}, Loss: {loss.item()}')
		
		# Há»‡ sá»‘ há»“i quy vÃ  intercept
		print(f'Há»‡ sá»‘ há»“i quy (slope): {model.weight.item()}')
		print(f'Intercept (Ä‘á»™ dá»i): {model.bias.item()}')
		
		# Trá»±c quan hÃ³a dá»¯ liá»‡u vÃ  Ä‘Æ°á»ng há»“i quy
		plt.figure(figsize=(10, 5))
		
		# Váº½ dá»¯ liá»‡u gá»‘c
		plt.scatter(X.numpy(), y.numpy(), color='blue', label='Dá»¯ liá»‡u gá»‘c')
		
		# Váº½ Ä‘Æ°á»ng há»“i quy
		x_line = torch.linspace(0, 5, 100).reshape(-1, 1)  # Táº¡o cÃ¡c Ä‘iá»ƒm x
		y_line = model(x_line).detach().numpy()  # Dá»± Ä‘oÃ¡n giÃ¡ trá»‹ y
		plt.plot(x_line.numpy(), y_line, color='red', label='ÄÆ°á»ng há»“i quy')
		
		plt.title('Há»“i quy tuyáº¿n tÃ­nh Ä‘Æ¡n giáº£n')
		plt.xlabel('X')
		plt.ylabel('y')
		plt.legend()
		plt.grid(True)
		plt.show()
		
		# Váº½ biá»ƒu Ä‘á»“ máº¥t mÃ¡t (loss) theo epoch
		plt.figure(figsize=(10, 5))
		plt.plot(range(1, 1001), losses, label='Loss')
		plt.title('GiÃ¡ trá»‹ Loss theo Epoch')
		plt.xlabel('Epoch')
		plt.ylabel('Loss')
		plt.grid(True)
		plt.legend()
		plt.show()


	

	# Giáº£i thÃ­ch code 
	1. Dá»¯ liá»‡u máº«u : 
		Táº¡o má»™t táº­p dá»¯ liá»‡u Ä‘áº§u vÃ o lÃ  cÃ¡c máº£ng Ä‘a chiá»u(tensor) mÃ´ phá»ng má»‘i quan há»‡ tuyáº¿n tÃ­nh y = 2x 
		
	2. Sá»­ dá»¥ng mÃ´ hÃ¬nh há»“i quy tuyáº¿n tÃ­nh : 
		Sá»­ dá»¥ng nn.Linear(1,1) Ä‘á»ƒ táº¡o má»™t mÃ´ hÃ¬nh há»“i quy tuyáº¿n tÃ­nh Ä‘Æ¡n giáº£n vá»›i : 
			1 Ä‘áº§u vÃ o(input feature)
			1 Ä‘áº§u ra (output feature)
	3. HÃ m máº¥t mÃ¡t : 
		nn.MSELoss() dÃ¹ng Ä‘á»ƒ tÃ­nh toÃ¡n sai sá»‘ bÃ¬nh phÆ°Æ¡ng trÃ¬nh bÃ¬nh MSE giá»¯a giÃ¡ trá»‹ dá»± Ä‘oÃ¡n vÃ  thá»±c táº¿. 
	
	4. Thuáº­t toÃ¡n tá»‘i Æ°u : 
		optim.SGD(Stochastic Gradient Descent ) Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ cáº­p nháº­t trá»ng sá»‘ dá»±a trÃªn gradient 
		
	5. VÃ²ng láº·p huáº¥n luyá»‡n : 
		
		### Trong má»—i epoch 
			- Dá»± Ä‘oÃ¡n giÃ¡ trá»‹ y_pred = model(X).
			- TÃ­nh toÃ¡n máº¥t mÃ¡t loss = criterion(y_pred , y)
			- Tá»‘i Æ°u hÃ³a trá»ng sá»‘ 
							optimizer.zero_grad()     //  XÃ³a gradient cÅ© 
							loss.backward()           // TÃ­nh gradient má»›i 
							optimizer.step()          // Cáº­p nháº­t trá»ng sá»‘ 
			
	6. Káº¿t quáº£ : 
		Sau khi huáº¥n luyá»‡n mÃ´ hÃ¬nh sáº½ tráº£ vá» há»‡ sá»‘ há»“i quy(slope) vÃ  intercept Ä‘á»™ dá»i: 


# 5.1 Há»“i quy tuyáº¿n tÃ­nh Ä‘a biáº¿n vá»›i PyTorch
	
			import torch 
			import torch.nn as nn
			import torch.optim as optim 
			import matplotlib.pyplot as plt 
			
			#Dá»¯ liá»‡u máº«u 
			# Giáº£ sá»­ cÃ³ 2 biáº¿n Ä‘á»™c láº­p vÃ  má»™t biáº¿n phá»¥ thuojc 
			X = torch.tensor([ [1.0 , 2.0] , [2.0,3.0] , [3.0,4.0] , [4.0,5.0] ]) 
			y = torch.tensor( [ [3.0] , [5.0] , [7.0] , [9.0] ])
			
			# MÃ´ hÃ¬nh há»“i quy tuyáº¿n tÃ­nh Ä‘a biáº¿n 
			model = nn.Linear(2,1)
			
			# HÃ m máº¥t mÃ¡t vÃ  tá»‘i Æ°u hÃ³a 
			criterion = nn.MSELoss()
			optimizer = optim.SGD(model.parameters() , lr = 0.01)
			
			#LÆ°u trá»¯ giÃ¡ trá»‹ máº¥t mÃ¡t Ä‘á»ƒ váº½ Ä‘á»“ thá»‹ 
			losses = []
			
			#Huáº¥n luyá»‡n mÃ´ hÃ¬nh 
			for epoch in range(1000):
				model.train()
			
				#Dá»± Ä‘oÃ¡n 
				y_pred = model(X)
				#TÃ­nh toÃ¡n máº¥t mÃ¡t 
				loss = criterion(y_pred , y)
				losses.append(loss.item())
				# Tá»‘i Æ°u hÃ³a
				optimizer.zero_grad()
				loss.backward()
				optimizer.step()
			
				if(epoch + 1) % 100 == 0:
					print(f'Epoch {epoch+1}, Loss: {loss.item()}')
			
			#Há»‡ sá»‘ há»“i quy vÃ  intercept
			print(f'Há»‡ sá»‘ há»“i quy: {model.weight.data}')
			print(f'Intercept: {model.bias.data}')
			
			# Váº½ Ä‘á»“ thá»‹ máº¥t mÃ¡t qua cÃ¡c epoch (log scale cho trá»¥c Y)
			plt.plot(losses)
			plt.title('QuÃ¡ trÃ¬nh giáº£m máº¥t mÃ¡t (Log Scale)')
			plt.xlabel('Epoch')
			plt.ylabel('Loss')
			plt.yscale('log')  # Chuyá»ƒn trá»¥c Y sang dáº¡ng logarit
			plt.grid(True, which="both", linestyle="--", linewidth=0.5)
			plt.show()
			#Kiá»ƒm tra dá»± Ä‘oÃ¡n 
			with torch.no_grad():
				y_test = model(X)
				print(f'Dá»± Ä‘oÃ¡n: {y_test}')


		### Giáº£i thÃ­ch : 
			- Sá»­ dá»¥ng torch.tensor Ä‘á»ƒ táº¡o dá»¯ liá»‡u Ä‘áº§u vÃ o X vÃ  Ä‘áº§u ra y 
			- MÃ´ hÃ¬nh há»“i quy tuyáº¿n tÃ­nh Ä‘a biáº¿n Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a vá»›i 2 biáº¿n Ä‘áº§u vÃ o vÃ  1 biáº¿n Ä‘áº§u ra báº±ng cÃ¡ch sá»­ dá»¥ng lá»›p nn.Linear 
			- ChÃºng ta sá»­ dá»¥ng hÃ m máº¥t mÃ¡t nn.MSELoss Ä‘á»ƒ tÃ­nh toÃ¡n sai sá»‘ bÃ¬nh phÆ°Æ¡ng trung bÃ¬nh vÃ  tá»‘i Æ°u hÃ³a mÃ´ hÃ¬nh báº±ng optim.SGD 
			- ChÃºng ta huáº¥n luyá»‡n mÃ´ hÃ¬nh qua nhiá»u epoch vÃ  in ra cÃ¡c há»‡ sá»‘ há»“i quy vÃ  intercept sau khi huáº¥n luyá»‡n 


#6. á»¨ng dá»¥ng cá»§a há»“i quy tuyáº¿n tÃ­nh trong há»c mÃ¡y 
Há»“i quy tuyáº¿n tÃ­nh cÃ³ ráº¥t nhiá»u á»©ng dá»¥ng trong cÃ¡c lÄ©nh vá»±c khÃ¡c nhau, tá»« kinh táº¿, tÃ i chÃ­nh Ä‘áº¿n y há»c, ká»¹ thuáº­t vÃ  hÆ¡n tháº¿ ná»¯a. DÆ°á»›i Ä‘Ã¢y lÃ  má»™t sá»‘ vÃ­ dá»¥ Ä‘iá»ƒn hÃ¬nh : 


	##6.1 Dá»± Ä‘oÃ¡n giÃ¡ nhÃ  
		Há»“i quy tuyáº¿n tÃ­nh cÃ³ thá»ƒ sá»­ dá»¥ng Ä‘á»ƒ dá»± Ä‘oÃ¡n giÃ¡ nhÃ  dá»±a trÃªn cÃ¡c yáº¿u tá»‘ nhÆ° diá»‡n tÃ­ch, sá»‘ phÃ²ng ngá»§,vÃ  vá»‹ trÃ­. Báº¡n cÃ³ thá»ƒ xÃ¢y dá»±ng mÃ´ hÃ¬nh há»“i quy tuyáº¿n tÃ­nh Ä‘á»ƒ dá»± Ä‘oÃ¡n giÃ¡ nhÃ  dá»±a trÃªn cÃ¡c Ä‘áº·c Ä‘iá»ƒm nÃ y 
		
	## 6.2  PhÃ¢n tÃ­ch má»—i quan há»‡ giá»¯a cÃ¡c biáº¿n kinh táº¿ 
		Trong kinh táº¿ há»c, há»“i quy tuyáº¿n tÃ­nh cÃ³ thá»ƒ Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ phÃ¢n tÃ­ch má»‘i quan há»‡ giá»¯a cÃ¡c chá»‰ sá»‘ kinh táº¿ nhÆ° GDP, tá»· lá»‡ tháº¥t nghiá»‡p vÃ  láº¡m phÃ¡t. VÃ­ dá»¥, báº¡n cÃ³ thá»ƒ nghiÃªn cá»©u áº£nh hÆ°á»Ÿng cá»§a tá»· lá»‡ tháº¥t nghiá»‡p Ä‘áº¿n tÄƒng trÆ°á»Ÿng GDP 
		
	## 6.3 Dá»± Ä‘oÃ¡n nguy cÆ¡ bá»‡nh táº­t 
		Há»“i quy tuyáº¿n tÃ­nh cÅ©ng cÃ³ thá»ƒ Ä‘Æ°á»£c sá»­ dá»¥ng trong y há»c Ä‘á»ƒ dá»± Ä‘oÃ¡n nguy cÆ¡ máº¯c bá»‡nh dá»±a trÃªn cÃ¡c chá»‰ sá»‘ sá»©c khá»e. VÃ­ dá»¥, mÃ´ hÃ¬nh há»“i quy tuyáº¿n tÃ­nh cÃ³ thá»ƒ Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ phÃ¢n tÃ­ch má»‘i quan há»‡ giá»¯a huyáº¿t Ã¡p vÃ  nguy cÆ¡ máº¯c bá»‡nh tim máº¡ch 
		

# Káº¿t luáº­n  
	Há»“i quy tuyáº¿n tÃ­nh lÃ  má»™t ká»¹ thuáº­t cÆ¡ báº£n nhÆ°ng cá»±c ká»³ máº¡nh máº½ trong phÃ¢n tÃ­ch dá»¯ liá»‡u vÃ  há»c mÃ¡y. NÃ³ cung cáº¥p má»™t ná»n táº£ng quan trá»ng cho cÃ¡c mÃ´ hÃ¬nh phá»©c táº¡p hÆ¡n vÃ  cÃ³ nhiá»u á»©ng dá»¥ng thá»±c tiá»…n trong cÃ¡c lÄ©nh vá»±c khÃ¡c nhau. Viá»‡c hiá»ƒu rÃµ cÃ¡ch thá»©c hoáº¡t Ä‘á»™ng vÃ  á»©ng dá»¥ng cá»§a há»“i quy tuyáº¿n tÃ­nh khÃ´ng chá»‰ giÃºp báº¡n phÃ¢n tÃ­ch dá»¯ liá»‡u tá»‘t hÆ¡n mÃ  cÃ²n má»Ÿ ra nhiá»u cÆ¡ há»™i trong phÃ¡t triá»ƒn cÃ¡c mÃ´ hÃ¬nh há»c mÃ¡y hiá»‡u quáº£. 

	
		
// ============================= Biá»ƒu Ä‘á»“ máº¥t mÃ¡t (loss )================= 
Biá»ƒu Ä‘á»“ Loss theo Epoch cho tháº¥y quÃ¡ trÃ¬nh há»c táº­p cá»§a mÃ´ hÃ¬nh qua tá»«ng bÆ°á»›c (epoch). NÃ³ Ä‘o xem mÃ´ hÃ¬nh cá»§a báº¡n Ä‘ang há»c tá»‘t hÆ¡n hay tá»‡ hÆ¡n khi cá»‘ gáº¯ng giáº£m sai sá»‘ giá»¯a dá»± Ä‘oÃ¡n vÃ  thá»±c táº¿ 

# 1. # Ã nghÄ©a cá»§a Loss khi huáº¥n luyá»‡n 
	- Loss lÃ  cÃ¡ch Ä‘o lÆ°á»ng sai sá»‘ cá»§a mÃ´ hÃ¬nh : 
		+ Loss cao : MÃ´ hÃ¬nh dá»± Ä‘oÃ¡n khÃ´ng tá»‘t(xa thá»±c táº¿)
		+ Loss tháº¥p : MÃ´ hÃ¬nh dá»± Ä‘oÃ¡n tá»‘t hÆ¡n(gáº§n thá»±c táº¿).
		
	- Trong huáº¥n luyá»‡n, má»¥c tiÃªu cá»§a mÃ´ hÃ¬nh lÃ  giáº£m Loss dáº§n qua cÃ¡c epoch báº±ng cÃ¡ch cáº£i thá»‡n cÃ¡c tham sá»‘ bÃªn trong(trá»ng sá»‘ vÃ  Ä‘á»™ dá»i) 
	
# 2. # VÃ­ dá»¥ minh há»a dá»… hiá»ƒu 
	- Khi dáº¡y má»™t Ä‘á»©a tráº» nÃ©m bÃ³ng trÃºng rá»• 
		+ Ban Ä‘áº§u(epoch Ä‘áº§u tiÃªn) : Tráº» nÃ©m bÃ¡o xa rá»• , sai ráº¥t nhiá»u -> Loss cao 
		+ Trong quÃ¡ trÃ¬nh luyá»‡n táº­p :  Tráº» báº¯t Ä‘áº§u Ä‘iá»u chá»‰nh ká»¹ thuáº­t: dÃ¹ng lá»±c Ä‘Ãºng hÆ¡n, nháº¯m chÃ­nh xÃ¡c hÆ¡n
		+ Sau má»—i láº§n táº­p, sai sá»‘(khoáº£ng cÃ¡ch bÃ³ng Ä‘áº¿n rá»• )giáº£m dáº§n -> Loss nhá» dáº§n 
		+ Káº¿t quáº£(epoch cuá»‘i): Tráº» nÃ©m bÃ³ng vÃ o rá»• chÃ­nh xÃ¡c -> Loss gáº§n báº±ng 0 
		
	- Biá»ƒu Ä‘á»“ :  
		+ Náº¿u tráº» há»c tá»‘t, biá»ƒu Ä‘á»“ sáº½ giáº£m dáº§n Ä‘á»u 
		+ Náº¿u tráº» há»c khÃ´ng tá»‘t hoáº·c gáº·p váº¥n Ä‘á», biá»ƒu Ä‘á»“ cÃ³ thá»ƒ pháº³ng, tÄƒng lÃªn, khÃ´ng giáº£m  
		

# 3 . PhÃ¢n tÃ­ch biá»ƒu Ä‘á»“ Loss trong mÃ´ hÃ¬nh AI 
	## 1.  Biá»ƒu Ä‘á»“ Loss giáº£m dáº§n : 
		+ ÄÃ¢y lÃ  dáº¥u hiá»‡u tá»‘t. NÃ³ cho tháº¥y mÃ´ hÃ¬nh Ä‘ang há»c cÃ¡ch dá»± Ä‘oÃ¡n ngÃ y cÃ ng chÃ­nh xÃ¡c hÆ¡n 
				Epoch 1: Loss = 10.0
				Epoch 100: Loss = 1.5
				Epoch 1000: Loss = 0.01
		
	## 2. Loss khÃ´ng giáº£m hoáº·c tÄƒng lÃªn : 
		+ CÃ³ thá»ƒ mÃ´ hÃ¬nh gáº·p váº¥n Ä‘á» : 
			+ Tá»‘c Ä‘á»™ há»c(learning rate) quÃ¡ lá»›n hoáº·c quÃ¡ nhá» 
			+ Dá»¯ liá»‡u khÃ´ng Ä‘á»§ tá»‘t hoáº·c khÃ´ng phÃ¹ há»£p 
			+ MÃ´ hÃ¬nh quÃ¡ Ä‘Æ¡n giáº£n (underfitting) hoáº·c quÃ¡ phá»©c táº¡p(overfitting)
			
	## 3. Loss giáº£m máº¡nh rá»“i chá»¯ng láº¡i : 
		+ ÄÃ¢y lÃ  Ä‘iá»u bÃ¬nh thÆ°á»ng. Sau khi há»c Ä‘Æ°á»£c nhiá»u, mÃ´ hÃ¬nh cáº§n nhiá»u ná»— lá»±c hÆ¡n Ä‘á»ƒ cáº£i thiá»‡n tiáº¿p. 
			
			
# 4. VÃ­ dá»¥ báº±ng hÃ¬nh áº£nh 
	
	+ Trá»¥c X (epoch) : Sá»‘ láº§n mÃ´ hÃ¬nh há»c(epoch )
	+ Trá»¥c Y (loss) : Sai sá»‘ táº¡i má»—i epoch 


	1. Biá»ƒu Ä‘á»“ tá»‘t : 
		+ Giáº£m dáº§n Ä‘á»u : MÃ´ hÃ¬nh Ä‘ang há»c tá»‘t, ngÃ y cÃ ng chÃ­nh xÃ¡c hÆ¡n 
	2. Biá»ƒu Ä‘á»“ khÃ´ng giáº£m : 
		+ Khoogn thay Ä‘á»•i : CÃ³ lá»—i hoáº·c mÃ´ hÃ¬nh khÃ´ng há»c Ä‘Æ°á»£c 
		
	3. Loss dao Ä‘á»™ng : 
		+ Dao Ä‘á»™ng tháº¥t thÆ°á»ng : CÃ³ thá»ƒ do tá»‘c Ä‘á»™ há»c quÃ¡ lá»›n hoáº·c dá»¯ liá»‡u khÃ´ng á»•n Ä‘á»‹nh 
		

</pre><a id='backBottom' href='../java-learning-list.html' style='display:none;'>ğŸ”™ Quay láº¡i danh sÃ¡ch</a><br><button onclick='toggleTheme()'>ğŸŒ™ Chuyá»ƒn giao diá»‡n</button></div><script>function toggleTheme() {   let mode = document.body.classList.contains('dark-mode') ? 'light-mode' : 'dark-mode';   document.body.className = mode; localStorage.setItem('theme', mode);   syncTheme();}function applyTheme() {   let savedTheme = localStorage.getItem('theme') || 'dark-mode';   document.body.className = savedTheme;   syncTheme();}function syncTheme() {   let preElement = document.querySelector('pre');   if (document.body.classList.contains('dark-mode')) { preElement.style.background = '#1e1e1e'; preElement.style.color = '#e0e0e0'; }   else { preElement.style.background = '#f5f5f5'; preElement.style.color = '#333333'; }}function checkPageHeight() {   let contentHeight = document.body.scrollHeight;   let windowHeight = window.innerHeight;   if (contentHeight > windowHeight * 1.2) {       document.getElementById('backBottom').style.display = 'block';   } else {       document.getElementById('backBottom').style.display = 'none';   }}</script></body></html>