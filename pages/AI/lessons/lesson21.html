<html><head><title>Lesson 21 == Há»c tÄƒng cÆ°á»ng (Reinforcement Learning): TÃ¬m hiá»ƒu chi tiáº¿t ==========//</title><style>body { font-family: Arial, sans-serif; transition: background 0.3s, color 0.3s; }.dark-mode { background-color: #121212; color: #e0e0e0; }.light-mode { background-color: #ffffff; color: #333333; }h1 { text-align: center; color: #73d9f5; }pre { padding: 15px; border-radius: 5px;       white-space: pre-wrap; word-wrap: break-word;       overflow-x: auto; max-width: 100%;       transition: background 0.3s, color 0.3s; }.dark-mode pre { background: #1e1e1e; color: #e0e0e0; }.light-mode pre { background: #f5f5f5; color: #333333; }#backTop, #backBottom {    font-size: 2em; padding: 20px 40px;    background: #bb86fc; color: white; text-decoration: none;    border-radius: 10px; display: inline-block; text-align: center; }#backTop:hover, #backBottom:hover { background: #9b67e2; }button { font-size: 1.5em; padding: 15px 30px;    background: #03dac6; color: #121212; border: none;    cursor: pointer; border-radius: 5px; display: block; margin: 10px auto; }button:hover { background: #02b8a3; }.dark-mode a { color: #03dac6; } .light-mode a { color: #007bff; }</style></head><body onload='applyTheme(); checkPageHeight()'><div class='container'><a id='backTop' href='../AI-learning-list.html'>ğŸ”™ Quay láº¡i danh sÃ¡ch</a><br><h1>Lesson 21 -- Há»c tÄƒng cÆ°á»ng (Reinforcement Learning): TÃ¬m hiá»ƒu chi tiáº¿t -//</h1><pre>				
		
# 	1. Giá»›i thiá»‡u 
		
Há»c tÄƒng cÆ°á»ng (Reinforcement Learning â€“ RL) lÃ  má»™t nhÃ¡nh quan trá»ng cá»§a há»c mÃ¡y, Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ giáº£i quyáº¿t cÃ¡c bÃ i toÃ¡n mÃ  trong Ä‘Ã³ má»™t tÃ¡c nhÃ¢n (agent) tÆ°Æ¡ng tÃ¡c vá»›i mÃ´i trÆ°á»ng Ä‘á»ƒ há»c cÃ¡ch Ä‘áº¡t Ä‘Æ°á»£c má»¥c tiÃªu thÃ´ng qua pháº§n thÆ°á»Ÿng (reward) vÃ  hÃ¬nh pháº¡t (penalty).

Thay vÃ¬ há»c tá»« má»™t táº­p dá»¯ liá»‡u cá»‘ Ä‘á»‹nh nhÆ° trong há»c cÃ³ giÃ¡m sÃ¡t (supervised learning), tÃ¡c nhÃ¢n sáº½ há»c thÃ´ng qua quÃ¡ trÃ¬nh thá»­ vÃ  sai (trial and error). Má»—i hÃ nh Ä‘á»™ng mÃ  tÃ¡c nhÃ¢n thá»±c hiá»‡n sáº½ nháº­n vá» má»™t pháº§n thÆ°á»Ÿng hoáº·c hÃ¬nh pháº¡t, vÃ  má»¥c tiÃªu cá»§a tÃ¡c nhÃ¢n lÃ  há»c Ä‘Æ°á»£c cÃ¡ch tá»‘i Ä‘a hÃ³a tá»•ng pháº§n thÆ°á»Ÿng nháº­n Ä‘Æ°á»£c trong dÃ i háº¡n.

# 	2. CÃ¡c thÃ nh pháº§n chÃ­nh		
		
	## TÃ¡c nhÃ¢n (Agent) 
		ÄÃ¢y lÃ  thá»±c thá»ƒ Ä‘Æ°a ra cÃ¡c hÃ nh Ä‘á»™ng. TÃ¡c nhÃ¢n cÃ³ thá»ƒ lÃ  má»™t chÆ°Æ¡ng trÃ¬nh AI Ä‘ang chÆ¡i má»™t trÃ² chÆ¡i, má»™t robot Ä‘ang thá»±c hiá»‡n cÃ¡c bÆ°á»›c di chuyá»ƒn, hay tháº­m chÃ­ lÃ  má»™t há»‡ thá»‘ng tá»± Ä‘á»™ng hÃ³a trong nhÃ  mÃ¡y.
		
	## MÃ´i trÆ°á»ng (Environment) 
		LÃ  táº¥t cáº£ nhá»¯ng gÃ¬ xung quanh tÃ¡c nhÃ¢n vÃ  cÃ³ thá»ƒ tÆ°Æ¡ng tÃ¡c vá»›i nÃ³. MÃ´i trÆ°á»ng pháº£n há»“i láº¡i cÃ¡c hÃ nh Ä‘á»™ng cá»§a tÃ¡c nhÃ¢n báº±ng cÃ¡ch cung cáº¥p tráº¡ng thÃ¡i má»›i vÃ  pháº§n thÆ°á»Ÿng tÆ°Æ¡ng á»©ng. MÃ´i trÆ°á»ng cÃ³ thá»ƒ lÃ  váº­t lÃ½ (tháº¿ giá»›i thá»±c) hoáº·c áº£o (mÃ´ phá»ng trÃ² chÆ¡i, mÃ´ phá»ng nhÃ  mÃ¡y).
		
	## Tráº¡ng thÃ¡i (State) 
		Tráº¡ng thÃ¡i biá»ƒu diá»…n má»™t mÃ´ táº£ ngáº¯n gá»n nhÆ°ng Ä‘áº§y Ä‘á»§ vá» tÃ¬nh huá»‘ng hiá»‡n táº¡i cá»§a mÃ´i trÆ°á»ng mÃ  tÃ¡c nhÃ¢n Ä‘ang pháº£i Ä‘á»‘i máº·t. Táº¡i má»—i thá»i Ä‘iá»ƒm, tÃ¡c nhÃ¢n nháº­n má»™t tráº¡ng thÃ¡i tá»« mÃ´i trÆ°á»ng vÃ  sá»­ dá»¥ng tráº¡ng thÃ¡i nÃ y Ä‘á»ƒ quyáº¿t Ä‘á»‹nh hÃ nh Ä‘á»™ng tiáº¿p theo.VÃ­ dá»¥: Trong trÃ² chÆ¡i cá» vua, tráº¡ng thÃ¡i lÃ  vá»‹ trÃ­ cá»§a táº¥t cáº£ cÃ¡c quÃ¢n cá» trÃªn bÃ n cá» táº¡i má»™t thá»i Ä‘iá»ƒm nháº¥t Ä‘á»‹nh.
		
		
	## 	HÃ nh Ä‘á»™ng (Action) 
		LÃ  má»™t lá»±a chá»n mÃ  tÃ¡c nhÃ¢n cÃ³ thá»ƒ thá»±c hiá»‡n táº¡i má»™t tráº¡ng thÃ¡i cá»¥ thá»ƒ. Má»—i hÃ nh Ä‘á»™ng cÃ³ thá»ƒ dáº«n Ä‘áº¿n má»™t tráº¡ng thÃ¡i má»›i cá»§a mÃ´i trÆ°á»ng. Má»¥c tiÃªu cá»§a tÃ¡c nhÃ¢n lÃ  chá»n hÃ nh Ä‘á»™ng sao cho tá»‘i Ä‘a hÃ³a pháº§n thÆ°á»Ÿng nháº­n Ä‘Æ°á»£c.VÃ­ dá»¥: Trong trÃ² chÆ¡i cá» vua, má»™t hÃ nh Ä‘á»™ng cÃ³ thá»ƒ lÃ  di chuyá»ƒn quÃ¢n mÃ£ tá»« Ã´ nÃ y sang Ã´ khÃ¡c.
		
	## Pháº§n thÆ°á»Ÿng (Reward) 
		LÃ  giÃ¡ trá»‹ pháº£n há»“i mÃ  mÃ´i trÆ°á»ng tráº£ láº¡i sau khi tÃ¡c nhÃ¢n thá»±c hiá»‡n má»™t hÃ nh Ä‘á»™ng. Pháº§n thÆ°á»Ÿng cÃ³ thá»ƒ lÃ  dÆ°Æ¡ng (thÆ°á»Ÿng) náº¿u hÃ nh Ä‘á»™ng cá»§a tÃ¡c nhÃ¢n lÃ  Ä‘Ãºng, hoáº·c Ã¢m (pháº¡t) náº¿u hÃ nh Ä‘á»™ng lÃ  sai. TÃ¡c nhÃ¢n sá»­ dá»¥ng thÃ´ng tin nÃ y Ä‘á»ƒ Ä‘iá»u chá»‰nh hÃ nh Ä‘á»™ng cá»§a mÃ¬nh trong tÆ°Æ¡ng lai.VÃ­ dá»¥: Trong trÃ² chÆ¡i cá» vua, pháº§n thÆ°á»Ÿng cÃ³ thá»ƒ lÃ  giÃ¡ trá»‹ +1 náº¿u tÃ¡c nhÃ¢n báº¯t Ä‘Æ°á»£c quÃ¢n Ä‘á»‘i thá»§ hoáº·c giÃ¡ trá»‹ -1 náº¿u bá»‹ máº¥t quÃ¢n.
		
		
	## ChÃ­nh sÃ¡ch (Policy)
		ChÃ­nh sÃ¡ch lÃ  chiáº¿n lÆ°á»£c mÃ  tÃ¡c nhÃ¢n sá»­ dá»¥ng Ä‘á»ƒ chá»n hÃ nh Ä‘á»™ng dá»±a trÃªn tráº¡ng thÃ¡i hiá»‡n táº¡i. ChÃ­nh sÃ¡ch cÃ³ thá»ƒ Ä‘Æ°á»£c biá»ƒu diá»…n dÆ°á»›i dáº¡ng má»™t hÃ m toÃ¡n há»c hoáº·c má»™t báº£ng tra cá»©u.VÃ­ dá»¥: Trong trÃ² chÆ¡i cá» vua, chÃ­nh sÃ¡ch cÃ³ thá»ƒ quyáº¿t Ä‘á»‹nh ráº±ng khi má»™t quÃ¢n mÃ£ á»Ÿ vá»‹ trÃ­ X, tÃ¡c nhÃ¢n nÃªn di chuyá»ƒn nÃ³ Ä‘áº¿n vá»‹ trÃ­ Y Ä‘á»ƒ tá»‘i Ä‘a hÃ³a cÆ¡ há»™i tháº¯ng.


	## HÃ m giÃ¡ trá»‹ (Value function) 
		HÃ m giÃ¡ trá»‹ lÃ  má»™t hÃ m dá»± Ä‘oÃ¡n giÃ¡ trá»‹ tÆ°Æ¡ng lai mÃ  tÃ¡c nhÃ¢n cÃ³ thá»ƒ nháº­n Ä‘Æ°á»£c tá»« má»™t tráº¡ng thÃ¡i nháº¥t Ä‘á»‹nh. HÃ m nÃ y giÃºp tÃ¡c nhÃ¢n Ä‘Ã¡nh giÃ¡ lá»£i Ã­ch cá»§a má»™t tráº¡ng thÃ¡i Ä‘á»ƒ chá»n hÃ nh Ä‘á»™ng tá»‘t nháº¥t.VÃ­ dá»¥: Trong má»™t trÃ² chÆ¡i, tráº¡ng thÃ¡i A cÃ³ giÃ¡ trá»‹ 5, tráº¡ng thÃ¡i B cÃ³ giÃ¡ trá»‹ 10. Äiá»u nÃ y cÃ³ nghÄ©a lÃ  tráº¡ng thÃ¡i B cÃ³ thá»ƒ mang láº¡i pháº§n thÆ°á»Ÿng cao hÆ¡n trong dÃ i háº¡n, vÃ  tÃ¡c nhÃ¢n nÃªn cá»‘ gáº¯ng chuyá»ƒn Ä‘áº¿n tráº¡ng thÃ¡i B. 
		
	## HÃ m Q (Q-function) 
		HÃ m Q Ä‘Ã¡nh giÃ¡ giÃ¡ trá»‹ cá»§a viá»‡c thá»±c hiá»‡n má»™t hÃ nh Ä‘á»™ng cá»¥ thá»ƒ táº¡i má»™t tráº¡ng thÃ¡i cá»¥ thá»ƒ. HÃ m nÃ y giÃºp tÃ¡c nhÃ¢n chá»n hÃ nh Ä‘á»™ng tá»‘i Æ°u báº±ng cÃ¡ch so sÃ¡nh giÃ¡ trá»‹ cá»§a cÃ¡c hÃ nh Ä‘á»™ng kháº£ thi. 
		
		CÃ´ng thá»©c cÆ¡ báº£n cho hÃ m Q trong bÃ i toÃ¡n há»c tÄƒng cÆ°á»ng lÃ :	
			Q(s, a) = R(s, a) + \gamma \sum_{sâ€™} P(sâ€™|s, a) \max_{aâ€™} Q(sâ€™, aâ€™)
			
		Trong Ä‘Ã³ : 
			-  Q(s, a)	 lÃ  giÃ¡ trá»‹ Q cá»§a hÃ nh Ä‘á»™ng a táº¡i tráº¡ng thÃ¡i s
			- R(s, a) lÃ  pháº§n thÆ°á»Ÿng nháº­n Ä‘Æ°á»£c sau khi thá»±c hiá»‡n hÃ nh Ä‘á»™ng a táº¡i tráº¡ng thÃ¡i  s
			- \gamma lÃ  há»‡ sá»‘ giáº£m giÃ¡ (discount factor), mÃ´ táº£ má»©c Ä‘á»™ mÃ  tÃ¡c nhÃ¢n Ä‘Ã¡nh giÃ¡ pháº§n thÆ°á»Ÿng trong tÆ°Æ¡ng lai. 
			- P(sâ€™|s, a)  lÃ  xÃ¡c suáº¥t chuyá»ƒn tráº¡ng thÃ¡i tá»«  s sang  s' sau khi thá»±c hiá»‡n hÃ nh Ä‘á»™ng a

		CÃ´ng thá»©c tá»•ng pháº§n thÆ°á»Ÿng tÃ­ch lÅ©y: 
			Pháº§n thÆ°á»Ÿng mÃ  tÃ¡c nhÃ¢n nháº­n Ä‘Æ°á»£c khÃ´ng chá»‰ quan tÃ¢m Ä‘áº¿n pháº§n thÆ°á»Ÿng tá»©c thá»i mÃ  cÃ²n bao gá»“m tá»•ng pháº§n thÆ°á»Ÿng trong tÆ°Æ¡ng lai. Tá»•ng pháº§n thÆ°á»Ÿng tÃ­ch lÅ©y táº¡i thá»i Ä‘iá»ƒm ttt cÃ³ thá»ƒ Ä‘Æ°á»£c tÃ­nh nhÆ° sau: 
				G_t = R_{t+1} + \gamma R_{t+2} + \gamma^2 R_{t+3} + \cdots = \sum_{k=0}^{\infty} \gamma^k R_{t+k+1} 
				
			Trong Ä‘Ã³ : 
				- G_t lÃ  tá»•ng pháº§n thÆ°á»Ÿng tÃ­ch lÅ©y báº¯t Ä‘áº§u tá»« thá»i Ä‘iá»ƒm t 
				- \gamma Ã  há»‡ sá»‘ giáº£m giÃ¡ (discount factor), Ä‘iá»u chá»‰nh táº§m quan trá»ng cá»§a pháº§n thÆ°á»Ÿng trong tÆ°Æ¡ng lai. 
				- R_t  lÃ  pháº§n thÆ°á»Ÿng nháº­n Ä‘Æ°á»£c táº¡i thá»i Ä‘iá»ƒm t 
				
				
				
				
				
# CÃ¡c phÆ°Æ¡ng phÃ¡p há»c tÄƒng cÆ°á»ng 
	Há»c tÄƒng cÆ°á»ng (Reinforcement Learning) cÃ³ nhiá»u phÆ°Æ¡ng phÃ¡p khÃ¡c nhau, tÃ¹y thuá»™c vÃ o cÃ¡ch tÃ¡c nhÃ¢n há»c vÃ  tá»‘i Æ°u hÃ³a chÃ­nh sÃ¡ch Ä‘á»ƒ nháº­n Ä‘Æ°á»£c pháº§n thÆ°á»Ÿng cao nháº¥t. DÆ°á»›i Ä‘Ã¢y lÃ  cÃ¡c phÆ°Æ¡ng phÃ¡p phá»• biáº¿n trong há»c tÄƒng cÆ°á»ng:
	
	## 3.1. PhÆ°Æ¡ng phÃ¡p há»c dá»±a trÃªn giÃ¡ trá»‹ (Value-based Methods) 
		PhÆ°Æ¡ng phÃ¡p nÃ y táº­p trung vÃ o viá»‡c Æ°á»›c tÃ­nh giÃ¡ trá»‹ cá»§a cÃ¡c tráº¡ng thÃ¡i hoáº·c cÃ¡c hÃ nh Ä‘á»™ng táº¡i cÃ¡c tráº¡ng thÃ¡i, sau Ä‘Ã³ chá»n hÃ nh Ä‘á»™ng dá»±a trÃªn cÃ¡c giÃ¡ trá»‹ nÃ y. TÃ¡c nhÃ¢n sáº½ há»c má»™t hÃ m giÃ¡ trá»‹ Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ má»©c Ä‘á»™ tá»‘t xáº¥u cá»§a má»™t tráº¡ng thÃ¡i hoáº·c hÃ nh Ä‘á»™ng.
		
		### Q-learning 
			ÄÃ¢y lÃ  thuáº­t toÃ¡n ná»•i tiáº¿ng nháº¥t trong nhÃ³m há»c dá»±a trÃªn giÃ¡ trá»‹. Q-learning sá»­ dá»¥ng hÃ m giÃ¡ trá»‹ Q(s, a) Ä‘á»ƒ Æ°á»›c tÃ­nh giÃ¡ trá»‹ cá»§a má»™t hÃ nh Ä‘á»™ng a táº¡i tráº¡ng thÃ¡i s CÃ´ng thá»©c cáº­p nháº­t Q-learning: 
				Q(s_t, a_t) \leftarrow Q(s_t, a_t) + \alpha \left[ r_{t+1} + \gamma \max_a Q(s_{t+1}, a) â€“ Q(s_t, a_t) \right] 
				
			Trong Ä‘Ã³ 
				a  lÃ  tá»‘c Ä‘á»™ há»c. 
				y   lÃ  há»‡ sá»‘ giáº£m giÃ¡.
				r_{t+1}	lÃ  pháº§n thÆ°á»Ÿng sau khi thá»±c hiá»‡n hÃ nh Ä‘á»™ng  a_t
				 
			
		### SARSA (State-Action-Reward-State-Action) 
			SARSA lÃ  má»™t phÆ°Æ¡ng phÃ¡p tÆ°Æ¡ng tá»± nhÆ° Q-learning, nhÆ°ng thay vÃ¬ tá»‘i Æ°u hÃ³a theo hÃ nh Ä‘á»™ng tá»‘t nháº¥t tiáº¿p theo, nÃ³ sá»­ dá»¥ng hÃ nh Ä‘á»™ng mÃ  tÃ¡c nhÃ¢n thá»±c sá»± thá»±c hiá»‡n Ä‘á»ƒ cáº­p nháº­t giÃ¡ trá»‹ Q 
			
			CÃ´ng thá»©c cáº­p nháº­t SARSA:			
				Q(s_t, a_t) \leftarrow Q(s_t, a_t) + \alpha \left[ r_{t+1} + \gamma Q(s_{t+1}, a_{t+1}) â€“ Q(s_t, a_t) \right]
				
				
	## 	3.2. PhÆ°Æ¡ng phÃ¡p há»c chÃ­nh sÃ¡ch (Policy-based Methods) 
		Thay vÃ¬ há»c hÃ m giÃ¡ trá»‹, phÆ°Æ¡ng phÃ¡p há»c chÃ­nh sÃ¡ch trá»±c tiáº¿p há»c má»™t chiáº¿n lÆ°á»£c hoáº·c chÃ­nh sÃ¡ch \pi(a|s) giÃºp tÃ¡c nhÃ¢n chá»n hÃ nh Ä‘á»™ng dá»±a trÃªn tráº¡ng thÃ¡i hiá»‡n táº¡i. 
		
		### Policy Gradient 
			ÄÃ¢y lÃ  má»™t phÆ°Æ¡ng phÃ¡p sá»­ dá»¥ng Ä‘á»™ dá»‘c (gradient) Ä‘á»ƒ Ä‘iá»u chá»‰nh chÃ­nh sÃ¡ch sao cho tÄƒng cÆ°á»ng kháº£ nÄƒng cá»§a tÃ¡c nhÃ¢n trong viá»‡c Ä‘áº¡t pháº§n thÆ°á»Ÿng cao. TÃ¡c nhÃ¢n há»c trá»±c tiáº¿p chiáº¿n lÆ°á»£c chá»n hÃ nh Ä‘á»™ng tá»‘i Æ°u thÃ´ng qua viá»‡c tá»‘i Æ°u hÃ³a hÃ m má»¥c tiÃªu. 
			
			HÃ m máº¥t mÃ¡t cá»§a policy gradient thÆ°á»ng lÃ :
				\ \nabla J(\theta) = \mathbb{E}_{\pi_\theta} \left[ \nabla_\theta \log \pi_\theta (a|s) G_t \right] 
				
			Trong Ä‘Ã³: 
				J(\theta) lÃ  hÃ m má»¥c tiÃªu, \theta lÃ  cÃ¡c tham sá»‘ cá»§a chÃ­nh sÃ¡ch.
				\pi_\theta(a|s) lÃ  xÃ¡c suáº¥t chá»n hÃ nh Ä‘á»™ng a táº¡i tráº¡ng thÃ¡i s dÆ°á»›i chÃ­nh sÃ¡ch hiá»‡n táº¡i. 
				G_t lÃ  tá»•ng pháº§n thÆ°á»Ÿng tÃ­ch lÅ©y tá»« thá»i Ä‘iá»ƒm t 
				
		### REINFORCE	
			REINFORCE lÃ  má»™t thuáº­t toÃ¡n cá»¥ thá»ƒ trong policy gradient. NÃ³ sá»­ dá»¥ng gradient descent Ä‘á»ƒ tá»‘i Æ°u hÃ³a chÃ­nh sÃ¡ch
			\pi_\theta
			
			ChÃ­nh sÃ¡ch Ä‘Æ°á»£c cáº­p nháº­t dá»±a trÃªn tá»•ng pháº§n thÆ°á»Ÿng nháº­n Ä‘Æ°á»£c tá»« má»—i táº­p thá»­ (episode).

	## 3.3. PhÆ°Æ¡ng phÃ¡p há»c lai (Actor-Critic Methods) 
		https://aicandy.vn/hoc-tang-cuong-reinforcement-learning-tim-hieu-chi-tiet/














	
</pre><a id='backBottom' href='../AI-learning-list.html' style='display:none;'>ğŸ”™ Quay láº¡i danh sÃ¡ch</a><br><button onclick='toggleTheme()'>ğŸŒ™ Chuyá»ƒn giao diá»‡n</button></div><script>function toggleTheme() {   let mode = document.body.classList.contains('dark-mode') ? 'light-mode' : 'dark-mode';   document.body.className = mode; localStorage.setItem('theme', mode);   syncTheme();}function applyTheme() {   let savedTheme = localStorage.getItem('theme') || 'dark-mode';   document.body.className = savedTheme;   syncTheme();}function syncTheme() {   let preElement = document.querySelector('pre');   if (document.body.classList.contains('dark-mode')) { preElement.style.background = '#1e1e1e'; preElement.style.color = '#e0e0e0'; }   else { preElement.style.background = '#f5f5f5'; preElement.style.color = '#333333'; }}function checkPageHeight() {   let contentHeight = document.body.scrollHeight;   let windowHeight = window.innerHeight;   if (contentHeight > windowHeight * 1.2) {       document.getElementById('backBottom').style.display = 'block';   } else {       document.getElementById('backBottom').style.display = 'none';   }}</script></body></html>