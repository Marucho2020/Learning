<html><head><title>Lesson 17 == CÃ¡c phÆ°Æ¡ng phÃ¡p Ä‘Ã¡nh giÃ¡ hiá»‡u suáº¥t mÃ´ hÃ¬nh Machine Learning ==========//</title><style>body { font-family: Arial, sans-serif; transition: background 0.3s, color 0.3s; }.dark-mode { background-color: #121212; color: #e0e0e0; }.light-mode { background-color: #ffffff; color: #333333; }h1 { text-align: center; color: #73d9f5; }pre { padding: 15px; border-radius: 5px;       white-space: pre-wrap; word-wrap: break-word;       overflow-x: auto; max-width: 100%;       transition: background 0.3s, color 0.3s; }.dark-mode pre { background: #1e1e1e; color: #e0e0e0; }.light-mode pre { background: #f5f5f5; color: #333333; }#backTop, #backBottom {    font-size: 2em; padding: 20px 40px;    background: #bb86fc; color: white; text-decoration: none;    border-radius: 10px; display: inline-block; text-align: center; }#backTop:hover, #backBottom:hover { background: #9b67e2; }button { font-size: 1.5em; padding: 15px 30px;    background: #03dac6; color: #121212; border: none;    cursor: pointer; border-radius: 5px; display: block; margin: 10px auto; }button:hover { background: #02b8a3; }.dark-mode a { color: #03dac6; } .light-mode a { color: #007bff; }</style></head><body onload='applyTheme(); checkPageHeight()'><div class='container'><a id='backTop' href='../AI-learning-list.html'>ğŸ”™ Quay láº¡i danh sÃ¡ch</a><br><h1>Lesson 17 -- CÃ¡c phÆ°Æ¡ng phÃ¡p Ä‘Ã¡nh giÃ¡ hiá»‡u suáº¥t mÃ´ hÃ¬nh Machine Learning -//</h1><pre>
# Giá»›i thiá»‡u 
	Trong Machine Learning, viá»‡c Ä‘Ã¡nh giÃ¡ hiá»‡u suáº¥t cá»§a má»™t mÃ´ hÃ¬nh lÃ  bÆ°á»›c quan trá»ng Ä‘á»ƒ Ä‘áº£m báº£o ráº±ng mÃ´ hÃ¬nh hoáº¡t Ä‘á»™ng tá»‘t trÃªn dá»¯ liá»‡u thá»±c táº¿. CÃ¡c chá»‰ sá»‘ Ä‘o lÆ°á»ng hiá»‡u suáº¥t nhÆ° Accuracy, Sensitivity (Recall) vÃ  Specificity lÃ  nhá»¯ng cÃ´ng cá»¥ phá»• biáº¿n Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ kháº£ nÄƒng phÃ¢n loáº¡i cá»§a mÃ´ hÃ¬nh.
	
		## Accuracy 
			Ä‘o lÆ°á»ng tá»· lá»‡ dá»± Ä‘oÃ¡n Ä‘Ãºng trÃªn tá»•ng sá»‘ dá»± Ä‘oÃ¡n, thá»ƒ hiá»‡n má»©c Ä‘á»™ chÃ­nh xÃ¡c tá»•ng thá»ƒ cá»§a mÃ´ hÃ¬nh. Tuy nhiÃªn, khi dá»¯ liá»‡u bá»‹ máº¥t cÃ¢n báº±ng(vÃ­ dá»¥ sá»‘ lÆ°á»£ng lá»›p khÃ´ng Ä‘á»“ng Ä‘á»u), chá»‰ sá»‘ nÃ y cÃ³ thá»ƒ khÃ´ng pháº£n Ã¡nh Ä‘Ãºng hiá»‡u suáº¥t cá»§a mÃ´ hÃ¬nh. 
			
		## Sensitivity(hay Recall) 
			Ä‘Ã¡nh giÃ¡ kháº£ nÄƒng cá»§a mÃ´ hÃ¬nh trong viá»‡c phÃ¡t hiá»‡n cÃ¡c máº«u thuá»™c lá»›p dÆ°Æ¡ng tÃ­nh. NÃ³ Ä‘áº·c biá»‡t quan trá»ng trong cÃ¡c bÃ i toÃ¡n mÃ  viá»‡c phÃ¡t hiá»‡n Ä‘Ãºng cÃ¡c trÆ°á»ng há»£p dÆ°Æ¡ng tÃ­nh lÃ  Æ°u tiÃªn hÃ ng Ä‘áº§u, nhÆ° chuáº©n Ä‘oÃ¡n bá»‡nh táº­t 
			
		## Specificity
			NgÆ°á»£c láº¡i vá»›i Sensitivity, táº­p trung vÃ o kháº£ nÄƒng mÃ´ hÃ¬nh loáº¡i bá» cÃ¡c trÆ°á»ng há»£p Ã¢m tÃ­nh má»™t cÃ¡ch chÃ­nh xÃ¡c. Äiá»u nÃ y ráº¥t há»¯u Ã­ch trong cÃ¡c trÆ°á»ng há»£p mÃ  viá»‡c nháº­n diá»‡n Ä‘Ãºng lá»›p Ã¢m tÃ­nh cÃ³ táº§m quan trá»ng cao, nhÆ° trong cÃ¡c bÃ i toÃ¡n kiá»ƒm tra cháº¥t lÆ°á»£ng sáº£n pháº©m.
			
		Hiá»ƒu rÃµ vÃ  Ã¡p dá»¥ng cÃ¡c chá»‰ sá»‘ nÃ y giÃºp ngÆ°á»i phÃ¡t triá»ƒn mÃ´ hÃ¬nh tá»‘i Æ°u hÃ³a vÃ  lá»±a chá»n mÃ´ hÃ¬nh phÃ¹ há»£p vá»›i bÃ i toÃ¡n cá»¥ thá»ƒ. 
			https://aicandy.vn/wp-content/uploads/2024/09/aicandy_PhuongPhapDanhGiaMoHinh_ML.jpg


# Confusion Matrix 
	Confusion Matrix lÃ  má»™t cÃ´ng cá»¥ dÃ¹ng Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ hiá»‡u suáº¥t cá»§a má»™t mÃ´ hÃ¬nh phÃ¢n loáº¡i. NÃ³ hiá»ƒn thá»‹ sá»‘ láº§n mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n Ä‘Ãºng vÃ  sai cho tá»«ng lá»›p, giÃºp báº¡n dá»… dÃ ng hiá»ƒu rÃµ mÃ´ hÃ¬nh phÃ¢n loáº¡i chÃ­nh xÃ¡c hay sai lá»‡ch nhÆ° tháº¿ nÃ o. 
	
	Confusion Matrix lÃ  má»™t báº£ng hÃ¬nh vuÃ´ng vá»›i cÃ¡c giÃ¡ trá»‹ thá»ƒ hiá»‡n káº¿t quáº£ cá»§a mÃ´ hÃ¬nh phÃ¢n loáº¡i 
	
	
								Predicted Positive				Predicted Negative
		Actual Positive			True Positive (TP)				False Negative (FN)
		Actual Negative			False Positive (FP)				True Negative (TN)
		
		Giáº£i thÃ­ch cÃ¡c thÃ nh pháº§n
		True Positive (TP): Sá»‘ máº«u thá»±c sá»± dÆ°Æ¡ng tÃ­nh vÃ  Ä‘Æ°á»£c mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n chÃ­nh xÃ¡c lÃ  dÆ°Æ¡ng tÃ­nh.
		True Negative (TN): Sá»‘ máº«u thá»±c sá»± Ã¢m tÃ­nh vÃ  Ä‘Æ°á»£c mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n chÃ­nh xÃ¡c lÃ  Ã¢m tÃ­nh.
		False Positive (FP): Sá»‘ máº«u thá»±c sá»± Ã¢m tÃ­nh nhÆ°ng mÃ´ hÃ¬nh láº¡i dá»± Ä‘oÃ¡n nháº§m lÃ  dÆ°Æ¡ng tÃ­nh. 
		False Negative (FN): Sá»‘ máº«u thá»±c sá»± dÆ°Æ¡ng tÃ­nh nhÆ°ng mÃ´ hÃ¬nh láº¡i dá»± Ä‘oÃ¡n nháº§m lÃ  Ã¢m tÃ­nh. 



		
	## VÃ­ dá»¥ vá» Confusion Matrix 
		Giáº£ sá»­ báº¡n cÃ³ má»™t mÃ´ hÃ¬nh phÃ¢n loáº¡i nhá»‹ phÃ¢n vá»›i káº¿t quáº£ nhÆ° sau 
			- Sá»‘ máº«u thá»±c sá»± dÆ°Æ¡ng tÃ­nh : 50 
			- Sá»‘ máº«u thá»±c sá»± áº¥m tÃ­nh : 50 
			- MÃ´ hÃ¬nh dá»± Ä‘oÃ¡n chÃ­nh xÃ¡c 45 máº«u dÆ°Æ¡ng tÃ­nh vÃ  40 máº«u Ã¢m tÃ­nh  
			- CÃ¡c káº¿t quáº£ nháº§m láº§n lÃ  5 False Negative vÃ  10 False Positive 
		
		### Confusion Matrix sáº½ nhÆ° sau: 
									Predicted Positive	Predicted Negative
		Actual Positive					45 (TP)				5 (FN)
		Actual Negative					10 (FP)				40 (TN)
		

		Trong Ä‘Ã³:
		
		TP (True Positive): Sá»‘ lÆ°á»£ng dá»± Ä‘oÃ¡n Ä‘Ãºng cho lá»›p dÆ°Æ¡ng tÃ­nh.
		TN (True Negative): Sá»‘ lÆ°á»£ng dá»± Ä‘oÃ¡n Ä‘Ãºng cho lá»›p Ã¢m tÃ­nh.
		FP (False Positive): Sá»‘ lÆ°á»£ng dá»± Ä‘oÃ¡n sai cho lá»›p dÆ°Æ¡ng tÃ­nh (Ã¢m tÃ­nh bá»‹ dá»± Ä‘oÃ¡n nháº§m thÃ nh dÆ°Æ¡ng tÃ­nh).
		FN (False Negative): Sá»‘ lÆ°á»£ng dá»± Ä‘oÃ¡n sai cho lá»›p Ã¢m tÃ­nh (dÆ°Æ¡ng tÃ­nh bá»‹ dá»± Ä‘oÃ¡n nháº§m thÃ nh Ã¢m tÃ­nh).



# Accuracy
	
	Accuracy lÃ  má»™t trong nhá»¯ng chá»‰ sá»‘ phá»• biáº¿n nháº¥t Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ Ä‘o lÆ°á»ng hiá»‡u suáº¥t cá»§a cÃ¡c mÃ´ hÃ¬nh phÃ¢n loáº¡i. NÃ³ biá»ƒu thá»‹ tá»‰ lá»‡ pháº§n trÄƒm cÃ¡c dá»± Ä‘oÃ¡n Ä‘Ãºng so vá»›i tá»•ng sá»‘ máº«u dá»¯ liá»‡u Ä‘Æ°á»£c dá»± Ä‘oÃ¡n . 
	
	CÃ´ng thá»©c Accuracy  
		Accuracy = \frac{TP + TN}{TP + TN + FP + FN} 
		
	
	## VÃ­ dá»¥ vá» Accuracy  
		Giáº£ sá»­ chÃºng ta cÃ³ 100 máº«u dá»¯ liá»‡u, trong Ä‘Ã³ mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n Ä‘Ãºng 90 máº«u vÃ  sai 10 máº«u. Khi Ä‘Ã³, Ä‘á»™ chÃ­nh xÃ¡c Accuracy sáº½ lÃ  
			Accuracy = 90 / 100 = 0.9 = 90% 
			
			
	## Äá»™ chÃ­nh xÃ¡c vÃ  dá»¯ liá»‡u máº¥t cÃ¢n báº±ng 
		Máº·c dÃ¹ Accuracy lÃ  má»™t chá»‰ sá»‘ quan trá»ng, nhÆ°ng nÃ³ cÃ³ thá»ƒ khÃ´ng pháº£n Ã¡nh Ä‘Ãºng hiá»‡u suáº¥t cá»§a mÃ´ hÃ¬nh trong cÃ¡c bÃ i toÃ¡n mÃ  dá»¯ liá»‡u bá»‹ máº¥t cÃ¢n báº±ng . VÃ­ dá»¥, náº¿u mÃ´ hÃ¬nh chá»‰ dá»± Ä‘oÃ¡n táº¥t cáº£ cÃ¡c máº¥u thuá»™c má»™t lá»›p, Ä‘á»™ chÃ­nh xÃ¡c váº«n cao náº¿u lá»›p Ä‘Ã³ chiáº¿m tá»‰ lá»‡ lá»›n trong dá»¯ liá»‡u. 
		
	
	
	## ChÆ°Æ¡ng trÃ¬nh máº«u tÃ­nh Accuracy vá»›i pytorch 
		
		
			import torch 
			
			# HÃ m láº¥y Ä‘á»™ chÃ­nh xÃ¡c 
			def accuracy(pred, labels):
				# Láº¥y sá»‘ dá»± Ä‘oÃ¡n chÃ­nh xÃ¡c 
				correct = (preds == labels).sum().item()
			
				# TÃ­nh Ä‘á»™ chÃ­nh xÃ¡c 
				acc = correct / labels.size(0)
				return acc
			
			# VÃ­ dá»¥ vá» dá»± Ä‘oÃ¡n vÃ  nhÃ£n thá»±c táº¿ 
			predictions = torch.tensor([1,0,1,1,0])
			labels = torch.tensor([1,0,1,0,0])
			
			# TÃ­nh Ä‘á»™ chÃ­nh xÃ¡c 
			acc = accuracy(predictions, labels)
			print(f'Accuracy:{acc * 100:.2f}%')	
			
	Trong vÃ­ dá»¥ trÃªn, ta cÃ³ 5 máº«u vá»›i dá»± Ä‘oÃ¡n vÃ  nhÃ£n thá»±c táº¿. HÃ m accuracy sáº½ tÃ­nh toÃ¡n Ä‘á»™ chÃ­nh xÃ¡c dá»±a trÃªn sá»‘ lÆ°á»£ng dá»± Ä‘oÃ¡n Ä‘Ãºng vá»›i tá»•ng sá»‘ máº«u 
	
	Káº¿t quáº£ Ä‘oáº¡n chÆ°Æ¡ng trÃ¬nh máº«u trÃªn lÃ  Accuracy : 80.00%
	
	
# Precision 

 Precision lÃ  má»™t chá»‰ sá»‘ Ä‘Ã¡nh giÃ¡ hiá»‡u suáº¥t cá»§a mÃ´ hÃ¬nh phÃ¢n loáº¡i, Ä‘áº·c biá»‡t chÃº trá»ng Ä‘áº¿n tÃ­nh chÃ­nh xÃ¡c cá»§a cÃ¡c dá»± Ä‘oÃ¡n dÆ°Æ¡ng tÃ­nh. NÃ³ biá»ƒu thá»‹ tá»· lá»‡ máº«u dÆ°Æ¡ng tÃ­nh Ä‘Æ°á»£c dá»± Ä‘oÃ¡n Ä‘Ãºng trÃªn tá»•ng sá»‘ máº«u Ä‘Æ°á»£c mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n lÃ  dÆ°Æ¡ng tÃ­nh.

	## CÃ´ng thá»©c Precision 
		CÃ´ng thá»©c tÃ­nh Ä‘á»™ chÃ­nh xÃ¡c theo lá»›p dÆ°Æ¡ng (Precision) nhÆ° sau:
			Precision = \frac{TP}{TP + FP}
			
		Trong Ä‘Ã³ 
			TP (True Positive): Sá»‘ lÆ°á»£ng dá»± Ä‘oÃ¡n Ä‘Ãºng cho lá»›p dÆ°Æ¡ng tÃ­nh. 
			FP (False Positive): Sá»‘ lÆ°á»£ng dá»± Ä‘oÃ¡n sai cho lá»›p dÆ°Æ¡ng tÃ­nh (Ã¢m tÃ­nh bá»‹ dá»± Ä‘oÃ¡n nháº§m thÃ nh dÆ°Æ¡ng tÃ­nh). 


	## VÃ­ dá»¥ vá» Precision 
		Giáº£ sá»­ mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n 30 máº«u lÃ  dÆ°Æ¡ng tÃ­nh, trong Ä‘Ã³ cÃ³ 25 máº«u Ä‘Ãºng vÃ  5 máº«u sai. Khi Ä‘Ã³, Ä‘á»™ chÃ­nh xÃ¡c theo lá»›p dÆ°Æ¡ng (Precision) sáº½ Ä‘Æ°á»£c tÃ­nh nhÆ° sau: 
				Precision = \frac{25}{25 + 5} = \frac{25}{30} = 0.83 = 83\%
			
			Precision Ä‘áº·c biá»‡t quan trá»ng trong cÃ¡c bÃ i toÃ¡n mÃ  viá»‡c dá»± Ä‘oÃ¡n sai lá»›p dÆ°Æ¡ng tÃ­nh (False Positive) cÃ³ háº­u quáº£ nghiÃªm trá»ng. VÃ­ dá»¥, trong cháº©n Ä‘oÃ¡n bá»‡nh, náº¿u mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n má»™t ngÆ°á»i bá»‡nh khi há» thá»±c sá»± khÃ´ng máº¯c bá»‡nh, Ä‘iá»u nÃ y cÃ³ thá»ƒ dáº«n Ä‘áº¿n viá»‡c Ä‘iá»u trá»‹ khÃ´ng cáº§n thiáº¿t. Do Ä‘Ã³, chá»‰ sá»‘ Precision giÃºp giáº£m thiá»ƒu cÃ¡c trÆ°á»ng há»£p dá»± Ä‘oÃ¡n sai lá»›p dÆ°Æ¡ng tÃ­nh.


		## ChÆ°Æ¡ng trÃ¬nh máº«u tÃ­nh Precision vá»›i pytorch: 

				import torch
				
				# HÃ m tÃ­nh Precision
				def precision(preds, labels):
					# TÃ­nh True Positive (TP) vÃ  False Positive (FP)
					true_positive = ((preds == 1) & (labels == 1)).sum().item()
					false_positive = ((preds == 1) & (labels == 0)).sum().item()
					
					# TÃ­nh Precision
					if true_positive + false_positive == 0:
						return 0
					else:
						prec = true_positive / (true_positive + false_positive)
						return prec
				
				# VÃ­ dá»¥ vá» dá»± Ä‘oÃ¡n vÃ  nhÃ£n thá»±c táº¿
				predictions = torch.tensor([1, 0, 1, 1, 0])
				labels = torch.tensor([1, 0, 1, 0, 0])
				
				# TÃ­nh Precision
				prec = precision(predictions, labels)
				print(f'Precision: {prec * 100:.2f}%')
				
				
		Trong vÃ­ dá»¥ trÃªn, mÃ´ hÃ¬nh cÃ³ 5 dá»± Ä‘oÃ¡n vÃ  nhÃ£n thá»±c táº¿ tÆ°Æ¡ng á»©ng. HÃ m precision sáº½ tÃ­nh toÃ¡n tá»· lá»‡ True Positive trÃªn tá»•ng sá»‘ máº«u Ä‘Æ°á»£c dá»± Ä‘oÃ¡n lÃ  dÆ°Æ¡ng tÃ­nh.
		Káº¿t quáº£ Ä‘oáº¡n chÆ°Æ¡ng trÃ¬nh máº«u trÃªn: Precision: 66.67%
		Precision ráº¥t quan trá»ng trong cÃ¡c bÃ i toÃ¡n mÃ  viá»‡c dá»± Ä‘oÃ¡n sai lá»›p dÆ°Æ¡ng tÃ­nh cÃ³ thá»ƒ gÃ¢y ra háº­u quáº£ lá»›n, cháº³ng háº¡n nhÆ° phÃ¡t hiá»‡n gian láº­n, cháº©n Ä‘oÃ¡n y táº¿, hoáº·c lá»c spam.



# Recall  
	Recall, cÃ²n Ä‘Æ°á»£c gá»i lÃ  Sensitivity hoáº·c True Positive Rate, lÃ  má»™t chá»‰ sá»‘ quan trá»ng Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ kháº£ nÄƒng cá»§a mÃ´ hÃ¬nh trong viá»‡c nháº­n diá»‡n Ä‘Ãºng cÃ¡c máº«u thuá»™c lá»›p dÆ°Æ¡ng tÃ­nh. NÃ³ thá»ƒ hiá»‡n tá»· lá»‡ cÃ¡c máº«u dÆ°Æ¡ng tÃ­nh thá»±c sá»± Ä‘Æ°á»£c mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n Ä‘Ãºng trÃªn tá»•ng sá»‘ máº«u dÆ°Æ¡ng tÃ­nh trong táº­p dá»¯ liá»‡u.
	
	
	## CÃ´ng thá»©c Recall
		 CÃ´ng thá»©c tÃ­nh Recall (Äá»™ nháº¡y) nhÆ° sau: 
			Recall = \frac{TP}{TP + FN} 
			
			
		Trong Ä‘Ã³: 
			TP (True Positive): Sá»‘ lÆ°á»£ng dá»± Ä‘oÃ¡n Ä‘Ãºng cho lá»›p dÆ°Æ¡ng tÃ­nh. 
			FN (False Negative): Sá»‘ lÆ°á»£ng dá»± Ä‘oÃ¡n sai cho lá»›p dÆ°Æ¡ng tÃ­nh (dÆ°Æ¡ng tÃ­nh bá»‹ dá»± Ä‘oÃ¡n nháº§m thÃ nh Ã¢m tÃ­nh).
			


	## VÃ­ dá»¥ vá» Recall 
		Giáº£ sá»­ cÃ³ 50 máº«u thá»±c sá»± thuá»™c lá»›p dÆ°Æ¡ng tÃ­nh, vÃ  mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n Ä‘Ãºng 40 máº«u, trong khi bá» sÃ³t 10 máº«u (False Negative). Khi Ä‘Ã³, Recall Ä‘Æ°á»£c tÃ­nh nhÆ° sau:
				Recall = \frac{40}{40 + 10} = \frac{40}{50} = 0.8 = 80\%



		Recall Ä‘áº·c biá»‡t quan trá»ng trong cÃ¡c bÃ i toÃ¡n mÃ  viá»‡c bá» sÃ³t cÃ¡c trÆ°á»ng há»£p dÆ°Æ¡ng tÃ­nh (False Negative) cÃ³ háº­u quáº£ nghiÃªm trá»ng. VÃ­ dá»¥, trong cháº©n Ä‘oÃ¡n y táº¿, viá»‡c bá» sÃ³t má»™t bá»‡nh nhÃ¢n máº¯c bá»‡nh (FN) cÃ³ thá»ƒ gÃ¢y ra nhá»¯ng rá»§i ro lá»›n. VÃ¬ váº­y, trong nhá»¯ng trÆ°á»ng há»£p nÃ y, Recall Ä‘Æ°á»£c Æ°u tiÃªn cao hÆ¡n so vá»›i Precision.


	## ChÆ°Æ¡ng trÃ¬nh máº«u tÃ­nh Recall vá»›i pytorch: 
		
			import torch
			
			# HÃ m tÃ­nh Recall
			def recall(preds, labels):
				# TÃ­nh True Positive (TP) vÃ  False Negative (FN)
				true_positive = ((preds == 1) & (labels == 1)).sum().item()
				false_negative = ((preds == 0) & (labels == 1)).sum().item()
				
				# TÃ­nh Recall
				if true_positive + false_negative == 0:
					return 0
				else:
					rec = true_positive / (true_positive + false_negative)
					return rec
			
			# VÃ­ dá»¥ vá» dá»± Ä‘oÃ¡n vÃ  nhÃ£n thá»±c táº¿
			predictions = torch.tensor([1, 0, 1, 1, 0])
			labels = torch.tensor([1, 0, 1, 0, 1])
			
			# TÃ­nh Recall
			rec = recall(predictions, labels)
			print(f'Recall: {rec * 100:.2f}%')


# 6. F1-Score 

F1-Score lÃ  má»™t chá»‰ sá»‘ tá»•ng há»£p giá»¯a Precision (Äá»™ chÃ­nh xÃ¡c theo lá»›p dÆ°Æ¡ng) vÃ  Recall (Äá»™ nháº¡y), Ä‘áº·c biá»‡t há»¯u Ã­ch trong cÃ¡c bÃ i toÃ¡n phÃ¢n loáº¡i máº¥t cÃ¢n báº±ng dá»¯ liá»‡u. F1-Score cung cáº¥p má»™t cÃ¡i nhÃ¬n cÃ¢n báº±ng giá»¯a Precision vÃ  Recall, khi viá»‡c tá»‘i Æ°u hÃ³a cáº£ hai chá»‰ sá»‘ nÃ y lÃ  cáº§n thiáº¿t. NÃ³ Ä‘Æ°á»£c tÃ­nh báº±ng trung bÃ¬nh Ä‘iá»u hÃ²a cá»§a Precision vÃ  Recall.

	## CÃ´ng thá»©c F1-Score 
		CÃ´ng thá»©c tÃ­nh F1-Score nhÆ° sau: 
			F1 = 2 \times \frac{Precision \times Recall}{Precision + Recall} 
			
		Trong Ä‘Ã³ : 
			Precision: Tá»· lá»‡ dá»± Ä‘oÃ¡n Ä‘Ãºng cho lá»›p dÆ°Æ¡ng tÃ­nh trÃªn tá»•ng sá»‘ máº«u Ä‘Æ°á»£c dá»± Ä‘oÃ¡n lÃ  dÆ°Æ¡ng tÃ­nh 
			Recall: Tá»· lá»‡ máº«u dÆ°Æ¡ng tÃ­nh thá»±c sá»± Ä‘Æ°á»£c dá»± Ä‘oÃ¡n Ä‘Ãºng. 
	
	## 	VÃ­ dá»¥ vá» F1-Score 
		Giáº£ sá»­ mÃ´ hÃ¬nh cá»§a báº¡n cÃ³ Precision lÃ  80% vÃ  Recall lÃ  70%. Khi Ä‘Ã³, F1-Score Ä‘Æ°á»£c tÃ­nh nhÆ° sau: 
			F1 = 2 \times \frac{0.8 \times 0.7}{0.8 + 0.7} = 2 \times \frac{0.56}{1.5} = 0.7467 \approx 74.67\% 
			F1-Score lÃ  chá»‰ sá»‘ quan trá»ng khi cÃ³ sá»± Ä‘Ã¡nh Ä‘á»•i giá»¯a Precision vÃ  Recall. Trong nhá»¯ng tÃ¬nh huá»‘ng mÃ  báº¡n muá»‘n cÃ¢n báº±ng giá»¯a viá»‡c giáº£m False Positive (FP) vÃ  False Negative (FN), F1-Score cung cáº¥p má»™t cÃ¡i nhÃ¬n toÃ n diá»‡n hÆ¡n so vá»›i chá»‰ sá»­ dá»¥ng riÃªng Precision hay Recall. 
			
			
	## ChÆ°Æ¡ng trÃ¬nh máº«u tÃ­nh F1-Score vá»›i pytorch: 
		F1ScoreByPytorch.py 
		
		
		
		Trong vÃ­ dá»¥ trÃªn, chÃºng ta tÃ­nh toÃ¡n F1-Score dá»±a trÃªn cÃ¡c giÃ¡ trá»‹ Precision vÃ  Recall. HÃ m f1_score tráº£ vá» trung bÃ¬nh Ä‘iá»u hÃ²a giá»¯a Precision vÃ  Recall Ä‘á»ƒ cho ra chá»‰ sá»‘ F1.

		Káº¿t quáº£ Ä‘oáº¡n chÆ°Æ¡ng trÃ¬nh trÃªn: F1-Score: 66.67%
		
		F1-Score Ä‘áº·c biá»‡t quan trá»ng trong cÃ¡c bÃ i toÃ¡n mÃ  dá»¯ liá»‡u máº¥t cÃ¢n báº±ng, nÆ¡i viá»‡c tá»‘i Æ°u hÃ³a cáº£ Precision láº«n Recall lÃ  cáº§n thiáº¿t. NÃ³ giÃºp cung cáº¥p cÃ¡i nhÃ¬n tá»•ng quan vá» kháº£ nÄƒng phÃ¢n loáº¡i chÃ­nh xÃ¡c cá»§a mÃ´ hÃ¬nh trong nhá»¯ng tÃ¬nh huá»‘ng mÃ  má»™t chá»‰ sá»‘ Ä‘Æ¡n láº» khÃ´ng Ä‘á»§ pháº£n Ã¡nh hiá»‡u suáº¥t toÃ n diá»‡n.	
	

# 7. ROC vÃ  AUC 
	ROC (Receiver Operating Characteristic) lÃ  má»™t biá»ƒu Ä‘á»“ thá»ƒ hiá»‡n hiá»‡u suáº¥t cá»§a mÃ´ hÃ¬nh phÃ¢n loáº¡i á»Ÿ cÃ¡c ngÆ°á»¡ng khÃ¡c nhau. ROC Curve giÃºp so sÃ¡nh giá»¯a tá»· lá»‡ True Positive (TPR) vÃ  False Positive (FPR), cung cáº¥p má»™t cÃ¡i nhÃ¬n toÃ n diá»‡n vá» kháº£ nÄƒng phÃ¢n loáº¡i cá»§a mÃ´ hÃ¬nh Ä‘á»‘i vá»›i cÃ¡c lá»›p khÃ¡c nhau.
	
	## ROC Curve vÃ  AUC 
			True Positive Rate (TPR): CÃ²n Ä‘Æ°á»£c gá»i lÃ  Recall, Ä‘Æ°á»£c tÃ­nh báº±ng cÃ´ng thá»©c: 
				TPR = \frac{TP}{TP + FN} 
				
			False Positive Rate (FPR): ÄÆ°á»£c tÃ­nh báº±ng cÃ´ng thá»©c:
				FPR = \frac{FP}{FP + TN} 

		Káº¿t quáº£ lÃ  má»™t Ä‘á»“ thá»‹ biá»ƒu diá»…n sá»± Ä‘Ã¡nh Ä‘á»•i giá»¯a TPR vÃ  FPR á»Ÿ cÃ¡c ngÆ°á»¡ng khÃ¡c nhau. Chá»‰ sá»‘ phá»• biáº¿n Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh dá»±a trÃªn ROC lÃ  AUC (Area Under the Curve), thá»ƒ hiá»‡n diá»‡n tÃ­ch dÆ°á»›i Ä‘Æ°á»ng cong ROC. AUC náº±m trong khoáº£ng tá»« 0 Ä‘áº¿n 1, vá»›i giÃ¡ trá»‹ cÃ ng gáº§n 1 thÃ¬ mÃ´ hÃ¬nh cÃ ng tá»‘t.


	# VÃ­ dá»¥ vá» ROC vÃ  AUC 
		Giáº£ sá»­ báº¡n cÃ³ má»™t mÃ´ hÃ¬nh phÃ¢n loáº¡i vá»›i nhiá»u ngÆ°á»¡ng dá»± Ä‘oÃ¡n khÃ¡c nhau. á» má»—i ngÆ°á»¡ng, báº¡n tÃ­nh toÃ¡n TPR vÃ  FPR vÃ  váº½ Ä‘Æ°á»ng ROC. Náº¿u Ä‘Æ°á»ng ROC gáº§n vá»›i gÃ³c trÃªn bÃªn trÃ¡i cá»§a Ä‘á»“ thá»‹ (AUC gáº§n báº±ng 1), thÃ¬ mÃ´ hÃ¬nh cá»§a báº¡n hoáº¡t Ä‘á»™ng tá»‘t. 
		
		
	# ChÆ°Æ¡ng trÃ¬nh máº«u tÃ­nh ROC vÃ  AUC vá»›i pytorch: 
		
		Trong vÃ­ dá»¥ trÃªn, mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n xÃ¡c suáº¥t cho má»—i máº«u, vÃ  chÃºng ta sá»­ dá»¥ng thÆ° viá»‡n Scikit-learn Ä‘á»ƒ tÃ­nh toÃ¡n Ä‘Æ°á»ng ROC vÃ  AUC. Káº¿t quáº£ Ä‘Æ°á»£c váº½ dÆ°á»›i dáº¡ng Ä‘á»“ thá»‹ Ä‘á»ƒ thá»ƒ hiá»‡n má»‘i quan há»‡ giá»¯a TPR vÃ  FPR á»Ÿ cÃ¡c ngÆ°á»¡ng khÃ¡c nhau.
		https://aicandy.vn/wp-content/uploads/2024/09/aicandy_ROC.png
		
		ROC vÃ  AUC lÃ  nhá»¯ng cÃ´ng cá»¥ máº¡nh máº½ giÃºp Ä‘Ã¡nh giÃ¡ kháº£ nÄƒng phÃ¢n loáº¡i cá»§a mÃ´ hÃ¬nh mÃ  khÃ´ng phá»¥ thuá»™c vÃ o ngÆ°á»¡ng phÃ¢n loáº¡i cá»¥ thá»ƒ. Äiá»u nÃ y giÃºp ta cÃ³ cÃ¡i nhÃ¬n rÃµ rÃ ng hÆ¡n vá» hiá»‡u suáº¥t cá»§a mÃ´ hÃ¬nh trong cÃ¡c bÃ i toÃ¡n phÃ¢n loáº¡i nhá»‹ phÃ¢n. 

# Káº¿t luáº­n 
	Viá»‡c lá»±a chá»n phÆ°Æ¡ng phÃ¡p Ä‘Ã¡nh giÃ¡ hiá»‡u suáº¥t phÃ¹ há»£p lÃ  yáº¿u tá»‘ quan trá»ng giÃºp cáº£i thiá»‡n cháº¥t lÆ°á»£ng mÃ´ hÃ¬nh Machine Learning. TÃ¹y vÃ o loáº¡i bÃ i toÃ¡n vÃ  dá»¯ liá»‡u, cÃ¡c chá»‰ sá»‘ nhÆ° Accuracy, Precision, Recall, F1-Score hay AUC-ROC Ä‘á»u mang Ä‘áº¿n nhá»¯ng gÃ³c nhÃ¬n riÃªng vá» hiá»‡u quáº£ cá»§a mÃ´ hÃ¬nh. Äá»ƒ Ä‘áº£m báº£o mÃ´ hÃ¬nh hoáº¡t Ä‘á»™ng tá»‘i Æ°u trong cÃ¡c tÃ¬nh huá»‘ng thá»±c táº¿, viá»‡c káº¿t há»£p nhiá»u phÆ°Æ¡ng phÃ¡p Ä‘Ã¡nh giÃ¡ vÃ  phÃ¢n tÃ­ch káº¿t quáº£ lÃ  cáº§n thiáº¿t. Qua Ä‘Ã³, báº¡n cÃ³ thá»ƒ Ä‘áº£m báº£o ráº±ng mÃ´ hÃ¬nh khÃ´ng chá»‰ hoáº¡t Ä‘á»™ng tá»‘t trÃªn dá»¯ liá»‡u huáº¥n luyá»‡n mÃ  cÃ²n cÃ³ kháº£ nÄƒng tá»•ng quÃ¡t hÃ³a cao trÃªn dá»¯ liá»‡u thá»±c táº¿. 


</pre><a id='backBottom' href='../AI-learning-list.html' style='display:none;'>ğŸ”™ Quay láº¡i danh sÃ¡ch</a><br><button onclick='toggleTheme()'>ğŸŒ™ Chuyá»ƒn giao diá»‡n</button></div><script>function toggleTheme() {   let mode = document.body.classList.contains('dark-mode') ? 'light-mode' : 'dark-mode';   document.body.className = mode; localStorage.setItem('theme', mode);   syncTheme();}function applyTheme() {   let savedTheme = localStorage.getItem('theme') || 'dark-mode';   document.body.className = savedTheme;   syncTheme();}function syncTheme() {   let preElement = document.querySelector('pre');   if (document.body.classList.contains('dark-mode')) { preElement.style.background = '#1e1e1e'; preElement.style.color = '#e0e0e0'; }   else { preElement.style.background = '#f5f5f5'; preElement.style.color = '#333333'; }}function checkPageHeight() {   let contentHeight = document.body.scrollHeight;   let windowHeight = window.innerHeight;   if (contentHeight > windowHeight * 1.2) {       document.getElementById('backBottom').style.display = 'block';   } else {       document.getElementById('backBottom').style.display = 'none';   }}</script></body></html>