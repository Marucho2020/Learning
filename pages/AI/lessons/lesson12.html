<html><head><title>Lession 14  Convolutional Neural Networks (CNN) trong Deep Learning //</title><style>body { font-family: Arial, sans-serif; transition: background 0.3s, color 0.3s; }.dark-mode { background-color: #121212; color: #e0e0e0; }.light-mode { background-color: #ffffff; color: #333333; }h1 { text-align: center; color: #73d9f5; }pre { padding: 15px; border-radius: 5px;       white-space: pre-wrap; word-wrap: break-word;       overflow-x: auto; max-width: 100%;       transition: background 0.3s, color 0.3s; }.dark-mode pre { background: #1e1e1e; color: #e0e0e0; }.light-mode pre { background: #f5f5f5; color: #333333; }#backTop, #backBottom {    font-size: 2em; padding: 20px 40px;    background: #bb86fc; color: white; text-decoration: none;    border-radius: 10px; display: inline-block; text-align: center; }#backTop:hover, #backBottom:hover { background: #9b67e2; }button { font-size: 1.5em; padding: 15px 30px;    background: #03dac6; color: #121212; border: none;    cursor: pointer; border-radius: 5px; display: block; margin: 10px auto; }button:hover { background: #02b8a3; }.dark-mode a { color: #03dac6; } .light-mode a { color: #007bff; }</style></head><body onload='applyTheme(); checkPageHeight()'><div class='container'><a id='backTop' href='../AI-learning-list.html'>üîô Quay l·∫°i danh s√°ch</a><br><h1>Lession 14  Convolutional Neural Networks (CNN) trong Deep Learning //</h1><pre># Gi·ªõi thi·ªáu v·ªÅ CNN 
		Convolutional Neural Networks (CNN) l√† m·ªôt trong nh·ªØng ki·∫øn tr√∫c m·∫°ng n∆°-ron nh√¢n t·∫°o ƒë·∫∑c bi·ªát, ch·ªß y·∫øu ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ x·ª≠ l√Ω d·ªØ li·ªáu h√¨nh ·∫£nh, video, v√† c√°c d·∫°ng d·ªØ li·ªáu c√≥ c·∫•u tr√∫c kh√¥ng gian nh∆∞ t√≠n hi·ªáu √¢m thanh v√† chu·ªói d·ªØ li·ªáu. CNN xu·∫•t ph√°t t·ª´ vi·ªác m√¥ ph·ªèng l·∫°i c∆° ch·∫ø h·∫°t ƒë·ªông c·ªßa v·ªè n√£o th·ªã gi√°c c·ªßa con ng∆∞·ªùi, n∆°i c√°c t·∫ø b√†o th·∫ßn kinh c√≥ kh·∫£ nƒÉng ph·∫£n ·ª©ng v·ªõi c√°c k√≠ch th√≠ch th·ªã gi√°c, t·ª´ c√°c ƒë∆∞·ªùng bi√™n ƒë·∫øn c√°c h√¨nh d·∫°ng ph·ª©c t·∫°p. 
		
		CNN ƒë√£ c√≥ s·ª± ph√°t tri·ªÉn ƒëang k·ªÉ trong v√†i th·∫≠p k·ª∑ qua, b∆∞·ªõc ngo·∫∑t l√† s·ª± th√†nh c√¥ng c·ªßa m√¥ h√¨nh LeNet-5 do Yann LeCun gi·ªõi thi·ªáu v√†o nƒÉm 1998, ƒë∆∞·ª£c s·ª≠ d·ª•ng cho vi·ªác nh·∫≠n d·∫°ng ch·ªØ s·ªë vi·∫øt tay. Tuy nhi√™n, CNN th·ª±c s·ª± n·ªïi ti·∫øng nh·ªù m√¥ h√¨nh AlexNext, chi·∫øn th·∫Øng trong cu·ªôc thi ImageNet Large Scale Visual Recognition Challenge (ILSVRC) v√†o nƒÉm 2012. S·ª± th√†nh c√¥ng c·ªßa AlexNet m·ªü ra m·ªôt k·ª∑ nguy√™n m·ªõi cho nghi√™n c·ª©u trong th·ªã gi√°c m√°y t√≠nh v√† h·ªçc s√¢u 
		
	
	
	# C·∫•u tr√∫c c·ªßa CNN 
		CNN ƒë∆∞·ª£c x√¢y d·ª±ng t·ª´ nhi·ªÅu l·ªõp kh√°c nhau, m·ªói l·ªõp th·ª±c hi·ªán m·ªôt nhi·ªám v·ª• c·ª• th·ªÉ trong qu√° tr√¨nh tr√≠ch xu·∫•t v√† x·ª≠ l√Ω ƒë·∫∑c tr∆∞ng t·ª´ d·ªØ li·ªáu ƒë·∫ßu v√†o. C·∫•u tr√∫c ƒëi·ªÉn h√¨nh c·ªßa CNN bao g·ªìm b·ªën lo·∫°i l·ªõp ch√≠nh : Convolutional Layer , Activation Layer , Pooling Layer , Fully Connected Layer . M·ªói l·ªõp c√≥ vai tr√≤ c·ª• th·ªÉ v√† c√πng nhau t·∫°o th√†nh m·ªôt m·∫°ng CNN m·∫°nh m·∫Ω. 
		
			https://aicandy.vn/wp-content/uploads/2024/09/aicandy_CNN_arch.jpg


		## 2.1 Convolutional Layer 
			L·ªõp t√≠ch ch·∫≠p l√† n·ªÅn t·∫£ng c·ªët l√µi c·ªßa CNN, ch·ªãu tr√°ch nhi·ªám tr√≠ch xu·∫•t c√°c ƒë·∫∑c tr∆∞ng t·ª´ h√¨nh ·∫£nh ƒë·∫ßu v√†o. B·ªô l·ªçc(Filter )	 s·∫Ω tr∆∞·ª£t qua ·∫£nh v√† t√≠nh to√°n ph√©p t√≠ch ch·∫≠p gi·ªØa ·∫£nh v√† b·ªô l·ªçc ƒë√≥ 
			
			C√¥ng th·ª©c c·ªßa ph√©p t√≠ch ch·∫≠p hai chi·ªÅu 
				Y[i,j] = \sum_{m} \sum_{n} X[i+m, j+n] \cdot K[m,n] 
				
			Trong ƒë√≥ 
				X : Ma tr·∫≠n ƒë·∫ßu v√†o bi·ªÉu di·ªÖn h√¨nh ·∫£nh. 
				K : Ma tr·∫≠n kernel (b·ªô l·ªçc)
				Y[i,j] : Gi√° tr·ªã ƒë·∫ßu ra t·∫°i v·ªã tr√≠(i,j) sau khi th·ª±c hi·ªán ph√©p t√≠ch ch·∫≠p 
				
		
		## 2.2 Activation Layer 
			Sau khi th·ª±c hi·ªán ph√©p t√≠ch ch·∫≠p, d·ªØ li·ªáu s·∫Ω ƒëi qua l·ªõp k√≠ch ho·∫°t ƒë·ªÉ th√™m t√≠nh phi tuy·∫øn v√†o m√¥ h√¨nh. H√†m k√≠ch ho·∫°t ph·ªï bi·∫øn nh·∫•t l√† ReLU (Rectified Linear Unit)
					\text{ReLU}(x) = \max(0, x)
					
			ReLU gi√∫p lo·∫°i b·ªè c√°c gi√° tr·ªã √¢m trong ƒë·∫ßu ra c·ªßa ph√©p t√≠ch ch·∫≠p, gi·ªØ l·∫°i c√°c gi√° tr·ªã d∆∞∆°ng v√† gi√∫p tƒÉng t·ªëc qu√° tr√¨nh hu·∫•n luy·ªán 
			


		## 2.3 Pooling Layer 
			L·ªõp g·ªôp c√≥ nhi·ªám v·ª• gi·∫£m k√≠ch th∆∞·ªõc kh√¥ng gian c·ªßa b·∫£n ƒë·ªì ƒë·∫∑c tr∆∞ng, gi√∫p gi·∫£m s·ªë l∆∞·ª£ng tham s·ªë v√† t√≠nh to√°n trong m·∫°ng. L·ªõp g·ªôp l√†m cho m√¥ h√¨nh b·ªÅn v·ªØng h∆°n v·ªõi c√°c ph√©p bi·∫øn ƒë·ªïi nh∆∞ d·ªãch chuy·ªÉn ho·∫∑c xoay ·∫£nh 
			
			Ph·ªï bi·∫øn nh·∫•t l√† Max Pooling v·ªõi c√¥ng th·ª©c 
				Y[i,j] = \max(X[i:i+f, j:j+f]) 
				
			trong ƒë√≥ f l√† k√≠ch th∆∞·ªõc c·ªßa c·ª≠a s·ªï g·ªôp 
			
		## 2.4 Fully Connected Layer 
			Sau khi ƒëi qua nhi·ªÅu l·ªõp t√≠ch ch·∫≠p v√† g·ªôp, c√°c b·∫£n ƒë·ªì ƒë·∫∑c tr∆∞ng s·∫Ω ƒë∆∞·ª£c l√†m ph·∫≥ng th√†nh m·ªôt vector m·ªôt chi·ªÅu v√† ƒë∆∞a v√†o c√°c l·ªõp ho√†n to√°n k·∫øt n·ªëi.
			
			L·ªõp n√†y s·ª≠ d·ª•ng h√†m k√≠ch ho·∫°t softmax cho c√°c b√†i to√°n ph√¢n lo·∫°i ƒëa l·ªõp 
					\text{softmax}(z_i) = \frac{e^{z_i}}{\sum_{j=1}^{n} e^{z_j}} 
					
			Trong ƒë√≥ : 
				z_i : ƒê·∫ßu ra c·ªßa n∆°-ron t·∫°i l·ªõp fullyconnected 
				n : S·ªë l·ªõp ph√¢n lo·∫°i ƒë·∫ßu ra 
				
		## 2.5 Back propagation 
			Qu√° tr√¨nh hu·∫•n luy·ªán CNN s·ª≠ d·ª•ng thu·∫≠t to√°n lan truy·ªÅn ng∆∞·ª£c ƒë·ªÉ t·ªëi ∆∞u h√≥a c√°c tham s·ªë b·∫±ng c√°ch gi·∫£m thi·ªÉu h√†m m·∫•t m√°t(loss function). H√†m m·∫•t m√°t ph·ªï bi·∫øn cho b√†i to√°n ph√¢n lo·∫°i l√† cross-entropy 
						L = ‚Äì \sum_{i} y_i \log(\hat{y_i})
						
			Trong ƒë√≥ : 
				y_i : Gi√° tr·ªã th·ª±c t·∫ø (ground truth) cho l·ªõp i 
				\hat{y_i} : X√°c su·∫•t d·ª± ƒëo√°n c·ªßa m√¥ h√¨nh cho l·ªõp i 
				
		
		## 2.6 		 Tri·ªÉn khai CNN b·∫±ng PyTorch
		
			ConvolutionalNeuralNetworksByPyTorch.py
			
			Gi·∫£i th√≠ch : 
				conv1 , conv2 : C√°c l·ªõp t√≠ch ch·∫≠p ƒë·ªÉ tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng 
				pool : l·ªõp Max Pooling gi·∫£m k√≠ch th∆∞·ªõc ·∫£nh 
				fc1 , fc2 : C√°c l·ªõp fully connected th·ª±c hi·ªán ph√¢n lo·∫°i cu·ªëi c√πng 
				relu : H√†m k√≠ch ho·∫°t ReLU 
				
			ƒê√¢y l√† m·ªôt v√≠ d·ª• ƒë∆°n gi·∫£n v·ªÅ CNN. C√°c c·∫•u tr√∫c CNN th·ª±c t·∫ø c√≥ th·ªÉ ph·ª©c t·∫°p h∆°n, bao g·ªìm nhi·ªÅu t·∫ßng t√≠ch ch·∫≠p v√† g·ªôp ƒë·ªÉ tr√≠ch xu·∫•t c√°c ƒë·∫∑c tr∆∞ng ph·ª©c t·∫°p t·ª´ ·∫£nh. 
			
			
			
	# C√°c kh√°i ni·ªám ch√≠nh trong CNN 		
		
		## 3.1 Stride 
			Stride l√† b∆∞·ªõc nh·∫£y c·ªßa c·ª≠a s·ªï t√≠ch ch·∫≠p khi n√≥ di chuy·ªÉn qua ·∫£nh ƒë·∫ßu v√†o. Gi√° tr·ªã stride quy·∫øt ƒë·ªãnh t·ªëc ƒë·ªô di chuy·ªÉn c·ªßa c·ª≠a s·ªï. N·∫øu stride b·∫±ng 1, c·ª≠a s·ªï t√≠ch ch·∫≠p s·∫Ω di chuy·ªÉn t·ª´ng b∆∞·ªõc m·ªôt qua c√°c pixel, c√≤n n·∫øu stride b·∫±ng 2, c·ª≠a s·ªï s·∫Ω di chuy·ªÉn c√°ch 2 pixel m·ªôt l·∫ßn. 
				https://aicandy.vn/wp-content/uploads/2024/09/aicandy_CNN_stride.jpg
			
			Gi√° tr·ªã stride c√†ng l·ªõn, k√≠ch th∆∞·ªõc c·ªßa ƒë·∫ßu ra s·∫Ω nh·ªè h∆°n v√¨ c·ª≠a s·ªï t√≠ch ch·∫≠p s·∫Ω b·ªè qua nhi·ªÅu pixel h∆°n. ƒêi·ªÅu n√†y c√≥ th·ªÉ l√†m gi·∫£m ƒë·ªô ph√¢n gi·∫£i c·ªßa ƒë·∫ßu ra, nh∆∞ng ƒë·ªìng th·ªùi gi·∫£m thi·ªÉu kh·ªëi l∆∞·ª£ng t√≠nh to√°n. 
			
			
		## 3.2 Padding 
			Padding l√† k·ªπ thu·∫≠t th√™m c√°c pixel gi·∫£(th∆∞·ªùng l√† gi√° tr·ªã 0 , g·ªçi l√† Zero padding) xung quanh bi√™n c·ªßa ·∫£nh ƒë·∫ßu v√†o. ƒêi·ªÅu n√†y gi√∫p duy tr√¨ k√≠ch th∆∞·ªõc ƒë·∫ßu ra sau khi t√≠ch ch·∫≠p. 
					https://aicandy.vn/wp-content/uploads/2024/09/aicandy_CNN_padding.png
					
			Trong nhi·ªÅu tr∆∞·ªùng h·ª£p, ng∆∞·ªùi ta th√™m padding ƒë·ªÉ k√≠ch th∆∞·ªõc ƒë·∫ßu ra c·ªßa l·ªõp t√≠ch ch·∫≠p kh√¥ng b·ªã gi·∫£m. V√≠ d·ª•, n·∫øu kh√¥ng c√≥ padding, m·ªói l·∫ßn t√≠ch ch·∫≠p c√≥ th·ªÉ l√†m gi·∫£m k√≠ch th∆∞·ªõc kh√¥ng gian c·ªßa ·∫£nh ƒë·∫ßu ra. 
			
			
		## 3.3 Filter(Kernel)
			Filter hay c√≤n g·ªçi l√† kernels l√† c√°c ma tr·∫≠n nh·ªè ƒë∆∞·ª£c √°p d·ª•ng l√™n ·∫£nh ƒë·∫ßu v√†o trong qu√° tr√¨nh t√≠ch ch·∫≠p. C√°c b·ªô l·ªçc n√†y th·ª±c hi·ªán vi·ªác qu√©t qua to√†n b·ªô ·∫£nh ƒë·∫ßu v√†o, t√≠nh to√°n c√°c gi√° tr·ªã m·ªõi d·ª±a tr√™n ph√©p nh√¢n t√≠ch ch·∫≠p gi·ªØa b·ªô l·ªçc v√† c√°c ph·∫ßn t∆∞∆°ng ·ª©ng c·ªßa ·∫£nh. 
			
			M·ªói b·ªô l·ªçc s·∫Ω ph√°t hi·ªán c√°c ƒë·∫∑c tr∆∞ng c·ª• th·ªÉ, ch·∫≥ng h·∫°n nh∆∞ c·∫°nh, ƒë∆∞·ªùng n√©t, ho·∫∑c chi ti·∫øt ph·ª©c t·∫°p h∆°n ·ªü c√°c l·ªõp s√¢u. M·ªói l·ªõp t√≠ch ch·∫≠p trong m·∫°ng CNN c√≥ th·ªÉ s·ª≠ d·ª•ng nhi·ªÅu b·ªô l·ªçc ƒë·ªÉ ph√°t hi·ªán nhi·ªÅu ƒë·∫∑c tr∆∞ng kh√°c nhau. 
			
			
		## 3.4 Feature Maps 
			Features Maps(B·∫£n ƒë·ªì ƒë·∫∑c tr∆∞ng) l√† k·∫øt qu·∫£ ƒë·∫ßu ra c·ªßa m·ªôt l·ªõp t√≠ch ch·∫≠p sau khi √°p d·ª•ng c√°c b·ªô l·ªçc l√™n ·∫£nh ƒë·∫ßu v√†o. ƒê√¢y l√† n∆°i l∆∞u tr·ªØ c√°c ƒë·∫∑c tr∆∞ng ƒë√£ ƒë∆∞·ª£c ph√°t hi·ªán b·ªüi b·ªô l·ªçc trong qu√° tr√¨nh t√≠ch ch·∫≠p. 
			
			Feature maps th·ªÉ hi·ªán s·ª± hi·ªán di·ªán c·ªßa c√°c ƒë·∫∑c tr∆∞ng(nh∆∞ c·∫°nh, g√≥c) trong m·ªôt b·ª©c ·∫£nh t·∫°i c√°c v·ªã tr√≠ kh√¥ng gian kh√°c nhau. C√°c feature maps c√†ng s√¢u trong m·∫°ng CNN th√¨ ch·ª©a c√°c ƒë·∫∑c tr∆∞ng c√†ng ph·ª©c t·∫°p, tr·ª´u t∆∞·ª£ng h∆°n. 
			
			

	# Chu·∫©n b·ªã d·ªØ li·ªáu 
	
	Tr∆∞·ªõc khi b√°t ƒë·∫ßu qu√° tr√¨nh hu·∫•n luy·ªán, d·ªØ li·ªáu c·∫ßn ƒë∆∞·ª£c chu·∫©n b·ªã c·∫©n th·∫≠n: 
		
		## Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu 
			C√°c h√¨nh ·∫£nh ƒë·∫ßu v√†o th∆∞·ªùng ƒë∆∞·ª£c ƒëi·ªÅu ch·ªânh k√≠ch th∆∞·ªõc, chu·∫©n h√≥a gi√° tr·ªã pixel v·ªÅ m·ªôt kho·∫£ng gi√° tr·ªã nh·∫•t ƒë·ªãnh (v√≠ d·ª• t·ª´ 0 ƒë·∫øn 1), v√† ƒë√¥i khi ƒë∆∞·ª£c √°p d·ª•ng c√°c k·ªπ thu·∫≠t tƒÉng c∆∞·ªùng d·ªØ li·ªáu (data augmentation) nh∆∞ xoay, l·∫≠t ·∫£nh ƒë·ªÉ tƒÉng t√≠nh ƒëa d·∫°ng c·ªßa d·ªØ li·ªáu. 
			
		## v√≠ d·ª• code v·ªõi pytorch 
			# 1. ƒê·ªãnh nghƒ©a c√°c ph√©p bi·∫øn ƒë·ªïi (transform) cho d·ªØ li·ªáu
			transform = transforms.Compose([
				transforms.Resize((28, 28)),          # Thay ƒë·ªïi k√≠ch th∆∞·ªõc ·∫£nh v·ªÅ 28x28
				transforms.ToTensor(),                # Chuy·ªÉn ƒë·ªïi ·∫£nh th√†nh tensor
				transforms.Normalize((0.1307,), (0.3081,))  # Chu·∫©n h√≥a d·ªØ li·ªáu v·ªõi gi√° tr·ªã trung b√¨nh v√† ƒë·ªô l·ªách chu·∫©n
			])


		## Ph√¢n chia d·ªØ li·ªáu 
			B·ªô d·ªØ li·ªáu th∆∞·ªùng ƒë∆∞·ª£c chia th√†nh 3 ph·∫ßn : 
				- D·ªØ li·ªáu hu·∫•n luy·ªán (training set)  : D√πng ƒë·ªÉ hu·∫•n luy·ªán m√¥ h√¨nh 
				- D·ªØ li·ªáu ki·ªÉm ƒë·ªãnh (validation set) : D√πng ƒë·ªÉ ƒë√°nh gi√° m√¥ h√¨nh trong qu√° tr√¨nh hu·∫•n luy·ªán nh·∫±m ngƒÉn ch·∫∑n hi·ªán t∆∞·ª£ng overfitting 
				- D·ªØ li·ªáu ki·ªÉm tra(test set) : D√πng ƒë·ªÉ ƒë√°nh gi√° m√¥ h√¨nh sau khi ho√†n th√†nh hu·∫•n luy·ªán. 
				
		## Truy·ªÅn d·ªØ li·ªáu qua m·∫°ng  
			Qu√° tr√¨nh hu·∫•n luy·ªán bƒÉt ƒë·∫ßu b·∫±ng vi·ªác truy·ªÅn d·ªØu li·ªáu qua m·∫°ng CNN. C√°c B∆∞·ªõc ch√≠nh g·ªìm  : 
				
				### Forward pass 
					Trong b∆∞·ªõc n√†y, d·ªØ li·ªáu ƒë·∫ßu v√†o ƒëi qua c√°c l·ªõp c·ªßa m·∫°ng CNN, b·∫Øt ƒë·∫ßu t·ª´ l·ªõp t√≠ch ch·∫≠p, l·ªõp k√≠ch ho·∫°t(ReLU), L·ªõp pooling(gi·∫£m k√≠ch th∆∞·ªõc), v√† cu·ªëi c√πng l√† l·ªõp fully connected (k·∫øt n·ªëi ƒë·∫ßy ƒë·ªß).
					
						- C√°c l·ªõp t√≠ch ch·∫≠p(convolutaional layers) th·ª±c hi·ªán t√≠ch ch·∫≠p v·ªõi c√°c b·ªô l·ªçc (filters) ƒë·ªÉ ph√°t hi·ªán c√°c ƒë·∫∑c tr∆∞ng c·ªßa ·∫£nh. 
						- C√°c l·ªõp pooling gi·∫£m k√≠ch th∆∞·ªõc c·ªßa b·∫£n ƒë·ªì ƒë·∫∑c tr∆∞ng(feature maps), gi√∫p gi·∫£m kh·ªëi l∆∞·ª£ng t√≠nh to√°n v√† tr√≠ch xu·∫•t c√°c ƒë·∫∑c tr∆∞ng ch√≠nh
						- Cu·ªëi c√πng, l·ªõp fully connected t·∫°o ra c√°c d·ª± ƒëo√°n (output) v·ªÅ l·ªõp c·ªßa ·∫£nh 
						
				### T√≠nh to√°n h√†m m·∫•t m√°t (Loss Function)
					
					Sau khi nh·∫≠n ƒë∆∞·ª£c ƒë·∫ßu ra t·ª´ m·∫°ng, m·ªôt h√†m m·∫•t m√°t (loss function) ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ ƒëo l∆∞·ªùng s·ª± kh√°c bi·ªát gi·ªØa d·ª± ƒëo√°n c·ªßa m·∫°ng v√† gi√° tr·ªã nh√£n th·ª±c t·∫ø c·ªßa d·ªØ li·ªáu. 
					
					H√†m m·∫•t m√°t ph·ªï bi·∫øn : ƒë·ªëi v·ªõi c√°c b√†i to√°n ph√¢n lo·∫°i h√¨nh ·∫£nh, h√†m m·∫•t m√°t ph·ªï bi·∫øn nh·∫•t l√† cross-entropy loss, gi√∫p t√≠nh to√°n m·ª©c ƒë·ªô sai l·ªách gi·ªØa x√°c su·∫•t d·ª± ƒëo√°n c·ªßa m·∫°ng v√† nh√£n th·ª±c t·∫ø. 
					
					V√≠ d·ª• : code pytorch s·ª≠ d·ª•ng cross-entropy loss : 
						model = SimpleCNN()
						criterion = nn.CrossEntropyLoss()  # H√†m m·∫•t m√°t Cross-Entropy
						...
						...
						outputs = model(inputs)  # Forward pass
						loss = criterion(outputs, labels)  # T√≠nh to√°n h√†m m·∫•t m√°t
					
			
			

				### Lan truy·ªÅn ng∆∞·ª£c (Back propagation)	
					Sau khi t√≠nh to√°n h√†m m·∫•t m√°t, qu√° tr√¨nh lan truy·ªÅn ng∆∞·ª£c (backpropagation) b·∫Øt ƒë·∫ßu ƒë·ªÉ c·∫≠p nh·∫≠t c√°c tham s·ªë (weights)  c·ªßa m·∫°ng: 
						
						#### T√≠nh gradient : Qu√° tr√¨nh n√†y s·ª≠ d·ª•ng ƒë·∫°o h√†m c·ªßa h√†m m·∫•t m√°t v·ªõi t·ª´ng tr·ªçng s·ªë (weight) c·ªßa c√°c l·ªõp th√¥ng qua quy t·∫Øc chu·ªói (chain rule). ƒêi·ªÅu n√†y cho ph√©p t√≠nh to√°n ƒë∆∞·ª£c gradient, cho bi·∫øt tr·ªçng s·ªë n√†o c·∫ßn ƒëi·ªÅu ch·ªânh v√† ƒëi·ªÅu ch·ªânh bao nhi√™u. 
						
						#### C·∫≠p nh·∫≠t weights : C√°c tham s·ªë weights c·ªßa m·∫°ng ƒë∆∞·ª£c c·∫≠p nh·∫≠t b·∫±ng c√°ch s·ª≠ d·ª•ng thu·∫≠t to√°n t·ªëi ∆∞u h√≥a, ph·ªï bi·∫øn nh·∫•t l√† stochastic gradient descent(SGD) ho·∫∑c c√°c bi·∫øn th·ªÉ c·ªßa n√≥ nh∆∞ Adam. C√°c ham s·ªë n√†y ƒë∆∞·ª£c ƒëi·ªÅu ch·ªânh ƒë·ªÉ l√†m gi·∫£m m·∫•t m√°t trong c√°c l·∫ßn l·∫∑p ti·∫øp theo. 
						
						
				### Early stopping 
					Qu√° tr√¨nh tr√™n (forward pass , t√≠nh h√†m m·∫•t m√°t, backpropagation) di·ªÖn ra trong nhi·ªÅu l·∫ßn l·∫∑p g·ªçi l√† epoch 
					
					Trong m·ªói epoch, m·∫°ng s·∫Ω tr·∫£i qua to√†n b·ªô d·ªØ li·ªáu hu·∫•n luy·ªán. Sau ƒë√≥, m·∫°ng ti·∫øp t·ª•c ƒë∆∞·ª£c ƒë√°nh gi√° tr√™n b·ªô d·ªØ li·ªáu ki·ªÉm ƒë·ªãnh(validation set) ƒë·ªÉ theo d√µi ƒë·ªô ch√≠nh x√°c v√† ki·ªÉm tra t√¨nh trjang overfitting.
					
					Early stopping : Trong qu√° tr√¨nh hu·∫•n luy·ªán, n·∫øu ƒë·ªô ch√≠nh x√°c tr√™n t·∫≠p ki·ªÉm ƒë·ªãnh b·∫Øt ƒë·∫ßu gi·∫£m m·∫∑c d√π ƒë·ªô ch√≠nh x√°c tr√™n t·∫≠p hu·∫•n luy·ªán tƒÉng, qu√° tr√¨nh hu·∫•n luy·ªán c√≥ th·ªÉ ƒë∆∞·ª£c d·ª´ng s·ªõm (early stopping) ƒë·ªÉ tr√°nh hi·ªán t∆∞·ª£ng Overfitting.
					
			
		## ·ª®ng d·ª•ng th·ª±c t·∫ø c·ªßa CNN 
			M·∫°ng n∆°-ron t√≠ch ch·∫≠p (CNN) l√† m·ªôt trong nh·ªØng c√¥ng ngh·ªá quan tr·ªçng v√† ƒë∆∞·ª£c s·ª≠ d·ª•ng r·ªông r√£i trong nhi·ªÅu lƒ©nh v·ª±c li√™n quan ƒë·∫øn x·ª≠ l√Ω h√¨nh ·∫£nh v√† d·ªØ li·ªáu kh√¥ng gian. D∆∞·ªõi ƒë√¢y l√† c√°c ·ª©ng d·ª•ng th·ª±c t·∫ø ph·ªï bi·∫øn c·ªßa CNN : 
			
			### 5.1 Image Recognition & Classification 
				CNN ƒë√£ ƒë·∫°t ƒë∆∞·ª£c nhi·ªÅu th√†nh c√¥ng v∆∞·ª£t tr·ªôi trong c√°c b√†i to√°n nh·∫≠n di·ªán v√† ph√¢n lo·∫°i h√¨nh ·∫£nh. C√°c m√¥ h√¨nh CNN c√≥ th·ªÉ ph√¢n lo·∫°i c√°c ƒë·ªëi t∆∞·ª£ng trong ·∫£nh v·ªõi ƒë·ªô ch√≠nh x√°c r·∫•t cao. 
				
				·ª®ng d·ª•ng : Ph√¢n lo·∫°i ƒë·ªông v·∫≠t, nh·∫≠n di·ªán c√°c lo·∫°i ph∆∞∆°ng ti·ªán giao th√¥ng, ph√¢n lo·∫°i hoa v√† th·ª±c ph·∫©m. 
				
				V√≠ d·ª• th·ª±c t·∫ø : Trong Google Photos, CNN ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ ph√¢n lo·∫°i h√¨nh ·∫£nh th√†nh c√°c nh√≥m d·ª±a tr√™n n·ªôi dung nh∆∞ con ng∆∞·ªùi, phong c·∫£nh, ƒë·ªì v·∫≠t. 
				
			### Optical Character Recognition - OCR 
				CNN Kh√¥ng ch·ªâ ·ª©ng d·ª•ng cho h√¨nh ·∫£nh m√† c√≤n ƒë∆∞·ª£c √°p d·ª•ng trong x·ª≠ l√Ω ng√¥n ng·ªØ t·ª± nhi√™n v√† nhi·ªán di·ªán k√Ω t·ª± quang h·ªçc (OCR), gi√∫p m√°y t√≠nh nh·∫≠n di·ªán v√† chuy·ªÉn ƒë·ªïi vƒÉn b·∫£n t·ª´ h√¨nh ·∫£nh sang d·∫°ng vƒÉn b·∫£n s·ªë . 
				
				·ª®ng d·ª•ng : Qu√©t v√† nh·∫≠n di·ªán vƒÉn b·∫£n trong c√°c t√†i li·ªáu gi·∫•y, bi·ªÉn b√°o giao th√¥ng, s√°ch, ho·∫∑c h√≥a ƒë∆°n. 
				V√≠ d·ª• th·ª±c t·∫ø : Google Translate s·ª≠ d·ª•ng trong CNN trong t√≠nh nƒÉng d·ªãch tr·ª±c ti·∫øp t·ª´ h√¨nh ·∫£nh b·∫±ng c√°ch nh·∫≠n di·ªán vƒÉn b·∫£n trong ·∫£nh v√† d·ªãch sang ng√¥n ng·ªØ kh√°c. 
				
			### Image Segmentation 
				Ph√¢n ƒëo·∫°n ·∫£nh l√† qu√° tr√¨nh chia m·ªôt b·ª©c ·∫£nh th√†nh c√°c th√†nh ph·∫ßn ho·∫∑c ƒë·ªëi t∆∞·ª£ng kh√°c nhau d·ª±a tr√™n c√°c ƒë·∫∑c ƒëi·ªÉm. CNN gi√∫p ph√¢n ƒëo·∫°n c√°c v√πng kh√°c nhau trong ·∫£nh v√† x√°c ƒë·ªãnh c√°c ƒë·∫∑c tr∆∞ng ri√™ng bi·ªát c·ªßa t·ª´ng v√πng. 
				
				 ·ª®ng d·ª•ng : 
					Ph√¢n ƒëo·∫°n trong y t·∫ø ƒë·ªÉ x√°c ƒë·ªãnh c√°c t·∫ø b√†o ung th∆∞ ho·∫∑c c√°c m√¥ b·∫•t th∆∞·ªùng trong ·∫£nh y khoa, ph√¢n ƒëo·∫°n ƒë∆∞·ªùng trong h√¨nh ·∫£nh v·ªá tinh . 
					
				 V√≠ d·ª• th·ª±c t·∫ø : 
					Trong y h·ªçc, CNN gi√∫p ph√¢n ƒëo·∫°n c√°c c∆° quan n·ªôi t·∫°ng ho·∫∑c v√πng m√¥ ung th∆∞ t·ª´ c√°c ·∫£nh ch·ª•p CT ho·∫∑c MRI< h·ªó tr·ª£ chu·∫©n ƒëo√°n v√† ph·∫´u thu·∫≠t. 
					
			### Autonomous Driving 
				CNN ƒë√≥ng vai tr√≤ quan tr·ªçng trong c√°c h·ªá th·ªëng l·∫°i xe t·ª± ƒë·ªông, gi√∫p xe nh·∫≠n di·ªán v√† ph√¢n t√≠ch m√¥i tr∆∞·ªùng xung quanh, t·ª´ ƒë√≥ ƒë∆∞a ra quy·∫øt ƒë·ªãnh ƒëi·ªÅu h∆∞·ªõng v√† tr√°nh v·∫≠t c·∫£n. 
				
				·ª®ng d·ª•ng : 
					Nh·∫≠n di·ªán bi·ªÉn b√°o giao th√¥ng, l√†n ƒë∆∞·ªùng, ng∆∞·ªùi ƒëi b·ªô, ph∆∞∆°ng ti·ªán kh√°c v√† c√°c v·∫≠t th·ªÉ nguy hi·ªÉm. 
				V√≠ d·ª• th·ª±c t·∫ø : 
					Xe t·ª± l√°i c·ªßa Tesla s·ª≠ d·ª•ng CNN ƒë·ªÉ x·ª≠ l√Ω th√¥ng tin t·ª´ camera v√† c·∫£m bi·∫øn, gi√∫p xe di chuy·ªÉn an to√†n tr√™n ƒë∆∞·ªùng. 
					
				
# K·∫øt lu·∫≠n 
				Convolutional Neural Network(CNN) l√† m·ªôt trong nh·ªØng m√¥ h√¨nh quan t·ªèng v√† m·∫°nh m·∫Ω nh·∫•t trong lƒ©nh v·ª±c Deep Learning, ƒë·∫∑c bi·ªát hi·ªáu qu·∫£ cho c√°c b√†i to√°n x·ª≠ l√Ω h√¨nh ·∫£nh v√† nh·∫≠n di·ªán th·ªã gi√°c. CNN t·∫≠n d·ª•ng c√°c l·ªõp t√≠ch ch·∫≠p ƒë·ªÉ t·ª± ƒë·ªông tr√≠ch xu·∫•t c√°c ƒë·∫∑c tr∆∞ng t·ª´ d·ªØ li·ªáu m√† kh√¥ng c·∫ßn can thi·ªáp c·ªßa con ng∆∞·ªùi trong vi·ªác l·ª±a ch·ªçn c√°c ƒë·∫∑c tr∆∞ng ph√π h·ª£p .
				
				Nh·ªù v√†o c·∫•u tr√∫c ph√¢n c·∫•p, CNN c√≥ th·ªÉ h·ªçc t·ª´ c√°c ƒë·∫∑c tr∆∞ng c∆° b·∫£n (nh∆∞ c·∫°nh, g√≥c) ƒë·∫øn c√°c ƒë·∫∑c tr∆∞ng ph·ª©c t·∫°p h∆°n (nh∆∞ h√¨nh d·∫°ng, ƒë·ªëi t∆∞·ª£ng) khi ƒë·ªô s√¢u c·ªßa m·∫°ng tƒÉng l√™n. C√°c l·ªõp t√≠ch ch·∫≠p, l·ªõp g·ªôp, v√† l·ªõp fully connected k·∫øt h·ª£p v·ªõi nhau gi√∫p CNN c√≥ kh·∫£ nƒÉng x·ª≠ l√Ω d·ªØ li·ªáu l·ªõn v√† ƒë·∫°t ƒë·ªô ch√≠nh x√°c cao trong c√°c b√†i to√°n ph√¢n lo·∫°i, nh·∫≠n di·ªán ƒë·ªëi t∆∞·ª£ng, v√† c√°c nhi·ªám v·ª• kh√°c li√™n quan ƒë·∫øn th·ªã gi√°c m√°y t√≠nh. 
				M·∫∑c d√π c√≥ c·∫•u tr√∫c ph·ª©c t·∫°p v√† ƒë√≤i h·ªèi nhi·ªÅu t√†i nguy√™n t√≠nh to√°n, CNN v·∫´n ƒëang ƒë∆∞·ª£c nghi√™n c·ª©u v√† c·∫£i thi·ªán v·ªõi c√°c phi√™n b·∫£n ti√™n ti·∫øn h∆°n nh∆∞ ResNet, Inception, YOLO, v√† nhi·ªÅu h∆°n n·ªØa, gi√∫p n√¢ng cao hi·ªáu qu·∫£ v√† t·ªëc ƒë·ªô hu·∫•n luy·ªán m√¥ h√¨nh. 
				
				
</pre><a id='backBottom' href='../AI-learning-list.html' style='display:none;'>üîô Quay l·∫°i danh s√°ch</a><br><button onclick='toggleTheme()'>üåô Chuy·ªÉn giao di·ªán</button></div><script>function toggleTheme() {   let mode = document.body.classList.contains('dark-mode') ? 'light-mode' : 'dark-mode';   document.body.className = mode; localStorage.setItem('theme', mode);   syncTheme();}function applyTheme() {   let savedTheme = localStorage.getItem('theme') || 'dark-mode';   document.body.className = savedTheme;   syncTheme();}function syncTheme() {   let preElement = document.querySelector('pre');   if (document.body.classList.contains('dark-mode')) { preElement.style.background = '#1e1e1e'; preElement.style.color = '#e0e0e0'; }   else { preElement.style.background = '#f5f5f5'; preElement.style.color = '#333333'; }}function checkPageHeight() {   let contentHeight = document.body.scrollHeight;   let windowHeight = window.innerHeight;   if (contentHeight > windowHeight * 1.2) {       document.getElementById('backBottom').style.display = 'block';   } else {       document.getElementById('backBottom').style.display = 'none';   }}</script></body></html>